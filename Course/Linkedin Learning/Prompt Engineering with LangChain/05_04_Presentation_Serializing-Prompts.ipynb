{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dxKnBFQDOXH"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 29865,
     "status": "ok",
     "timestamp": 1706646166342,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "t2wToK-qqkNB"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain==0.1.4 openai==1.10.0 langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.3.11 requires langchain<0.4.0,>=0.3.11, but you have langchain 0.3.10 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain==0.3.10\n",
    "!pip install -q langchain-openai==0.2.12\n",
    "!pip install -q langchain-community==0.3.11\n",
    "!pip -q install openai==1.55.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3626,
     "status": "ok",
     "timestamp": 1706646169962,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "azqvOheLql3O",
    "outputId": "678c60b2-bfb0-41e6-cdf6-9eda2c40a641"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from getpass import getpass\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter Your OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZ1h776jqnQ4"
   },
   "source": [
    "# Serialization of Prompts in LangChain\n",
    "\n",
    "üåê **Prompt Serialization in LangChain:**\n",
    "\n",
    "- üìÅ **Save & Share Easily**: Turn prompts into files for simple storage and sharing.\n",
    "\n",
    "- üìÑ **Choose Your Format**: Use JSON or YAML for easy-to-read files.\n",
    "\n",
    "- üõ†Ô∏è **Flexible Storage**: Keep all your data in one place or spread it out‚Äîit's up to you.\n",
    "\n",
    "- ‚ö° **One-Stop Loading**: Regardless of the prompt type, loading them is a breeze.\n",
    "\n",
    "**Core Principles:**\n",
    "\n",
    "1. üëÄ**Readable by Humans**: JSON and YAML make prompts easy for us to read and edit.\n",
    "\n",
    "2. üìö **Flexible Filing**: Whether you're a one-file wonder or a multiple-file maestro, LangChain's got you covered.\n",
    "\n",
    "With LangChain, managing and exchanging prompts is as smooth as sending an email!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIOwDys6uEiQ"
   },
   "source": [
    "# Saving prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1706646510351,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "h77s5pAFuEsF"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an insightful question answering bot. A user will submit \\\n",
    "questions, which are delimited by triple backticks, and you should respond in \\\n",
    "an insighful manner.\n",
    "\n",
    "Question: ```{question}```\n",
    "\n",
    "Take a deep breath, and think step by step before answering.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "prompt.save(\"./content/cot_prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# !cat ./content/cot_prompt.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbcmkaNPuE63"
   },
   "source": [
    "# Loading prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1706646538025,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "KwN_kiSNrnLq"
   },
   "outputs": [],
   "source": [
    "# All prompts are loaded through the `load_prompt` function.\n",
    "from langchain.prompts import load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1706646539290,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "y596ApG8sBiY",
    "outputId": "7df2d134-97b6-46de-b8aa-5857ad7219b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# !wget https://raw.githubusercontent.com/hwchase17/langchain-hub/master/prompts/memory/summarize/prompt.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1706646542013,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "qEpleayXsGc5",
    "outputId": "8d858bcb-1465-45d0-ef19-c56c8cd8de03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"input_variables\": [\n",
      "        \"summary\",\n",
      "        \"new_lines\"\n",
      "    ],\n",
      "    \"output_parser\": null,\n",
      "    \"template\": \"Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n{summary}\\n\\nNew lines of conversation:\\n{new_lines}\\n\\nNew summary:\",\n",
      "    \"template_format\": \"f-string\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "# !cat prompt.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_prompt = load_prompt(\"./content/cot_prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an insightful question answering bot. A user will submit questions, which are delimited by triple backticks, and you should respond in an insighful manner.\\n\\nQuestion: ```{question}```\\n\\nTake a deep breath, and think step by step before answering.\\n\\nAnswer:\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1706646551815,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "LF8cSBSesIZh",
    "outputId": "426dfe09-b102-4458-d3a7-c221eb22ee35"
   },
   "outputs": [],
   "source": [
    "prompt = load_prompt(\"./content/sample_prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1706646554941,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "Qz4fTR76sl8K",
    "outputId": "60235c2a-04fb-4cfa-9746-502ac40e79af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "{summary}\n",
      "\n",
      "New lines of conversation:\n",
      "{new_lines}\n",
      "\n",
      "New summary:\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HtAHSsETD8X5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_lines', 'summary']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOz+9EA7GoBbsR13eqQZRIm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
