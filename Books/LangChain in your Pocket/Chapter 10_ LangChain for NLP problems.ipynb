{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNkYgAOeA9dQ0iSzERxdTo0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4yCvl3k0cQwg","executionInfo":{"status":"ok","timestamp":1701687459914,"user_tz":-330,"elapsed":6034,"user":{"displayName":"mehul gupta","userId":"02075325736316345622"}},"outputId":"c11272fb-e68a-4479-8f73-b99b37ced025"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['This article discusses the basics of recommendation systems, which are used in various platforms such as social media, e-commerce, and entertainment apps',\n"," ' It explains the terminology, types of recommendations, algorithms used, common issues, and the importance of context in making recommendations',\n"," ' The article also introduces different types of recommendations, such as non-personalized, semi-personalized, personalized, and opinion-based recommendations',\n"," ' It provides an overview of algorithms used in recommendation systems, such as content-based recommendations and collaborative filtering',\n"," ' The article concludes by mentioning the major challenges faced by recommendation systems, including the cold start problem and the gray sheep problem',\n"," '']"]},"metadata":{},"execution_count":2}],"source":["#10.1 Summarization\n","\n","from langchain.chat_models import ChatOpenAI\n","from langchain.document_loaders import WebBaseLoader\n","from langchain.chains.summarize import load_summarize_chain\n","import os\n","\n","api_key = ''\n","os.environ['OPENAI_API_KEY'] = api_key\n","\n","llm = ChatOpenAI(openai_api_key=api_key)\n","\n","loader = WebBaseLoader(\"https://medium.com/p/144223fe60c8\")\n","chain = load_summarize_chain(llm, chain_type=\"stuff\")\n","docs = loader.load()\n","chain.run(docs).split('.')"]},{"cell_type":"code","source":["#10.2 Text Tagging and Classification\n","\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains import create_tagging_chain\n","\n","# Schema\n","schema = {\n","    \"properties\": {\n","        \"complexity\": {\n","            \"type\": \"integer\",\n","            \"enum\": [1, 2, 3, 4, 5],\n","            \"description\": \"describes how complex is the text. A higher score means more complex statement\",\n","        },\n","        \"tense\": {\n","            \"type\": \"string\",\n","            \"enum\": [\"past\",\"present\",\"future\"],\n","        },\n","        \"mood\":{\n","            \"type\":\"string\",\n","            \"enum\":[\"suprised\",'awful','regretful','happy','angry','normal']\n","        },\n","        \"sentiment\":\n","        {\n","            \"type\":\"string\",\n","            \"description\":\"describes the sentiment of sentence\",\n","            \"enum\":[\"positive\",\"negative\"]\n","\n","        },\n","\n","    },\n","    \"required\": [\"language\", \"tense\",\"mood\",\"sentiment\",\"complexity\"],\n","}\n","\n","# LLM\n","llm = ChatOpenAI(openai_api_key=api_key)\n","chain = create_tagging_chain(schema, llm)\n","\n","inp = \"Hey ! I assume I saw you yesterday. You look gullible\"\n","print(inp,'\\n',chain.run(inp))\n","\n","inp = \"He was so meticulous but now is on a decline\"\n","print(inp,'\\n',chain.run(inp))"],"metadata":{"id":"xBQp1d4idzxx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701688813315,"user_tz":-330,"elapsed":3237,"user":{"displayName":"mehul gupta","userId":"02075325736316345622"}},"outputId":"e7292cbe-4c09-43fc-93c0-d87bc1bfa74a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hey ! I assume I saw you yesterday. You look gullible \n"," {'complexity': '2', 'tense': 'past', 'mood': 'normal', 'sentiment': 'negative'}\n","He was so meticulous but now is on a decline \n"," {'complexity': '3', 'tense': 'present', 'mood': 'normal', 'sentiment': 'negative'}\n"]}]},{"cell_type":"code","source":["#10.3 Named Entity Recognition\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains import create_extraction_chain\n","\n","# Schema\n","schema = {\n","    \"properties\": {\n","        \"name\": {\"type\": \"string\"},\n","        \"time\":{\"type\":\"string\"},\n","        \"day\":{\"type\":\"string\"}\n","    }\n","}\n","\n","# Run chain\n","llm = ChatOpenAI(openai_api_key=api_key)\n","chain = create_extraction_chain(schema, llm)\n","\n","inp = \"\"\"Rajesh went to KFC last Thursday. I saw him around 5.30 PM\"\"\"\n","print(chain.run(inp))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cvUZPkNHfjq4","executionInfo":{"status":"ok","timestamp":1701688747570,"user_tz":-330,"elapsed":1805,"user":{"displayName":"mehul gupta","userId":"02075325736316345622"}},"outputId":"06c09600-7e37-494b-93d0-bba2a64dd894"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'name': 'Rajesh', 'time': '5.30 PM', 'day': 'last Thursday'}]\n"]}]},{"cell_type":"code","source":["#10.4 Text Embeddings\n","from langchain.embeddings import OpenAIEmbeddings\n","embeddings_model = OpenAIEmbeddings()\n","embeddings = embeddings_model.embed_documents(\n","    [\n","        \"He is a wrestler\",\n","        \"Let's dance\",\n","        \"What was that\",\n","        'Hey you',\n","        'I love her'\n","    ]\n",")\n","len(embeddings), len(embeddings[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-1TMr6THlS34","executionInfo":{"status":"ok","timestamp":1701689255827,"user_tz":-330,"elapsed":2756,"user":{"displayName":"mehul gupta","userId":"02075325736316345622"}},"outputId":"e5c9f33a-b1da-44f2-860c-62b575c7e015"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5, 1536)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["  #10.5.2 Multi-Classification\n","  from langchain.prompts.few_shot import FewShotPromptTemplate\n","  from langchain.prompts.prompt import PromptTemplate\n","\n","  examples = [\n","    {\"input\":\"football is a fun game\",\n","     \"output\":\"sports\"},\n","    {\"input\":\"SRK is the best actor\",\n","     \"output\":\"cinema\"},\n","    {\"input\":\"AI startups are at a boom right now\",\n","     \"output\":\"tech\"},\n","    {\"input\":\"He is good player of basketball\",\n","     \"output\":\"sports\"},\n","    {\"input\":\"Computers are becoming powerful now\",\n","     \"output\":\"tech\"},\n","    {\"input\":\"GodFather is a higly rated movie\",\n","     \"output\":\"cinema\"}\n","  ]\n","\n","  example_prompt = PromptTemplate(input_variables=[\"input\", \"output\"], template=\"input:{input}\\n output:{output}\")\n","\n","\n","  prompt = FewShotPromptTemplate(\n","      examples=examples,\n","      example_prompt=example_prompt,\n","      suffix=\"Question: {input}\",\n","      input_variables=[\"input\"]\n","  )\n","\n","  from langchain.chat_models import ChatOpenAI\n","  from langchain.chains import LLMChain\n","\n","  chain = LLMChain(llm=ChatOpenAI(openai_api_key=api_key), prompt=prompt)"],"metadata":{"id":"2Ebp9zcFjweE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chain.run(\"India lost the Cricket world cup final\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tKTlEtBhpwY9","executionInfo":{"status":"ok","timestamp":1701690426034,"user_tz":-330,"elapsed":697,"user":{"displayName":"mehul gupta","userId":"02075325736316345622"}},"outputId":"fe2c8ae0-b073-4a62-c42a-eb3dbe83a3ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'output:sports'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["#10.5.3 Example Selection\n","\n","import os\n","from langchain.prompts.example_selector import LengthBasedExampleSelector\n","from langchain.vectorstores import Chroma\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n","from langchain.llms import HuggingFaceHub\n","from langchain.chains import LLMChain\n","\n","\n","examples = [\n","    {\"input\":\"football is a fun game\",\n","     \"output\":\"sports\"},\n","    {\"input\":\"SRK is the best actor\",\n","     \"output\":\"cinema\"},\n","    {\"input\":\"AI startups are at a boom right now\",\n","     \"output\":\"tech\"},\n","    {\"input\":\"He is good player of basketball\",\n","     \"output\":\"sports\"},\n","    {\"input\":\"Computers are becoming powerful now\",\n","     \"output\":\"tech\"},\n","    {\"input\":\"GodFather is a higly rated movie\",\n","     \"output\":\"cinema\"}\n","  ]\n","\n","example_prompt = PromptTemplate(input_variables=[\"input\", \"output\"], template=\"input:{input}\\n output:{output}\")\n","example_selector = LengthBasedExampleSelector(\n","    examples=examples,\n","    example_prompt=example_prompt,\n","    max_length=25,\n",")\n","\n","prompt = FewShotPromptTemplate(example_selector=example_selector,example_prompt=example_prompt,suffix=\"Question: {input}\",input_variables=[\"input\"])\n","chain=LLMChain(llm=ChatOpenAI(openai_api_key=api_key),prompt=prompt)"],"metadata":{"id":"MVCN4F74rl6Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702811890059,"user_tz":-330,"elapsed":665,"user":{"displayName":"mehul gupta","userId":"02075325736316345622"}},"outputId":"490ff38c-9aee-4d57-d015-77c9d240b50c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n","  warnings.warn(warning_message, FutureWarning)\n"]}]},{"cell_type":"code","source":["print(prompt.format(input=\"India lost the cricket final\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrINEpsfehUx","executionInfo":{"status":"ok","timestamp":1702811891465,"user_tz":-330,"elapsed":10,"user":{"displayName":"mehul gupta","userId":"02075325736316345622"}},"outputId":"ca8f0655-bd1b-4c72-d4a7-ab8349c1ef1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input:football is a fun game\n"," output:sports\n","\n","input:SRK is the best actor\n"," output:cinema\n","\n","Question: India lost the cricket final\n"]}]},{"cell_type":"code","source":["#10.6 POS Tagging, Segmentation and more\n","\n","from langchain.chat_models import ChatOpenAI\n","from langchain.prompts.chat import (\n","    ChatPromptTemplate,\n","    SystemMessagePromptTemplate,\n","    HumanMessagePromptTemplate,\n",")\n","from langchain.chains import LLMChain\n","\n","template = \"\"\"You are a NLP machine. Act as a {problem} machine and give output for the input : {text}\"\"\"\n","\n","system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n","human_template = \"{text}\"\n","human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n","\n","chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n","chain = LLMChain(\n","    llm=ChatOpenAI(openai_api_key=api_key),\n","    prompt=chat_prompt\n",")"],"metadata":{"id":"ui0XvLpxpzvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chain.run({\"problem\":'POS Tagging',\"text\":\"He is not a good boy\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"uCy8oUcQqzUG","executionInfo":{"status":"ok","timestamp":1701690712836,"user_tz":-330,"elapsed":1131,"user":{"displayName":"mehul gupta","userId":"02075325736316345622"}},"outputId":"cdc4a205-ad73-4bf5-9a7e-24f3e4fb35dc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'He/PRP is/VBZ not/RB a/DT good/JJ boy/NN'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["chain.run({\"problem\":'segmentation',\"text\":\"He is not a good boy\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"unZmPWQVq5sW","executionInfo":{"status":"ok","timestamp":1701690738334,"user_tz":-330,"elapsed":1923,"user":{"displayName":"mehul gupta","userId":"02075325736316345622"}},"outputId":"98d571de-db14-4e9f-ec25-1e8bcd02659c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Segmented Output: \\n1. He \\n2. is \\n3. not \\n4. a \\n5. good \\n6. boy'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["chain.run({\"problem\":'Dependency parsing',\"text\":\"He is not a good boy\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"R-EP-mVhq_oK","executionInfo":{"status":"ok","timestamp":1701690792019,"user_tz":-330,"elapsed":2829,"user":{"displayName":"mehul gupta","userId":"02075325736316345622"}},"outputId":"1396cc98-59f6-4639-d746-47317231c507"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Here is the dependency parsing output for the input sentence \"He is not a good boy\":\\n\\n1. He - nsubj(is)\\n2. is - ROOT\\n3. not - neg(good)\\n4. a - det(boy)\\n5. good - amod(boy)\\n6. boy - attr(is)\\n\\nThis output represents the syntactic structure and relationships between the words in the sentence.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":[],"metadata":{"id":"rJmp881nexN1"},"execution_count":null,"outputs":[]}]}