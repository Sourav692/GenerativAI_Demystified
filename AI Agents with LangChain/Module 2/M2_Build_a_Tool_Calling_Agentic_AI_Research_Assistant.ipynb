{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kiH8lf1y4sD"
      },
      "source": [
        "# Build a Tool-Calling Agentic AI Research Assistant with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYBpZTjLnEXb"
      },
      "source": [
        "This demo will cover building AI Agents with the legacy LangChain `AgentExecutor`. These are fine for getting started, but for working with more advanced agents and having more finer control, LangChain recommends to use LangGraph, which we cover in other courses.\n",
        "\n",
        "Agents are systems that use an LLM as a reasoning engine to determine which actions to take and what the inputs to those actions should be. The results of those actions can then be fed back into the agent and it determines whether more actions are needed, or whether it is okay to stop.\n",
        "\n",
        "![](https://i.imgur.com/1uVnBAm.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2evPp14fy258",
        "outputId": "93aa791d-4f4c-4167-e6d1-7491fbeb93e5"
      },
      "outputs": [],
      "source": [
        "!pip install -qq langchain==0.3.14\n",
        "!pip install -qq langchain-openai==0.3.0\n",
        "!pip install -qq langchain-community==0.3.14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AakmY6B_zYte",
        "outputId": "f206e910-8ac4-4423-c1af-c000a92f3429"
      },
      "outputs": [],
      "source": [
        "!pip install -qq markitdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9c37cLnSrbg"
      },
      "source": [
        "## Enter Open AI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv3JzCEx_PAd",
        "outputId": "3e7a5d36-2bd9-49d8-88bc-5753c36d235c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Open AI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# from getpass import getpass\n",
        "\n",
        "# OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucWRRI3QztL2"
      },
      "source": [
        "## Enter Tavily Search API Key\n",
        "\n",
        "Get a free API key from [here](https://tavily.com/#api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK-1WLzOrJdb",
        "outputId": "143b9b1d-9ae9-4ab1-e830-27bab3836ee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Tavily Search API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce5arICZEEov"
      },
      "source": [
        "## Enter WeatherAPI API Key\n",
        "\n",
        "Get a free API key from [here](https://www.weatherapi.com/signup.aspx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpAMz1XgEEov",
        "outputId": "da1143c0-4243-4799-d76e-79e41dd8ea5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter WeatherAPI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# WEATHER_API_KEY = getpass('Enter WeatherAPI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T0s0um5Svfa"
      },
      "source": [
        "## Setup Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "# os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "howf-v0ARWbv"
      },
      "source": [
        "## Create Tools\n",
        "\n",
        "Here we create two custom tools which are wrappers on top of the [Tavily API](https://tavily.com/#api) and [WeatherAPI](https://www.weatherapi.com/)\n",
        "\n",
        "- Web Search tool with information extraction\n",
        "- Weather tool\n",
        "\n",
        "![](https://i.imgur.com/TyPAYXE.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "WEATHER_API_KEY = os.getenv('WEATHER_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue8xgu9WpuPi",
        "outputId": "5f312771-4696-4ee6-9d37-6a890b73086d"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from markitdown import MarkItDown\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
        "import requests\n",
        "import json\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                  search_depth='advanced',\n",
        "                                  include_answer=False,\n",
        "                                  include_raw_content=True)\n",
        "# certain websites won't let you crawl them unless you specify a user-agent\n",
        "session = requests.Session()\n",
        "session.headers.update({\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br\"\n",
        "})\n",
        "md = MarkItDown(requests_session=session)\n",
        "\n",
        "@tool\n",
        "def search_web_extract_info(query: str) -> list:\n",
        "    \"\"\"Search the web for a query and extracts useful information from the search links.\"\"\"\n",
        "    print('Calling web search tool')\n",
        "    results = tavily_tool.invoke(query)\n",
        "    docs = []\n",
        "\n",
        "    def extract_content(url):\n",
        "        \"\"\"Helper function to extract content from a URL.\"\"\"\n",
        "        extracted_info = md.convert(url)\n",
        "        text_title = extracted_info.title.strip()\n",
        "        text_content = extracted_info.text_content.strip()\n",
        "        return text_title + '\\n' + text_content\n",
        "    # parallelize execution of different urls\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for result in tqdm(results):\n",
        "            try:\n",
        "                future = executor.submit(extract_content, result['url'])\n",
        "                # Wait for up to 15 seconds for the task to complete\n",
        "                content = future.result(timeout=15)\n",
        "                docs.append(content)\n",
        "            except TimeoutError:\n",
        "                print(f\"Extraction timed out for url: {result['url']}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting from url: {result['url']} - {e}\")\n",
        "\n",
        "    return docs\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_weather(query: str) -> list:\n",
        "    \"\"\"Search weatherapi to get the current weather of the queried location.\"\"\"\n",
        "    print('Calling weather tool')\n",
        "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
        "\n",
        "    response = requests.get(complete_url)\n",
        "    data = response.json()\n",
        "    if data.get(\"location\"):\n",
        "        return data\n",
        "    else:\n",
        "        return \"Weather Data Not Found\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling weather tool\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'location': {'name': 'Kolkata',\n",
              "  'region': 'West Bengal',\n",
              "  'country': 'India',\n",
              "  'lat': 22.5697,\n",
              "  'lon': 88.3697,\n",
              "  'tz_id': 'Asia/Kolkata',\n",
              "  'localtime_epoch': 1752708144,\n",
              "  'localtime': '2025-07-17 04:52'},\n",
              " 'current': {'last_updated_epoch': 1752707700,\n",
              "  'last_updated': '2025-07-17 04:45',\n",
              "  'temp_c': 28.4,\n",
              "  'temp_f': 83.1,\n",
              "  'is_day': 0,\n",
              "  'condition': {'text': 'Mist',\n",
              "   'icon': '//cdn.weatherapi.com/weather/64x64/night/143.png',\n",
              "   'code': 1030},\n",
              "  'wind_mph': 7.4,\n",
              "  'wind_kph': 11.9,\n",
              "  'wind_degree': 168,\n",
              "  'wind_dir': 'SSE',\n",
              "  'pressure_mb': 1004.0,\n",
              "  'pressure_in': 29.65,\n",
              "  'precip_mm': 0.0,\n",
              "  'precip_in': 0.0,\n",
              "  'humidity': 94,\n",
              "  'cloud': 75,\n",
              "  'feelslike_c': 34.8,\n",
              "  'feelslike_f': 94.6,\n",
              "  'windchill_c': 27.3,\n",
              "  'windchill_f': 81.2,\n",
              "  'heatindex_c': 32.1,\n",
              "  'heatindex_f': 89.8,\n",
              "  'dewpoint_c': 25.2,\n",
              "  'dewpoint_f': 77.4,\n",
              "  'vis_km': 3.2,\n",
              "  'vis_miles': 1.0,\n",
              "  'uv': 0.0,\n",
              "  'gust_mph': 11.5,\n",
              "  'gust_kph': 18.5}}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_weather.invoke(\"weather in kolkata now\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2N5192vikJR"
      },
      "source": [
        "## Test Tool Calling with LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_B2EFrwTpuXB"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = [search_web_extract_info, get_weather]\n",
        "\n",
        "chatgpt_with_tools = chatgpt.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0rVVBGDpuYw",
        "outputId": "95231440-d9de-4c58-a536-e05d67e0f279"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'search_web_extract_info',\n",
              "  'args': {'query': 'Microsoft earnings call Q4 2024 details'},\n",
              "  'id': 'call_GV8xEXfSjode2c5fseFaqwW7',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Get details of Microsoft's earnings call Q4 2024\"\n",
        "response = chatgpt_with_tools.invoke(prompt)\n",
        "response.tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qfchhGEpuaj",
        "outputId": "d4674863-91c3-44ea-8a7e-67121e208f3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'get_weather',\n",
              "  'args': {'query': 'Bangalore'},\n",
              "  'id': 'call_ZbP60Z86ldINMwKOZoXQPiUS',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"how is the weather in Bangalore today\"\n",
        "response = chatgpt_with_tools.invoke(prompt)\n",
        "response.tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7kvwG3SmREW"
      },
      "source": [
        "## Build and Test AI Agent\n",
        "\n",
        "Now that we have defined the tools and the LLM, we can create the agent. We will be using a tool calling agent to bind the tools to the agent with a prompt. We will also add in the capability to store historical conversations as memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grNq1I6_5dxC",
        "outputId": "7353b0b3-cb8d-4324-efc1-601180a6bc7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"Act as a helpful assistant.\\n                You run in a loop of Thought, Action, PAUSE, Observation.\\n                At the end of the loop, you output an Answer.\\n                Use Thought to describe your thoughts about the question you have been asked.\\n                Use Action to run one of the actions available to you - then return PAUSE.\\n                Observation will be the result of running those actions.\\n                Repeat till you get to the answer for the given user query.\\n\\n                Use the following workflow format:\\n                  Question: the input task you must solve\\n                  Thought: you should always think about what to do\\n                  Action: the action to take which can be any of the following:\\n                            - break it into smaller steps if needed\\n                            - see if you can answer the given task with your trained knowledge\\n                            - call the most relevant tools at your disposal mentioned below in case you need more information\\n                  Action Input: the input to the action\\n                  Observation: the result of the action\\n                  ... (this Thought/Action/Action Input/Observation can repeat N times)\\n                  Thought: I now know the final answer\\n                  Final Answer: the final answer to the original input question\\n\\n                Tools at your disposal to perform tasks as needed:\\n                  - get_weather: whenever user asks get the weather of a place.\\n                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\\n             \"), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "SYS_PROMPT = \"\"\"Act as a helpful assistant.\n",
        "                You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "                At the end of the loop, you output an Answer.\n",
        "                Use Thought to describe your thoughts about the question you have been asked.\n",
        "                Use Action to run one of the actions available to you - then return PAUSE.\n",
        "                Observation will be the result of running those actions.\n",
        "                Repeat till you get to the answer for the given user query.\n",
        "\n",
        "                Use the following workflow format:\n",
        "                  Question: the input task you must solve\n",
        "                  Thought: you should always think about what to do\n",
        "                  Action: the action to take which can be any of the following:\n",
        "                            - break it into smaller steps if needed\n",
        "                            - see if you can answer the given task with your trained knowledge\n",
        "                            - call the most relevant tools at your disposal mentioned below in case you need more information\n",
        "                  Action Input: the input to the action\n",
        "                  Observation: the result of the action\n",
        "                  ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "                  Thought: I now know the final answer\n",
        "                  Final Answer: the final answer to the original input question\n",
        "\n",
        "                Tools at your disposal to perform tasks as needed:\n",
        "                  - get_weather: whenever user asks get the weather of a place.\n",
        "                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\n",
        "             \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
        "        (\"human\", \"{query}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_template.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlJwVepDmsZw"
      },
      "source": [
        "Now, we can initalize the agent with the LLM, the prompt, and the tools.\n",
        "\n",
        "The agent is responsible for taking in input and deciding what actions to take.\n",
        "\n",
        "REMEMBER the Agent does not execute those actions - that is done by the AgentExecutor\n",
        "\n",
        "Note that we are passing in the model `chatgpt`, not `chatgpt_with_tools`.\n",
        "\n",
        "That is because `create_tool_calling_agent` will call `.bind_tools` for us under the hood.\n",
        "\n",
        "This should ideally be used with an LLM which supports tool \\ function calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u4NMA82HpueH"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = [search_web_extract_info, get_weather]\n",
        "agent = create_tool_calling_agent(chatgpt, tools, prompt_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiL70NCrmkkW"
      },
      "source": [
        "Finally, we combine the `agent` (the brains) with the `tools` inside the `AgentExecutor` (which will repeatedly call the agent and execute tools)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vAuGe5G5pugJ"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent,\n",
        "                               tools=tools,\n",
        "                               early_stopping_method='force',\n",
        "                               max_iterations=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXqgT0Yth892",
        "outputId": "6c03e40b-832c-44b2-9318-77cbdb3f42ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As of my last update, Nvidia's Q4 2024 earnings call has not occurred. However, I can provide a general idea of what typically might be discussed in such a call based on past earnings calls. Key points usually include:\n",
            "\n",
            "1. **Financial Performance**: Discussion of revenue, net income, and earnings per share compared to previous quarters and year-over-year. This includes insights into the performance of different business segments such as gaming, data center, professional visualization, and automotive.\n",
            "\n",
            "2. **Market Trends**: Analysis of current market conditions affecting Nvidia's business, including demand for GPUs, AI, and data center products.\n",
            "\n",
            "3. **Product Updates**: Announcements or updates on new products, technologies, or services, and their expected impact on future growth.\n",
            "\n",
            "4. **Strategic Initiatives**: Information on strategic partnerships, acquisitions, or investments that Nvidia is pursuing to enhance its market position.\n",
            "\n",
            "5. **Guidance**: Forward-looking statements regarding expectations for the next quarter or fiscal year, including revenue projections and potential challenges.\n",
            "\n",
            "6. **Q&A Session**: Responses to questions from analysts and investors, providing additional insights into Nvidia's operations and strategy.\n",
            "\n",
            "For the most accurate and up-to-date information, you would need to refer to the official transcript or summary of the Q4 2024 earnings call once it is available.\n"
          ]
        }
      ],
      "source": [
        "query = \"\"\"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\"\"\n",
        "response = chatgpt.invoke(query)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07nRAXEwY7Ea",
        "outputId": "00785ea5-fcad-45bb-a491-0e287c184f55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2/5 [00:01<00:02,  1.29it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            " 60%|██████    | 3/5 [00:03<00:02,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.databricks.com/dataaisummit - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            " 80%|████████  | 4/5 [00:06<00:02,  2.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.databricks.com/blog/mosaic-ai-announcements-data-ai-summit-2025 - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "100%|██████████| 5/5 [00:07<00:00,  1.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.youtube.com/watch?v=Kqx4eeSDtAI - 'NoneType' object has no attribute 'strip'\n"
          ]
        }
      ],
      "source": [
        "query = \"\"\"Summarize the key points discussed in latest Databricks DAIS 2025\"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne8x7JqGPMmf",
        "outputId": "67158154-6b2c-498a-a4e8-6c4dfcf327d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Summarize the key points discussed in latest Databricks DAIS 2025',\n",
              " 'output': \"The Databricks Data + AI Summit 2025 highlighted several key innovations and strategic insights that are shaping the future of data and analytics. Here are the main points:\\n\\n1. **Strategic Implications for Data Leaders**:\\n   - Acceleration of insight delivery through tools like Databricks One, Genie AI/BI, and Agent Bricks.\\n   - Enhanced semantic consistency with Unity Catalog Metrics.\\n   - Empowerment of self-service analytics via Lakeflow Designer and Databricks Apps.\\n   - Streamlined data modernization with Lakebridge and Lakebase Architecture.\\n   - Strategic resource allocation through no-code and low-code platforms.\\n\\n2. **Major Announcements**:\\n   - **Lakebase Architecture**: A serverless, fully managed Postgres-compatible OLTP database integrated into the lakehouse.\\n   - **Genie AI/BI and Deep Research**: Offering conversational analytics and multi-turn reasoning for deep analysis.\\n   - **Databricks One**: A unified UI for business users to access various tools without technical friction.\\n   - **Unity Catalog Metrics**: Supports centrally defined business metrics and governance.\\n   - **Lakeflow Designer**: An AI-powered, no-code ETL builder.\\n   - **Lakebridge Migration Framework**: An open-source toolkit for data warehouse migration.\\n   - **Agent Bricks**: A framework for creating production-grade AI agents.\\n   - **Databricks Apps**: Enables secure app development with built-in governance.\\n   - **Free Edition of Databricks**: Offers core capabilities without initial cost, supported by a $100M investment.\\n\\n3. **Overall Direction**:\\n   - The summit emphasized a shift towards unified, intuitive platforms powered by AI, aiming to simplify experiences, ensure governed access, and enhance intelligent data consumption.\\n\\nThese announcements and strategic directions reflect Databricks' commitment to democratizing data and AI, reducing fragmentation, and enabling more intelligent and efficient data-driven decision-making.\"}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "H2_MM2jrPRya",
        "outputId": "71457141-9bae-4ece-efb3-eb2c1d245488"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The Databricks Data + AI Summit 2025 highlighted several key innovations and strategic insights that are shaping the future of data and analytics. Here are the main points:\n",
              "\n",
              "1. **Strategic Implications for Data Leaders**:\n",
              "   - Acceleration of insight delivery through tools like Databricks One, Genie AI/BI, and Agent Bricks.\n",
              "   - Enhanced semantic consistency with Unity Catalog Metrics.\n",
              "   - Empowerment of self-service analytics via Lakeflow Designer and Databricks Apps.\n",
              "   - Streamlined data modernization with Lakebridge and Lakebase Architecture.\n",
              "   - Strategic resource allocation through no-code and low-code platforms.\n",
              "\n",
              "2. **Major Announcements**:\n",
              "   - **Lakebase Architecture**: A serverless, fully managed Postgres-compatible OLTP database integrated into the lakehouse.\n",
              "   - **Genie AI/BI and Deep Research**: Offering conversational analytics and multi-turn reasoning for deep analysis.\n",
              "   - **Databricks One**: A unified UI for business users to access various tools without technical friction.\n",
              "   - **Unity Catalog Metrics**: Supports centrally defined business metrics and governance.\n",
              "   - **Lakeflow Designer**: An AI-powered, no-code ETL builder.\n",
              "   - **Lakebridge Migration Framework**: An open-source toolkit for data warehouse migration.\n",
              "   - **Agent Bricks**: A framework for creating production-grade AI agents.\n",
              "   - **Databricks Apps**: Enables secure app development with built-in governance.\n",
              "   - **Free Edition of Databricks**: Offers core capabilities without initial cost, supported by a $100M investment.\n",
              "\n",
              "3. **Overall Direction**:\n",
              "   - The summit emphasized a shift towards unified, intuitive platforms powered by AI, aiming to simplify experiences, ensure governed access, and enhance intelligent data consumption.\n",
              "\n",
              "These announcements and strategic directions reflect Databricks' commitment to democratizing data and AI, reducing fragmentation, and enabling more intelligent and efficient data-driven decision-making."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "riHUt00KE_3q",
        "outputId": "a45dcd11-12bf-43c7-da55-33b01c0fa057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2/5 [00:03<00:04,  1.53s/it]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            " 60%|██████    | 3/5 [00:04<00:02,  1.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.ahead.com/resources/snowflake-summit-2023-ahead-takeaways/ - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:10<00:00,  2.10s/it]\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The Snowflake Summit 2023 focused on several key areas, including new features, partnerships, and community engagement. Here are the main highlights:\n",
              "\n",
              "1. **New Features and Announcements**:\n",
              "   - Introduction of the Native Applications Framework, Managed Iceberg Tables, Snowpark Container Services, Dynamic Tables, Snowpipe Streaming API, Document AI, Snowflake Copilot, SnowflakeBudgets, Warehouse Utilization, and improvements in GeoSpatial and Time Series Analytics.\n",
              "   - Emphasis on AI and large language models (LLM), with a notable partnership between Snowflake and Nvidia to integrate AI capabilities into the Data Cloud.\n",
              "\n",
              "2. **Community and Networking**:\n",
              "   - Recognition of the Snowflake Data Superhero community and their contributions.\n",
              "   - Opportunities for networking with industry peers, partners, and Snowflake founders.\n",
              "\n",
              "3. **Industry Solutions and Use Cases**:\n",
              "   - Focus on leveraging Snowflake to solve specific business and industry problems.\n",
              "   - Encouragement for existing clients to explore new solutions beyond traditional data warehousing.\n",
              "\n",
              "4. **Developer and Partner Engagement**:\n",
              "   - Emphasis on diversifying skills and knowledge in areas like LLM, Python, and Data Apps.\n",
              "   - Recognition of partners like kipi.bi, which received the Americas System Integrator Growth: Partner of the Year Award.\n",
              "\n",
              "5. **Event Experience**:\n",
              "   - The summit was larger and better organized than previous years, with over 12,000 attendees and more than 500 sessions.\n",
              "   - Enhanced opportunities for hands-on labs and partner interactions.\n",
              "\n",
              "Overall, the Snowflake Summit 2023 was a significant event for showcasing Snowflake's advancements in data cloud technology, AI integration, and community building."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"Summarize the key points discussed in Snowflake latest Summit\"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "GfBHtCzJFKdb",
        "outputId": "8bc3f413-9adf-48a7-88c5-6ea25be31108"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Could you please provide more context or specify which companies you are referring to? Without additional information, I won't be able to determine which company's future outlook looks better."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"which company's as discussed above future outlook looks to be better?\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "O1-HaMLoZAwO",
        "outputId": "88218ffb-eb4e-45f3-c530-68cbeb0e2f03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling weather tool\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The current weather in Bangalore is as follows:\n",
              "\n",
              "- **Temperature**: 21.3°C (70.3°F)\n",
              "- **Condition**: Light drizzle\n",
              "- **Wind**: 9.4 mph (15.1 kph) from the WSW\n",
              "- **Pressure**: 1011.0 mb (29.85 in)\n",
              "- **Precipitation**: 0.38 mm (0.01 in)\n",
              "- **Humidity**: 94%\n",
              "- **Cloud Cover**: 75%\n",
              "- **Feels Like**: 21.3°C (70.3°F)\n",
              "- **Dew Point**: 19.1°C (66.4°F)\n",
              "- **Visibility**: 5.0 km (3.0 miles)\n",
              "- **UV Index**: 0.0\n",
              "- **Wind Gusts**: 14.7 mph (23.6 kph)\n",
              "\n",
              "The weather is currently overcast with light drizzle, and the humidity is quite high."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"how is the weather in Bangalore today?\n",
        "           show detailed statistics\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "2GosuSIoZrZm",
        "outputId": "a5212dd7-68f9-4820-934c-48a47a823c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling weather tool\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The weather in Dubai today is clear. Here are the detailed statistics:\n",
              "\n",
              "- **Temperature**: 34.2°C (93.6°F)\n",
              "- **Feels Like**: 42.2°C (107.9°F)\n",
              "- **Wind**: 6.3 mph (10.1 kph) from the SSE\n",
              "- **Wind Gusts**: Up to 12.7 mph (20.4 kph)\n",
              "- **Humidity**: 50%\n",
              "- **Pressure**: 997.0 mb (29.44 in)\n",
              "- **Precipitation**: 0.0 mm (0.0 in)\n",
              "- **Cloud Cover**: 0%\n",
              "- **Visibility**: 10.0 km (6.0 miles)\n",
              "- **UV Index**: 0.0\n",
              "- **Dew Point**: 23.6°C (74.6°F)\n",
              "\n",
              "The current conditions are updated as of 03:15 local time."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"how is the weather in Dubai today?\n",
        "           show detailed statistics\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "ElF1npM4ZvAo",
        "outputId": "0414a0b5-51dc-4183-813b-a6a37701fc6a"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Question: The question is asking which city is hotter, but it doesn't specify which cities to compare. I need more information to proceed.\n",
              "\n",
              "Thought: I need to ask the user for the specific cities they want to compare in terms of temperature.\n",
              "\n",
              "Final Answer: Please provide the names of the cities you would like to compare to determine which one is hotter."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"which city is hotter?\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQQAx3B7xrl-"
      },
      "source": [
        "The agent is doing pretty well but unfortunately it doesn't remember conversations. We will use some user-session based memory to store this and dive deeper into this in the next video."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
