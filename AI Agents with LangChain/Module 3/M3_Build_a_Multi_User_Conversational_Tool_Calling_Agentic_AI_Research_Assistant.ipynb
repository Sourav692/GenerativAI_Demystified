{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kiH8lf1y4sD"
      },
      "source": [
        "# Build a Multi-User Conversational Tool-Calling Agentic AI Research Assistant with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYBpZTjLnEXb"
      },
      "source": [
        "This demo will cover building AI Agents with the legacy LangChain `AgentExecutor`. These are fine for getting started, but for working with more advanced agents, LangChain recommends to use LangGraph, which we will cover in the future demos.\n",
        "\n",
        "Agents are systems that use an LLM as a reasoning engine to determine which actions to take and what the inputs to those actions should be. The results of those actions can then be fed back into the agent and it determines whether more actions are needed, or whether it is okay to stop.\n",
        "\n",
        "Here we will build a multi-user Conversational Agent which can refer to previous conversations and give more contextual answers by storing agent messages to a SQL database\n",
        "\n",
        "![](https://i.imgur.com/lHWqaT9.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2evPp14fy258",
        "outputId": "8f7fcca6-1101-4488-c0c7-0ffe0307cf69"
      },
      "outputs": [],
      "source": [
        "!pip install -qq langchain==0.3.14\n",
        "!pip install -qq langchain-openai==0.3.0\n",
        "!pip install -qq langchain-community==0.3.14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AakmY6B_zYte",
        "outputId": "4be48016-fc58-4992-9b93-a13f4c358026"
      },
      "outputs": [],
      "source": [
        "!pip install -qq markitdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9c37cLnSrbg"
      },
      "source": [
        "## Enter Open AI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv3JzCEx_PAd",
        "outputId": "f9111545-cbad-4b45-c073-d2fe2b35fe70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Open AI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# from getpass import getpass\n",
        "\n",
        "# OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucWRRI3QztL2"
      },
      "source": [
        "## Enter Tavily Search API Key\n",
        "\n",
        "Get a free API key from [here](https://tavily.com/#api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK-1WLzOrJdb",
        "outputId": "06b5df28-b09c-449e-d2b3-b0630c7efa60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Tavily Search API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce5arICZEEov"
      },
      "source": [
        "## Enter WeatherAPI API Key\n",
        "\n",
        "Get a free API key from [here](https://www.weatherapi.com/signup.aspx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpAMz1XgEEov",
        "outputId": "78e31000-cb94-4b68-cd9f-e360d2cd7480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter WeatherAPI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# WEATHER_API_KEY = getpass('Enter WeatherAPI API Key: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T0s0um5Svfa"
      },
      "source": [
        "## Setup Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "# os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "howf-v0ARWbv"
      },
      "source": [
        "## Create Tools\n",
        "\n",
        "Here we create two custom tools which are wrappers on top of the [Tavily API](https://tavily.com/#api) and [WeatherAPI](https://www.weatherapi.com/)\n",
        "\n",
        "- Web Search tool with information extraction\n",
        "- Weather tool\n",
        "\n",
        "![](https://i.imgur.com/TyPAYXE.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "WEATHER_API_KEY = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue8xgu9WpuPi",
        "outputId": "fc5f62c8-d5a1-4e33-846f-9cf4bb8eccea"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from markitdown import MarkItDown\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
        "import requests\n",
        "import json\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                  search_depth='advanced',\n",
        "                                  include_answer=False,\n",
        "                                  include_raw_content=True)\n",
        "session = requests.Session()\n",
        "session.headers.update({\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br\"\n",
        "})\n",
        "md = MarkItDown(requests_session=session)\n",
        "\n",
        "@tool\n",
        "def search_web_extract_info(query: str) -> list:\n",
        "    \"\"\"Search the web for a query and extracts useful information from the search links.\"\"\"\n",
        "    print('Calling web search tool')\n",
        "    results = tavily_tool.invoke(query)\n",
        "    docs = []\n",
        "\n",
        "    def extract_content(url):\n",
        "        \"\"\"Helper function to extract content from a URL.\"\"\"\n",
        "        extracted_info = md.convert(url)\n",
        "        text_title = extracted_info.title.strip()\n",
        "        text_content = extracted_info.text_content.strip()\n",
        "        return text_title + '\\n' + text_content\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for result in tqdm(results):\n",
        "            try:\n",
        "                future = executor.submit(extract_content, result['url'])\n",
        "                # Wait for up to 60 seconds for the task to complete\n",
        "                content = future.result(timeout=60)\n",
        "                docs.append(content)\n",
        "            except TimeoutError:\n",
        "                print(f\"Extraction timed out for url: {result['url']}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting from url: {result['url']} - {e}\")\n",
        "\n",
        "    return docs\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_weather(query: str) -> list:\n",
        "    \"\"\"Search weatherapi to get the current weather of the queried location.\"\"\"\n",
        "    print('Calling weather tool')\n",
        "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
        "\n",
        "    response = requests.get(complete_url)\n",
        "    data = response.json()\n",
        "    if data.get(\"location\"):\n",
        "        return data\n",
        "    else:\n",
        "        return \"Weather Data Not Found\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling weather tool\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Weather Data Not Found'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_weather.invoke(\"weather in kolkata now\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7kvwG3SmREW"
      },
      "source": [
        "## Build and Test AI Agent\n",
        "\n",
        "Now that we have defined the tools and the LLM, we can create the agent. We will be using a tool calling agent to bind the tools to the agent with a prompt. We will also add in the capability to store historical conversations as memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grNq1I6_5dxC",
        "outputId": "42022951-93f7-4958-e5bf-052567f9f4ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"Act as a helpful assistant.\\n                You run in a loop of Thought, Action, PAUSE, Observation.\\n                At the end of the loop, you output an Answer.\\n                Use Thought to describe your thoughts about the question you have been asked.\\n                Use Action to run one of the actions available to you - then return PAUSE.\\n                Observation will be the result of running those actions.\\n                Repeat till you get to the answer for the given user query.\\n\\n                Use the following workflow format:\\n                  Question: the input task you must solve\\n                  Thought: you should always think about what to do\\n                  Action: the action to take which can be any of the following:\\n                            - break it into smaller steps if needed\\n                            - see if you can answer the given task with your trained knowledge\\n                            - call the most relevant tools at your disposal mentioned below in case you need more information\\n                  Action Input: the input to the action\\n                  Observation: the result of the action\\n                  ... (this Thought/Action/Action Input/Observation can repeat N times)\\n                  Thought: I now know the final answer\\n                  Final Answer: the final answer to the original input question\\n\\n                Tools at your disposal to perform tasks as needed:\\n                  - get_weather: whenever user asks get the weather of a place.\\n                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\\n             \"), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "SYS_PROMPT = \"\"\"Act as a helpful assistant.\n",
        "                You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "                At the end of the loop, you output an Answer.\n",
        "                Use Thought to describe your thoughts about the question you have been asked.\n",
        "                Use Action to run one of the actions available to you - then return PAUSE.\n",
        "                Observation will be the result of running those actions.\n",
        "                Repeat till you get to the answer for the given user query.\n",
        "\n",
        "                Use the following workflow format:\n",
        "                  Question: the input task you must solve\n",
        "                  Thought: you should always think about what to do\n",
        "                  Action: the action to take which can be any of the following:\n",
        "                            - break it into smaller steps if needed\n",
        "                            - see if you can answer the given task with your trained knowledge\n",
        "                            - call the most relevant tools at your disposal mentioned below in case you need more information\n",
        "                  Action Input: the input to the action\n",
        "                  Observation: the result of the action\n",
        "                  ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "                  Thought: I now know the final answer\n",
        "                  Final Answer: the final answer to the original input question\n",
        "\n",
        "                Tools at your disposal to perform tasks as needed:\n",
        "                  - get_weather: whenever user asks get the weather of a place.\n",
        "                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\n",
        "             \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
        "        (\"human\", \"{query}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_template.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlJwVepDmsZw"
      },
      "source": [
        "Now, we can initalize the agent with the LLM, the prompt, and the tools.\n",
        "\n",
        "The agent is responsible for taking in input and deciding what actions to take.\n",
        "\n",
        "REMEMBER the Agent does not execute those actions - that is done by the AgentExecutor\n",
        "\n",
        "Note that we are passing in the model `chatgpt`, not `chatgpt_with_tools`.\n",
        "\n",
        "That is because `create_tool_calling_agent` will call `.bind_tools` for us under the hood.\n",
        "\n",
        "This should ideally be used with an LLM which supports tool \\ function calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "u4NMA82HpueH"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = [search_web_extract_info, get_weather]\n",
        "agent = create_tool_calling_agent(chatgpt, tools, prompt_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiL70NCrmkkW"
      },
      "source": [
        "Finally, we combine the `agent` (the brains) with the `tools` inside the `AgentExecutor` (which will repeatedly call the agent and execute tools)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vAuGe5G5pugJ"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent,\n",
        "                               tools=tools,\n",
        "                               early_stopping_method='force',\n",
        "                               max_iterations=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "OXqgT0Yth892",
        "outputId": "deb88704-907a-4a18-fa21-02e0c69d05d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"As of my last update, Nvidia's Q4 2024 earnings call has not occurred, as my data only goes up to October 2023. Therefore, I cannot provide specific details about the call. However, I can offer guidance on what typically might be discussed in such an earnings call:\\n\\n1. **Financial Performance**: Discussion of revenue, net income, and earnings per share compared to previous quarters and the same quarter in the previous year.\\n\\n2. **Segment Performance**: Insights into how different business segments, such as gaming, data center, professional visualization, and automotive, have performed.\\n\\n3. **Market Trends**: Commentary on market conditions affecting Nvidia's business, such as demand for GPUs, AI advancements, and competition.\\n\\n4. **Product Updates**: Announcements or updates on new products, technologies, or partnerships.\\n\\n5. **Guidance**: Forward-looking statements regarding expectations for the next quarter or fiscal year, including revenue projections and strategic priorities.\\n\\n6. **Q&A Session**: Responses to analysts' questions, which often provide deeper insights into the company's strategy and market outlook.\\n\\nFor the most accurate and up-to-date information, I recommend checking Nvidia's investor relations website or financial news sources for the official earnings call transcript and summary.\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"\"\"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\"\"\n",
        "response = chatgpt.invoke(query)\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07nRAXEwY7Ea",
        "outputId": "0510692b-15ea-42dd-a52d-9957f939f8b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 4/5 [00:05<00:01,  1.42s/it]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "100%|██████████| 5/5 [00:10<00:00,  2.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.databricks.com/blog/azure-databricks-guide-data-ai-summit-2023-featuring-akamai-providence-health-services-abn - 'NoneType' object has no attribute 'strip'\n"
          ]
        }
      ],
      "source": [
        "query = \"\"\"Summarize key points discussed in Databricks Latest Summit\"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne8x7JqGPMmf",
        "outputId": "55f31718-3876-4385-976b-fa8e1a9eb57c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Summarize key points discussed in Databricks Latest Summit',\n",
              " 'output': \"The Databricks Data + AI Summit 2023 focused on several key themes and announcements:\\n\\n1. **Generative AI and Lakehouse AI**: Databricks introduced new tools and features to simplify the development of large language model (LLM) applications within the Databricks Lakehouse Platform. Key features include LakehouseIQ, an AI-powered knowledge engine, and Databricks Assistant, an AI-based companion for code and query generation.\\n\\n2. **Unity Catalog Enhancements**: New features in Unity Catalog were announced to improve data governance and metadata management, including Lakehouse Federation capabilities for accessing and analyzing data across multiple sources, and AI Governance features for managing AI/ML assets.\\n\\n3. **Data Sharing and Collaboration**: Databricks enhanced data sharing capabilities with the introduction of Databricks Marketplace, Lakehouse Apps, and Delta Sharing, allowing for secure data sharing and collaboration across platforms.\\n\\n4. **Data Development Improvements**: New features were introduced to improve performance and usability, such as the English SDK for Apache Spark, Delta Lake 3.0 with a universal format, and Project Lightspeed for enhanced streaming capabilities.\\n\\n5. **Acquisition of MosaicML**: Databricks announced the acquisition of MosaicML, a platform for training large language models, to enhance its generative AI capabilities.\\n\\n6. **Governance and AI for Governance**: Databricks emphasized unified governance across data and AI, with new features in Unity Catalog and Lakehouse Monitoring for enhanced observability and governance.\\n\\nThese advancements highlight Databricks' commitment to democratizing AI and analytics, improving data governance, and enhancing collaboration and data sharing capabilities.\"}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "H2_MM2jrPRya",
        "outputId": "11c6065b-3c22-4509-e643-f2e97e1ab370"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The Databricks Data + AI Summit 2023 focused on several key themes and announcements:\n",
              "\n",
              "1. **Generative AI and Lakehouse AI**: Databricks introduced new tools and features to simplify the development of large language model (LLM) applications within the Databricks Lakehouse Platform. Key features include LakehouseIQ, an AI-powered knowledge engine, and Databricks Assistant, an AI-based companion for code and query generation.\n",
              "\n",
              "2. **Unity Catalog Enhancements**: New features in Unity Catalog were announced to improve data governance and metadata management, including Lakehouse Federation capabilities for accessing and analyzing data across multiple sources, and AI Governance features for managing AI/ML assets.\n",
              "\n",
              "3. **Data Sharing and Collaboration**: Databricks enhanced data sharing capabilities with the introduction of Databricks Marketplace, Lakehouse Apps, and Delta Sharing, allowing for secure data sharing and collaboration across platforms.\n",
              "\n",
              "4. **Data Development Improvements**: New features were introduced to improve performance and usability, such as the English SDK for Apache Spark, Delta Lake 3.0 with a universal format, and Project Lightspeed for enhanced streaming capabilities.\n",
              "\n",
              "5. **Acquisition of MosaicML**: Databricks announced the acquisition of MosaicML, a platform for training large language models, to enhance its generative AI capabilities.\n",
              "\n",
              "6. **Governance and AI for Governance**: Databricks emphasized unified governance across data and AI, with new features in Unity Catalog and Lakehouse Monitoring for enhanced observability and governance.\n",
              "\n",
              "These advancements highlight Databricks' commitment to democratizing AI and analytics, improving data governance, and enhancing collaboration and data sharing capabilities."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "riHUt00KE_3q",
        "outputId": "23717c5a-f5b4-48a2-bf15-947526b37281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 4/5 [00:03<00:00,  1.37it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.databricks.com/blog/azure-databricks-guide-data-ai-summit-2023-featuring-akamai-providence-health-services-abn - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The Databricks Data + AI Summit 2023 focused on several key themes and announcements:\n",
              "\n",
              "1. **Generative AI and Lakehouse AI**: Databricks introduced new tools and features to simplify the development and deployment of large language models (LLMs) within the Databricks Lakehouse Platform. Key features include LakehouseIQ, an AI-powered knowledge engine, and Databricks Assistant, an AI-based companion for code and query generation.\n",
              "\n",
              "2. **Unity Catalog Enhancements**: New features in Unity Catalog were announced to improve data governance and metadata management, including Lakehouse Federation capabilities for accessing and analyzing data across multiple sources, and AI Governance features for managing AI/ML assets.\n",
              "\n",
              "3. **Data Sharing and Collaboration**: Databricks enhanced data sharing capabilities with the introduction of Databricks Marketplace, Lakehouse Apps, and Delta Sharing, allowing for secure data sharing and collaboration across platforms.\n",
              "\n",
              "4. **Data Development Improvements**: New features were introduced to improve performance and usability, such as the English SDK for Apache Spark, Delta Lake 3.0 with a universal format, and Project Lightspeed for enhanced streaming capabilities.\n",
              "\n",
              "5. **AI and Machine Learning Innovations**: Databricks announced Lakehouse AI, which includes vector search and model serving capabilities, and MLflow 2.5 for managing LLM operations. The acquisition of MosaicML was also highlighted to enhance generative AI capabilities.\n",
              "\n",
              "6. **Governance and Monitoring**: New governance features were introduced, including Lakehouse Monitoring for data quality and integrity, and enhanced observability features for better data management.\n",
              "\n",
              "Overall, the summit emphasized democratizing AI and analytics, improving data governance, and enhancing collaboration and data sharing capabilities within the Databricks ecosystem."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"Summarize key points discussed in Snowflake Latest Summit\"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "GfBHtCzJFKdb",
        "outputId": "383a447a-bc43-401b-921a-a5a36ff8882b"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "To provide a meaningful answer to your question about which company's future outlook looks better, I would need more specific information. Could you please specify which companies you are interested in comparing?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"\"\"which company's future outlook looks to be better?\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQQAx3B7xrl-"
      },
      "source": [
        "The agent is doing pretty well but unfortunately it doesn't remember conversations. We will use some user-session based memory to store this and dive deeper into this in the next video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw9mxPskx734"
      },
      "source": [
        "## Build and Test Multi-User Conversational AI Agent\n",
        "\n",
        "We will now use `SQLChatMessageHistory` which we learnt in the previous module to store separate conversation histories per user or session.\n",
        "\n",
        "This will help us build a conversational Agentic Chatbot which will be accessed by many users at the same time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUG09xD5zd2N",
        "outputId": "d3a5e771-912b-43a4-80b8-0342783dbe54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'memory.db': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# removes the memory database file - usually not needed\n",
        "# you can run this only when you want to remove ALL conversation histories\n",
        "# ok if you get rm: cannot remove 'memory.db': No such file or directory  because initially no memory exists\n",
        "# !rm memory.db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_XSzUrlyZyFF"
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "# used to retrieve conversation history from database\n",
        "# based on a specific user or session ID\n",
        "def get_session_history_db(session_id):\n",
        "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
        "\n",
        "# create a conversation chain + agent which can load memory based on specific user or session id\n",
        "agentic_chatbot = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_session_history_db,\n",
        "    input_messages_key=\"query\",\n",
        "    history_messages_key=\"history\",\n",
        ")\n",
        "\n",
        "# function to call the agent show results per user session\n",
        "from IPython.display import display, Markdown\n",
        "def chat_with_agent(prompt: str, session_id: str):\n",
        "    response = agentic_chatbot.invoke({\"query\": prompt},\n",
        "                                      {'configurable': { 'session_id': session_id}})\n",
        "    display(Markdown(response['output']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYTNL_iJ6ibC"
      },
      "source": [
        "Let's now simulate User 1 using the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "irMU68Ds0NTm",
        "outputId": "0d251ab7-5e47-4149-b562-2c25b88afbd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [00:01<00:01,  1.50it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            " 80%|████████  | 4/5 [00:05<00:01,  1.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.databricks.com/blog/azure-databricks-guide-data-ai-summit-2023-featuring-akamai-providence-health-services-abn - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.kenwayconsulting.com/blog/databricks-data-ai-world-tour-2023-conference-highlights/ - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The Databricks Data + AI Summit 2023 focused on several key themes and innovations:\n",
              "\n",
              "1. **Generative AI**: Databricks introduced new tools and features to simplify the development of large language model (LLM) applications within the Databricks Lakehouse Platform. Key features include LakehouseIQ, Databricks Assistant, and Lakehouse AI, which enable building AI models directly on the Data Lakehouse.\n",
              "\n",
              "2. **Unity Catalog Enhancements**: New features were announced to simplify data management and governance, including Lakehouse Federation Capabilities, AI Governance, and Lakehouse Monitoring and Observability.\n",
              "\n",
              "3. **Data Sharing and Collaboration**: Databricks enhanced its data sharing capabilities with the introduction of Databricks Marketplace, Lakehouse Apps, and Delta Sharing, allowing for efficient data collaboration and sharing.\n",
              "\n",
              "4. **Data Development Improvements**: New features like the English SDK for Apache Spark, Delta Lake 3.0, and Project Lightspeed were introduced to improve performance, compatibility, and scalability in data development.\n",
              "\n",
              "5. **Governance and AI**: Databricks emphasized unified governance across data and AI, with new features in Unity Catalog and Lakehouse Federation to manage data and AI assets effectively.\n",
              "\n",
              "6. **Lakehouse Collaboration**: Delta Sharing and Databricks Marketplace were highlighted as key features for cross-platform collaboration and data sharing.\n",
              "\n",
              "Overall, the summit showcased Databricks' commitment to innovation in AI and data management, aiming to democratize AI and enhance data-driven decision-making across organizations."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_id = 'john001'\n",
        "prompt = \"Summarize key points discussed in Databricks Latest Summit\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "XT4vtvku0TBW",
        "outputId": "34930943-0543-4f06-bb55-04ab680cca5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [00:03<00:02,  1.15s/it]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.databricks.com/blog/whats-new-unity-catalog-data-and-ai-summit-2023 - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "At the Databricks Data + AI Summit 2023, Intel's involvement was highlighted through their collaboration with Databricks to enhance AI and data processing capabilities. Intel's focus was on optimizing performance and efficiency for AI workloads, leveraging their hardware advancements to support Databricks' Lakehouse Platform. This partnership aims to accelerate data processing and AI model training, providing users with improved computational power and efficiency. The collaboration underscores Intel's commitment to advancing AI technologies and supporting data-driven innovations in partnership with leading data platforms like Databricks."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = \"What about Intel?\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "u-sz15g8YGNA",
        "outputId": "73eec36b-8363-4ddb-a8c8-a9a9c5396153"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "To determine which company, between Databricks and Intel, is doing better, we would need to consider various factors such as financial performance, market position, innovation, partnerships, and overall impact in their respective industries. \n",
              "\n",
              "1. **Databricks**: \n",
              "   - **Innovation and Growth**: Databricks has been at the forefront of data and AI innovation, particularly with its Lakehouse Platform, which combines data warehousing and AI capabilities. The company's focus on generative AI and data governance has positioned it as a leader in the data analytics space.\n",
              "   - **Market Position**: Databricks has seen significant growth and investment, with a strong presence in the cloud data platform market. Its partnerships and integrations with major cloud providers enhance its market reach.\n",
              "\n",
              "2. **Intel**: \n",
              "   - **Technological Advancements**: Intel continues to be a leader in semiconductor manufacturing and computing technology. Its focus on AI and data processing capabilities, as seen in collaborations with companies like Databricks, highlights its commitment to staying relevant in the AI and data processing sectors.\n",
              "   - **Market Challenges**: Intel faces competition from other semiconductor companies like AMD and NVIDIA, which have also made significant strides in AI and data processing technologies.\n",
              "\n",
              "To provide a more precise assessment, I would need to look at recent financial reports, market analyses, and industry trends. If you would like, I can search for the latest information on both companies to provide a more detailed comparison. Would you like me to do that?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = \"Which company seems to be doing better?\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4zIlISy6m-x"
      },
      "source": [
        "Let's now simulate User 2 using the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "ta1RUF_81RxX",
        "outputId": "c2996859-5fe7-4ef1-bd21-0ee5257afc93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling weather tool\n",
            "Calling web search tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2/5 [00:02<00:03,  1.16s/it]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.freepressjournal.in/india/bengaluru-weather-update-for-july-16 - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            " 80%|████████  | 4/5 [00:03<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.easeweather.com/asia/india/karnataka/bangalore-urban/bengaluru/july - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "100%|██████████| 5/5 [00:04<00:00,  1.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting from url: https://www.weather25.com/asia/india/karnataka/bangalore?page=month&month=July - 'NoneType' object has no attribute 'strip'\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The weather in Bangalore today is as follows:\n",
              "\n",
              "- **Temperature**: The minimum temperature is around 21°C, and the maximum temperature is expected to reach 28°C.\n",
              "- **Weather Condition**: Rain is expected throughout the day.\n",
              "- **Humidity**: The humidity level is at 82%.\n",
              "- **Pressure**: Atmospheric pressure is at 1009 hPa.\n",
              "- **Wind**: The wind speed is around 6.48 km/h, coming from 257 degrees with gusts up to 10.33 km/h.\n",
              "- **Sunrise and Sunset**: The sun rises at 06:02 AM and sets at 06:50 PM.\n",
              "\n",
              "The air quality index in Bangalore is satisfactory, with PM2.5 at 67 and PM10 at 38.\n",
              "\n",
              "This information provides a detailed overview of the current weather conditions in Bangalore."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"how is the weather in Bangalore today? Show detailed statistics\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "vfn_Wxxg42rZ",
        "outputId": "c695b4fc-0d20-44f8-bfa4-646ac682c9f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling weather tool\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "I couldn't retrieve the weather data for Dubai at the moment. There might be an issue with accessing the weather information for that location. You might want to try checking a reliable weather website or app for the latest updates."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"what about Dubai?\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "I7jjxtmz6Qzi",
        "outputId": "34323085-f10f-4552-a919-98382dc8a812"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Dubai is currently hotter than Bangalore. The temperature in Dubai is 16.2°C (61.2°F), while in Bangalore, it is 18.3°C (64.9°F)."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"which city is hotter?\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
