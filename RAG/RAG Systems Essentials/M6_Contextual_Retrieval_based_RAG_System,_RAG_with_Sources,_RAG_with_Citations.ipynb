{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d9c7a4e-05e9-4b0a-8691-ba466831cf34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Reference Link:** [RAG Systems Essentials (Analytics Vidhya)](https://courses.analyticsvidhya.com/courses/take/rag-systems-essentials/lessons/60148017-hands-on-deep-dive-into-rag-evaluation-metrics-generator-metrics-i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "511d4c4a-6761-406c-bdee-eda6694c1953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jbw4wHV4zlKj"
   },
   "source": [
    "# Build a Contextual Retrieval based RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ee75c75-dde6-4d9f-8d24-1202ee70274f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4vtFl39Ofu_8"
   },
   "source": [
    "## Install OpenAI, and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa3743f1-d0cc-4874-ad54-acde53394a99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47847,
     "status": "ok",
     "timestamp": 1734093570014,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "LVX6450Lfu_9",
    "outputId": "fa37d3dc-eda1-42d7-87c3-46bd3a670017"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.10\n",
    "!pip install langchain-openai==0.2.12\n",
    "!pip install langchain-community==0.3.11\n",
    "!pip install jq==1.8.0\n",
    "!pip install pymupdf==1.25.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a9802fb-9a6e-4592-b2d2-5c77b268f549",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "bwUBYHjPfu_-"
   },
   "source": [
    "## Install Chroma Vector DB and LangChain wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4b48495-bd30-46b2-affd-6cbaae8ffa0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33712,
     "status": "ok",
     "timestamp": 1734093603723,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "p30SmCgTfu__",
    "outputId": "6606e56e-c58e-4f22-ed48-859c4ba66cbb"
   },
   "outputs": [],
   "source": [
    "!pip install langchain-chroma==0.1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54a26bf9-817e-4321-a865-571a4d195fa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EITC17hwfu__"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dcc003a-dd3a-48c1-bad4-d122f4a234ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6063,
     "status": "ok",
     "timestamp": 1734093609780,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "yEh2olNvfvAA",
    "outputId": "f70e61f9-5d9e-4231-a206-a188edd11861"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82ea6560-0f7d-44d0-89d1-5ade2814f0ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "pm_mx0v-fvAA"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a32be567-7b59-454a-b599-d174aa473122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1734093612694,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "Jhfb4gMUfvAC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba789046-b2ff-47a9-bae0-0e78c68c122b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jiokYxD8fvAC"
   },
   "source": [
    "### Open AI Embedding Models\n",
    "\n",
    "LangChain enables us to access Open AI embedding models which include the newest models: a smaller and highly efficient `text-embedding-3-small` model, and a larger and more powerful `text-embedding-3-large` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43e18cdf-1a8a-4c25-89f5-8caf9386e272",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 7059,
     "status": "ok",
     "timestamp": 1734093622010,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "-On4AS0HfvAD"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e647c27-646b-4f12-bf14-931089242329",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "afzeN_WkHIz2"
   },
   "source": [
    "## Loading and Processing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f85e3013-3ce1-4763-b0c7-9813e1f3ab9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RA_-hzHbFeSP"
   },
   "source": [
    "### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c17b468-b170-4a51-968e-08559ec78108",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZFMYH-yFhWn",
    "outputId": "9ed1bd5f-a2d7-463e-db22-06214ccad8a8"
   },
   "outputs": [],
   "source": [
    "# if you can't download using the following code\n",
    "# go to https://drive.google.com/file/d/1aZxZejfteVuofISodUrY2CDoyuPLYDGZ download it\n",
    "# manually upload it on colab\n",
    "!gdown 1aZxZejfteVuofISodUrY2CDoyuPLYDGZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4ea20ee-2064-46ac-96b0-51958af7bb74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwLEBC4nF9ly",
    "outputId": "2369aa8c-de53-462b-ebd5-5b9404841bd7"
   },
   "outputs": [],
   "source": [
    "!unzip rag_docs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5b9fdf6-0876-4257-871e-96984b264017",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "wMlxKZ_5jIdE"
   },
   "source": [
    "### Load and Process JSON Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "895f9347-dd8c-4c87-aeeb-d295ecd78857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RZ5y0NfzHPhg"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "\n",
    "loader = JSONLoader(file_path='./rag_docs/wikidata_rag_demo.jsonl',\n",
    "                    jq_schema='.',\n",
    "                    text_content=False,\n",
    "                    json_lines=True)\n",
    "wiki_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89abc3fa-1702-40a7-acdf-1d5e73ac22c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4E1zYFSG7J-",
    "outputId": "32080ed1-8b19-405a-ffed-ec759522c284"
   },
   "outputs": [],
   "source": [
    "len(wiki_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "551a591a-11ee-409d-b50b-4f6e4878da1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSbhERAyGw0v",
    "outputId": "c03689eb-8ad3-44c9-8553-71c7439f961c"
   },
   "outputs": [],
   "source": [
    "wiki_docs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b41e98dc-ecf9-49a3-a658-779bc02ab525",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "yICyAF85h2DO"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.docstore.document import Document\n",
    "wiki_docs_processed = []\n",
    "\n",
    "for doc in wiki_docs:\n",
    "    doc = json.loads(doc.page_content)\n",
    "    metadata = {\n",
    "        \"title\": doc['title'],\n",
    "        \"id\": doc['id'],\n",
    "        \"source\": \"Wikipedia\",\n",
    "        \"page\": 1\n",
    "    }\n",
    "    data = ' '.join(doc['paragraphs'])\n",
    "    wiki_docs_processed.append(Document(page_content=data, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f9bd62a-4c6a-4eee-88a7-98376feb36c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IATrHWKh7II",
    "outputId": "08d4cc81-b8f4-4a33-ac6c-6ff33febd933"
   },
   "outputs": [],
   "source": [
    "wiki_docs_processed[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "103d1d15-622b-43de-9102-c0634fa4a782",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "F_GzvHP1jSBo"
   },
   "source": [
    "### Load and Process PDF documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "670bbc95-71bb-4f2e-9a9a-2884558cef2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4vH6xGFOnv7m"
   },
   "source": [
    "#### Create Chunk Contexts for Contextual Retrieval\n",
    "\n",
    "![](https://i.imgur.com/LRhKHzk.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d29d07f0-a862-4a05-895a-3412ddb75646",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jxHHyhlbl_9j"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d9ad252-5a75-45ec-a2bd-c84696124ba7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MHSh0Vg-mIUv"
   },
   "outputs": [],
   "source": [
    "# create chunk context generation chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "\n",
    "def generate_chunk_context(document, chunk):\n",
    "\n",
    "    chunk_process_prompt = \"\"\"You are an AI assistant specializing in research paper analysis.\n",
    "                            Your task is to provide brief, relevant context for a chunk of text\n",
    "                            based on the following research paper.\n",
    "\n",
    "                            Here is the research paper:\n",
    "                            <paper>\n",
    "                            {paper}\n",
    "                            </paper>\n",
    "\n",
    "                            Here is the chunk we want to situate within the whole document:\n",
    "                            <chunk>\n",
    "                            {chunk}\n",
    "                            </chunk>\n",
    "\n",
    "                            Provide a concise context (3-4 sentences max) for this chunk,\n",
    "                            considering the following guidelines:\n",
    "\n",
    "                            - Give a short succinct context to situate this chunk within the overall document\n",
    "                            for the purposes of improving search retrieval of the chunk.\n",
    "                            - Answer only with the succinct context and nothing else.\n",
    "                            - Context should be mentioned like 'Focuses on ....'\n",
    "                            do not mention 'this chunk or section focuses on...'\n",
    "\n",
    "                            Context:\n",
    "                        \"\"\"\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_template(chunk_process_prompt)\n",
    "\n",
    "    agentic_chunk_chain = (prompt_template\n",
    "                                |\n",
    "                            chatgpt\n",
    "                                |\n",
    "                            StrOutputParser())\n",
    "\n",
    "    context = agentic_chunk_chain.invoke({'paper': document, 'chunk': chunk})\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94933dc1-8dc5-4ac9-89b3-b5bc14b4e2a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-uxOSfcsxqHD"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import uuid\n",
    "\n",
    "def create_contextual_chunks(file_path, chunk_size=3500, chunk_overlap=0):\n",
    "\n",
    "    print('Loading pages:', file_path)\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    doc_pages = loader.load()\n",
    "\n",
    "    print('Chunking pages:', file_path)\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,\n",
    "                                              chunk_overlap=chunk_overlap)\n",
    "    doc_chunks = splitter.split_documents(doc_pages)\n",
    "\n",
    "    print('Generating contextual chunks:', file_path)\n",
    "    original_doc = '\\n'.join([doc.page_content for doc in doc_chunks])\n",
    "    contextual_chunks = []\n",
    "    for chunk in doc_chunks:\n",
    "        chunk_content = chunk.page_content\n",
    "        chunk_metadata = chunk.metadata\n",
    "        chunk_metadata_upd = {\n",
    "            'id': str(uuid.uuid4()),\n",
    "            'page': chunk_metadata['page'],\n",
    "            'source': chunk_metadata['source'],\n",
    "            'title': chunk_metadata['source'].split('/')[-1]\n",
    "        }\n",
    "        context = generate_chunk_context(original_doc, chunk_content)\n",
    "        contextual_chunks.append(Document(page_content=context+'\\n'+chunk_content,\n",
    "                                          metadata=chunk_metadata_upd))\n",
    "    print('Finished processing:', file_path)\n",
    "    print()\n",
    "    return contextual_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8381d2dd-819f-48c4-8539-0f9e6827b893",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-VUpdmczt0C",
    "outputId": "efe8db0c-6e47-464e-926f-2c993314d190"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "pdf_files = glob('./rag_docs/*.pdf')\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cb1e827-be87-4eff-b217-04245893c320",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsicBMPazzlg",
    "outputId": "8b567e07-d403-4ae6-d13b-98d02b0a24b8"
   },
   "outputs": [],
   "source": [
    "paper_docs = []\n",
    "for fp in pdf_files:\n",
    "    paper_docs.extend(create_contextual_chunks(file_path=fp, chunk_size=3500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de4db7a5-89d0-42d4-a89f-245af5d6dd8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOkwPMxp0gFh",
    "outputId": "6913c904-ac84-4281-d05f-5479f44f3c64"
   },
   "outputs": [],
   "source": [
    "len(paper_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8489d106-71d3-497b-8530-108852dc930e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVK2i0lR0ieV",
    "outputId": "da507bde-09e6-4f76-9e49-c62d545072c4"
   },
   "outputs": [],
   "source": [
    "paper_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f52129d-e3b1-4acb-99a7-ddaf16d5105d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "UyPdlZo2xEly"
   },
   "source": [
    "### Combine all document chunks in one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f3a92f1-e4ff-4281-aa99-936291482381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbtpR-r50mEn",
    "outputId": "7dd4d35d-fafd-4fff-ddf0-8351819b501e"
   },
   "outputs": [],
   "source": [
    "len(wiki_docs_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13773c08-231e-4a90-9dda-0db44c8a70ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNQWgq9t0pMH",
    "outputId": "58ca4c0c-18b4-4fbc-a77c-800e835a3610"
   },
   "outputs": [],
   "source": [
    "total_docs = wiki_docs_processed + paper_docs\n",
    "len(total_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df189d06-3a49-4c69-a737-d682fbd35993",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Daqn6Hglw9Nk"
   },
   "source": [
    "## Index Document Chunks and Embeddings in Vector DB\n",
    "\n",
    "Here we initialize a connection to a Chroma vector DB client, and also we want to save to disk, so we simply initialize the Chroma client and pass the directory where we want the data to be saved to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31d7f729-8519-4c7f-a0b3-9af53c716972",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ZhAQyrFBfvAN"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# create vector DB of docs and embeddings - takes < 30s on Colab\n",
    "chroma_db = Chroma.from_documents(documents=total_docs,\n",
    "                                  collection_name='my_context_db',\n",
    "                                  embedding=openai_embed_model,\n",
    "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
    "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
    "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "                                  persist_directory=\"./my_context_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b14ba19-d0c2-4a20-9d6f-f161d9dc67ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9ju_zBIj1Zsb"
   },
   "source": [
    "### Load Vector DB from disk\n",
    "\n",
    "This is just to show once you have a vector database on disk you can just load and create a connection to it anytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cf99110-3f57-4889-a373-3f00c39cf886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "pNvj0dDH1WDg"
   },
   "outputs": [],
   "source": [
    "# load from disk\n",
    "chroma_db = Chroma(persist_directory=\"./my_context_db\",\n",
    "                   collection_name='my_context_db',\n",
    "                   embedding_function=openai_embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d6c5a65-accf-492e-8c6f-44622874f2ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFC3uPqYop0a",
    "outputId": "ac8bd549-18a9-46af-f804-2a4ca5e0d192"
   },
   "outputs": [],
   "source": [
    "chroma_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db42690f-54c4-4499-811f-46e045d8fa08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "njfZOOVZxj1a"
   },
   "source": [
    "### Semantic Similarity based Retrieval\n",
    "\n",
    "We use simple cosine similarity here and retrieve the top 5 similar documents based on the user input query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0645cdf7-8a76-4af9-8ecf-0e36cceb0351",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tV1l6HYdxj1b"
   },
   "outputs": [],
   "source": [
    "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity\",\n",
    "                                              search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3665dfa3-ed5b-49e2-b384-562839a26364",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "nUIJG_bDxj1c"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_docs(docs):\n",
    "    for doc in docs:\n",
    "        print('Metadata:', doc.metadata)\n",
    "        print('Content Brief:')\n",
    "        display(Markdown(doc.page_content[:1000]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1ea3461-71ee-4379-b8b7-227bdc137b36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "PIh4xGv2xj1c",
    "outputId": "f8b431ff-094d-49ab-9bcd-e2c9aae2a632"
   },
   "outputs": [],
   "source": [
    "query = \"what is machine learning?\"\n",
    "top_docs = similarity_retriever.invoke(query)\n",
    "display_docs(top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "617b9cfa-8c5e-4768-accf-8fa9bd331afb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S_PXFMcJxuyO",
    "outputId": "5133bece-a361-4543-9214-1c80fe673353"
   },
   "outputs": [],
   "source": [
    "query = \"what is the difference between transformers and vision transformers?\"\n",
    "top_docs = similarity_retriever.invoke(query)\n",
    "display_docs(top_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce5f57a8-1dd4-463b-9365-6aaa6f7b8d89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gQFWv7YUyVII"
   },
   "source": [
    "## Build the RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d10766e-dd78-4f26-a2ec-2b7cad04e2bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PHOrfGXKyVIJ"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n",
    "                Answer the following question using only the following pieces of retrieved context.\n",
    "                If the answer is not in the context, do not make up answers, just say that you don't know.\n",
    "                Keep the answer detailed and well formatted based on the information from the context.\n",
    "\n",
    "                Question:\n",
    "                {question}\n",
    "\n",
    "                Context:\n",
    "                {context}\n",
    "\n",
    "                Answer:\n",
    "            \"\"\"\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5115713e-d82f-4e71-9b0c-c7b987572304",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "KmWeCB4yyVIJ"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_rag_chain = (\n",
    "    {\n",
    "        \"context\": (similarity_retriever\n",
    "                      |\n",
    "                    format_docs),\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "      |\n",
    "    rag_prompt_template\n",
    "      |\n",
    "    chatgpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b70135d-9961-4aad-b962-e473a15e729f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "xvj_eGIWyVIJ",
    "outputId": "1320207b-c57a-4e08-f755-0f050045884b"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "query = \"What is machine learning?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "397c3ac8-a7ef-49e1-bc26-21f28be3b8f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "id": "pXtezDlZzadt",
    "outputId": "747fbcca-5fcc-40f4-d903-2d70b334444d"
   },
   "outputs": [],
   "source": [
    "query = \"What is a CNN?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ad86ca4-2186-424e-8bbb-babeb38eed95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "Fo92-ZmIELPF",
    "outputId": "1c1cc31c-8ea4-4310-9975-8cee615f3f0e"
   },
   "outputs": [],
   "source": [
    "query = \"How is a resnet better than a CNN?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f282e43-805e-475b-8d64-3ca0da964264",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "J5IQoBc0zlAr",
    "outputId": "4ce7096b-f5b8-442b-b9c5-00bbe5e7a360"
   },
   "outputs": [],
   "source": [
    "query = \"What is NLP and its relation to linguistics?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e86dbf88-4d90-4b57-a7ff-ebeca5f0908d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "AzeZuG1hzvGy",
    "outputId": "ca55a840-f295-413f-d01a-54bc383e6b4b"
   },
   "outputs": [],
   "source": [
    "query = \"What is the difference between AI, ML and DL?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04348cde-80a6-4a9e-91d3-fc000580caad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "cWihDiL3zPzY",
    "outputId": "b8b3a24f-b11c-424d-efcd-6d5530148d15"
   },
   "outputs": [],
   "source": [
    "query = \"What is the difference between transformers and vision transformers?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bae4f0a-6bdd-4a38-85c9-fb9b648d6515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "k1lqzejlEvsj",
    "outputId": "a21b4676-1ccb-477a-b2c6-4b6bda910171"
   },
   "outputs": [],
   "source": [
    "query = \"How is self-attention important in transformers?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1485c25-1c09-4dec-9ed0-4fff96c5a43b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "7Zf_BjmlFBcb",
    "outputId": "97aa2758-d215-4fe3-8f5a-a4fa2a1b56c2"
   },
   "outputs": [],
   "source": [
    "query = \"How does a resnet work?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62102724-ea20-4258-86a1-e25124454737",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "UbaUpVXKz8IK",
    "outputId": "7a4dc86a-91e4-458b-97bc-91b0595d7009"
   },
   "outputs": [],
   "source": [
    "query = \"What is LangGraph?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69d23f35-ae33-4596-9f25-89b397539f19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "FmxNo6B50AdP",
    "outputId": "25797c69-e76e-4a30-cab3-334e0fd18178"
   },
   "outputs": [],
   "source": [
    "query = \"What is an Agentic AI System?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f84a2a81-72b1-410c-a32b-814212d1477c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "Ttz53mEy0J_D",
    "outputId": "da8bcee5-d16e-4638-9ed8-06987aba9ccf"
   },
   "outputs": [],
   "source": [
    "query = \"What is LangChain?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4494a92c-986c-43cb-bbc2-a394d4af378f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-HkUAnWFH8LA"
   },
   "source": [
    "# Build a RAG System with Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "406278fc-babb-4f13-a8ed-b883b2c8e81e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cd9CWH6hH8LB"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n",
    "                Answer the following question using only the following pieces of retrieved context.\n",
    "                If the answer is not in the context, do not make up answers, just say that you don't know.\n",
    "                Keep the answer detailed and well formatted based on the information from the context.\n",
    "\n",
    "                Question:\n",
    "                {question}\n",
    "\n",
    "                Context:\n",
    "                {context}\n",
    "\n",
    "                Answer:\n",
    "            \"\"\"\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be22b143-33b4-4ebc-8535-41764dbdcd94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "m6wFtKQqXNHE"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "src_rag_response_chain = (\n",
    "    {\n",
    "        \"context\": (itemgetter('context')\n",
    "                        |\n",
    "                    RunnableLambda(format_docs)),\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "        |\n",
    "    rag_prompt_template\n",
    "        |\n",
    "    chatgpt\n",
    "        |\n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_w_sources = (\n",
    "    {\n",
    "        \"context\": similarity_retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "        |\n",
    "    RunnablePassthrough.assign(response=src_rag_response_chain)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd9ac750-7a8f-480f-8301-9aa016c750f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYfU-VdjYf1u",
    "outputId": "ad1b6c91-065b-41e3-d6d2-92085cf786d0"
   },
   "outputs": [],
   "source": [
    "query = \"What is machine learning?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63dbbdba-97f7-4f96-a564-6bc0a6304032",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2wWdkU4oa1BD"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_results(result_obj):\n",
    "    print('Query:')\n",
    "    display(Markdown(result_obj['question']))\n",
    "    print()\n",
    "    print('Response:')\n",
    "    display(Markdown(result_obj['response']))\n",
    "    print('='*50)\n",
    "    print('Sources:')\n",
    "    for source in result_obj['context']:\n",
    "        print('Metadata:', source.metadata)\n",
    "        print('Content Brief:')\n",
    "        display(Markdown(source.page_content))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7338852-e3c7-4e89-92c3-f51c36d6839a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8NTfGcChbFuj",
    "outputId": "7687d1b3-efc7-442d-c9dd-819e4f0a907f"
   },
   "outputs": [],
   "source": [
    "query = \"What is machine learning?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3acad20-7c95-458d-9ccd-e5c4c2dfabe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jhWbcmodbYfy",
    "outputId": "83c9b9bc-2e9c-4f99-e90d-7cdafbc665a7"
   },
   "outputs": [],
   "source": [
    "query = \"What is the difference between AI, ML and DL?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27785ef4-b805-4bae-9e96-4f7a9c64db9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iKggz7qfYkh1",
    "outputId": "6e2076f9-cf61-4466-fa18-fd2a8de09da7"
   },
   "outputs": [],
   "source": [
    "query = \"What is the difference between transformers and vision transformers?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a82fe8a5-27dd-472a-8cc1-02614f5da873",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873
    },
    "id": "fCCvcwzEbqQq",
    "outputId": "62128376-aa6e-4290-c7bd-6e198ff8e362"
   },
   "outputs": [],
   "source": [
    "query = \"What is an Agentic AI System?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18ce6b76-4f79-4cfc-8307-16db179ed007",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "25Si_mSAc9HY"
   },
   "source": [
    "# Build a RAG System with Source Citations Agentic Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2858f33-5458-4178-b56a-8a98c356c3f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3cKwTUIc9HZ",
    "outputId": "2ca7b70c-cae1-4e73-c20a-653354a1c315"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n",
    "                Answer the following question using only the following pieces of retrieved context.\n",
    "                If the answer is not in the context, do not make up answers, just say that you don't know.\n",
    "                Keep the answer detailed and well formatted based on the information from the context.\n",
    "\n",
    "                Question:\n",
    "                {question}\n",
    "\n",
    "                Context:\n",
    "                {context}\n",
    "\n",
    "                Answer:\n",
    "            \"\"\"\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)\n",
    "rag_prompt_template.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "415438a3-2704-4247-9452-33d22b38b596",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fbhOllRprRx",
    "outputId": "26e90a30-253c-4220-adf7-20269e9dc4e2"
   },
   "outputs": [],
   "source": [
    "citations_prompt = \"\"\"You are an assistant who is an expert in analyzing answers to questions\n",
    "                      and finding out referenced citations from context articles.\n",
    "\n",
    "                      Given the following question, context and generated answer,\n",
    "                      analyze the generated answer and quote citations from context articles\n",
    "                      that can be used to justify the generated answer.\n",
    "\n",
    "                      Question:\n",
    "                      {question}\n",
    "\n",
    "                      Context Articles:\n",
    "                      {context}\n",
    "\n",
    "                      Answer:\n",
    "                      {answer}\n",
    "                  \"\"\"\n",
    "\n",
    "cite_prompt_template = ChatPromptTemplate.from_template(citations_prompt)\n",
    "cite_prompt_template.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5e03838-82e8-4d4c-826f-f0f2551384a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "n-ehwnM4dyGV"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    id: str = Field(description=\"\"\"The string ID of a SPECIFIC context article\n",
    "                                   which justifies the answer.\"\"\")\n",
    "    source: str = Field(description=\"\"\"The source of the SPECIFIC context article\n",
    "                                       which justifies the answer.\"\"\")\n",
    "    title: str = Field(description=\"\"\"The title of the SPECIFIC context article\n",
    "                                      which justifies the answer.\"\"\")\n",
    "    page: int = Field(description=\"\"\"The page number of the SPECIFIC context article\n",
    "                                     which justifies the answer.\"\"\")\n",
    "    quotes: str = Field(description=\"\"\"The VERBATIM sentences from the SPECIFIC context article\n",
    "                                      that are used to generate the answer.\n",
    "                                      Should be exact sentences from context article without missing words.\"\"\")\n",
    "\n",
    "\n",
    "class QuotedCitations(BaseModel):\n",
    "    \"\"\"Quote citations from given context articles\n",
    "       that can be used to justify the generated answer. Can be multiple articles.\"\"\"\n",
    "    citations: List[Citation] = Field(description=\"\"\"Citations (can be multiple) from the given\n",
    "                                                     context articles that justify the answer.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8ceeb3e-1ddd-4f36-86c1-17d2a5eda937",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "haxp_9LmjVp1"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "structured_chatgpt = chatgpt.with_structured_output(QuotedCitations)\n",
    "\n",
    "\n",
    "def format_docs_with_metadata(docs: List[Document]) -> str:\n",
    "    formatted_docs = [\n",
    "        f\"\"\"Context Article ID: {doc.metadata['id']}\n",
    "            Context Article Source: {doc.metadata['source']}\n",
    "            Context Article Title: {doc.metadata['title']}\n",
    "            Context Article Page: {doc.metadata['page']}\n",
    "            Context Article Details: {doc.page_content}\n",
    "         \"\"\"\n",
    "            for i, doc in enumerate(docs)\n",
    "    ]\n",
    "    return \"\\n\\n\" + \"\\n\\n\".join(formatted_docs)\n",
    "\n",
    "rag_response_chain = (\n",
    "    {\n",
    "        \"context\": (itemgetter('context')\n",
    "                        |\n",
    "                    RunnableLambda(format_docs_with_metadata)),\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "        |\n",
    "    rag_prompt_template\n",
    "        |\n",
    "    chatgpt\n",
    "        |\n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "cite_response_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter('context'),\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"answer\": itemgetter(\"answer\")\n",
    "    }\n",
    "        |\n",
    "    cite_prompt_template\n",
    "        |\n",
    "    structured_chatgpt\n",
    ")\n",
    "\n",
    "rag_chain_w_citations = (\n",
    "    {\n",
    "        \"context\": similarity_retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "        |\n",
    "    RunnablePassthrough.assign(answer=rag_response_chain)\n",
    "        |\n",
    "    RunnablePassthrough.assign(citations=cite_response_chain)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0757ab7-e600-4195-b0e3-df9e84920b4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qt12nMvTjVp2",
    "outputId": "ff2a1d85-1310-4ded-f8a7-afb16e6ee5c0"
   },
   "outputs": [],
   "source": [
    "query = \"What is machine learning\"\n",
    "result = rag_chain_w_citations.invoke(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39a796fe-48b7-414a-83d7-0b01de111746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3fufsoAHiuD",
    "outputId": "c3f9a01f-e1b7-4d72-9eca-3efae2b85bd4"
   },
   "outputs": [],
   "source": [
    "result['citations'].dict()['citations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd553157-4013-4d05-b0eb-67ba7036c1f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "docbPBPDxSVa"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# used mostly for nice display formatting, ignore if not needed\n",
    "def get_cited_context(result_obj):\n",
    "    # Dictionary to hold separate citation information for each unique source and title combination\n",
    "    source_with_citations = {}\n",
    "\n",
    "    def highlight_text(context, quote):\n",
    "        # Normalize whitespace and remove unnecessary punctuation\n",
    "        quote = re.sub(r'\\s+', ' ', quote).strip()\n",
    "        context = re.sub(r'\\s+', ' ', context).strip()\n",
    "\n",
    "        # Split quote into phrases, being careful with punctuation\n",
    "        phrases = [phrase.strip() for phrase in re.split(r'[.!?]', quote) if phrase.strip()]\n",
    "\n",
    "        highlighted_context = context\n",
    "\n",
    "        for phrase in phrases: # for each quoted phrase\n",
    "\n",
    "            # Create regex pattern to match cited phrases\n",
    "            # Escape special regex characters, but preserve word boundaries\n",
    "            escaped_phrase = re.escape(phrase)\n",
    "            # Create regex pattern that allows for slight variations\n",
    "            pattern = re.compile(r'\\b' + escaped_phrase + r'\\b', re.IGNORECASE)\n",
    "\n",
    "            # Replace all matched phrases with bolded version\n",
    "            highlighted_context = pattern.sub(lambda m: f\"**{m.group(0)}**\", highlighted_context)\n",
    "\n",
    "        return highlighted_context\n",
    "\n",
    "    # Process the citation data\n",
    "    for cite in result_obj['citations'].dict()['citations']:\n",
    "        cite_id = cite['id']\n",
    "        title = cite['title']\n",
    "        source = cite['source']\n",
    "        page = cite['page']\n",
    "        quote = cite['quotes']\n",
    "\n",
    "        # Check if the (source, title) key exists, and initialize if it doesn't\n",
    "        if (source, title) not in source_with_citations:\n",
    "            source_with_citations[(source, title)] = {\n",
    "                'title': title,\n",
    "                'source': source,\n",
    "                'citations': []\n",
    "            }\n",
    "\n",
    "        # Find or create the citation entry for this unique (id, page) combination\n",
    "        citation_entry = next(\n",
    "            (c for c in source_with_citations[(source, title)]['citations'] if c['id'] == cite_id and c['page'] == page),\n",
    "            None\n",
    "        )\n",
    "        if citation_entry is None:\n",
    "            citation_entry = {'id': cite_id, 'page': page, 'quote': [quote], 'context': None}\n",
    "            source_with_citations[(source, title)]['citations'].append(citation_entry)\n",
    "        else:\n",
    "            citation_entry['quote'].append(quote)\n",
    "\n",
    "    # Process context data\n",
    "    for context in result_obj['context']:\n",
    "        context_id = context.metadata['id']\n",
    "        context_page = context.metadata['page']\n",
    "        source = context.metadata['source']\n",
    "        title = context.metadata['title']\n",
    "        page_content = context.page_content\n",
    "\n",
    "        # Match the context to the correct citation entry by source, title, id, and page\n",
    "        if (source, title) in source_with_citations:\n",
    "            for citation in source_with_citations[(source, title)]['citations']:\n",
    "                if citation['id'] == context_id and citation['page'] == context_page:\n",
    "                    # Apply highlighting for each quote in the citation's quote list\n",
    "                    highlighted_content = page_content\n",
    "                    for quote in citation['quote']:\n",
    "                        highlighted_content = highlight_text(highlighted_content, quote)\n",
    "                    citation['context'] = highlighted_content\n",
    "\n",
    "    # Convert the dictionary to a list of dictionaries for separate entries\n",
    "    final_result_list = [\n",
    "        {\n",
    "            'title': details['title'],\n",
    "            'source': details['source'],\n",
    "            'citations': details['citations']\n",
    "        }\n",
    "        for details in source_with_citations.values()\n",
    "    ]\n",
    "\n",
    "    return final_result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c468896-1d58-4c01-973c-3a02a8d16146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kq8XyKnlJb4i",
    "outputId": "29f2fb4c-a6a1-499a-ca06-9f39bc0dabd7"
   },
   "outputs": [],
   "source": [
    "get_cited_context(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "902f759a-dd61-47dd-a0fd-ed9a11053901",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "aChUXboG903B"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_results(result_obj):\n",
    "    print('Query:')\n",
    "    display(Markdown(result_obj['question']))\n",
    "    print()\n",
    "    print('Response:')\n",
    "    display(Markdown(result_obj['answer']))\n",
    "    print('='*50)\n",
    "    print('Sources:')\n",
    "    cited_context = get_cited_context(result_obj)\n",
    "    for source in cited_context:\n",
    "        print('Title:', source['title'], ' ', 'Source:', source['source'])\n",
    "        print('Citations:')\n",
    "        for citation in source['citations']:\n",
    "            print('ID:', citation['id'], ' ', 'Page:', citation['page'])\n",
    "            print('Cited Quotes:')\n",
    "            display(Markdown('*'+' '.join(citation['quote'])+'*'))\n",
    "            print('Cited Context:')\n",
    "            display(Markdown(citation['context']))\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1408453c-8032-4756-a005-276566573f15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pG6fcxAE3I3G",
    "outputId": "a37ea781-e6e3-49bb-fead-0a73881391ad"
   },
   "outputs": [],
   "source": [
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d76c02fe-b723-4d13-be53-d8e1108fd79d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rgTlW5hg_d0x",
    "outputId": "2f15c49b-9e98-409b-bff8-0f0bcbd156ec"
   },
   "outputs": [],
   "source": [
    "query = \"What is AI, ML and DL?\"\n",
    "result = rag_chain_w_citations.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ddb8fe1-3642-4f92-a0dc-f0d6f20f1bc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Zho3RfTQ-_WU",
    "outputId": "16957e6c-e635-4482-cddc-ab4ba4529fff"
   },
   "outputs": [],
   "source": [
    "query = \"How is Machine learning related to supervised learning and clustering?\"\n",
    "result = rag_chain_w_citations.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95ca8f0d-8b3c-46a6-a283-586df152ad48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vy2zTEfAFxBo",
    "outputId": "5b6b577f-9c3b-4ae0-f51b-4634b2584ddf"
   },
   "outputs": [],
   "source": [
    "query = \"What is the difference between transformers and vision transformers?\"\n",
    "result = rag_chain_w_citations.invoke(query)\n",
    "display_results(result)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "M6_Contextual_Retrieval_based_RAG_System,_RAG_with_Sources,_RAG_with_Citations",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
