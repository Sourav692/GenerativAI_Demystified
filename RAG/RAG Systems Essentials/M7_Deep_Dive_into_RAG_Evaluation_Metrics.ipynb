{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40593191-0b62-4413-86cd-8899710603f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Reference Link:** [RAG Systems Essentials (Analytics Vidhya)](https://courses.analyticsvidhya.com/courses/take/rag-systems-essentials/lessons/60148017-hands-on-deep-dive-into-rag-evaluation-metrics-generator-metrics-i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fe742f3-1d71-4971-b59e-adc78a69ba34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jbw4wHV4zlKj"
   },
   "source": [
    "# Build a Simple RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6f07c33-9292-4584-bacf-7dfc229c268c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4vtFl39Ofu_8"
   },
   "source": [
    "## Install OpenAI, and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d94f403-82b3-48c7-8435-116e8505af28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39827,
     "status": "ok",
     "timestamp": 1734095711061,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "LVX6450Lfu_9",
    "outputId": "527c6d32-ab83-4720-86c9-19d9aedcbb1a"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.10\n",
    "!pip install langchain-openai==0.2.12\n",
    "!pip install langchain-community==0.3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d28d47f9-f21d-42b5-bcd0-73dac7e5695f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "bwUBYHjPfu_-"
   },
   "source": [
    "## Install Chroma Vector DB and LangChain wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d4a76f8-b333-4d27-9964-576b786b25e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34862,
     "status": "ok",
     "timestamp": 1734095745921,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "p30SmCgTfu__",
    "outputId": "52ad0aa7-bfde-408e-9bb7-8ed0471bb87b"
   },
   "outputs": [],
   "source": [
    "!pip install langchain-chroma==0.1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b18479f7-1a5a-4fe7-94bb-fa93c419c70c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ZNg9rKKVa3DJ"
   },
   "source": [
    "## Install RAG Eval Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6d0df06-0739-4b26-a27b-7b4888c43d6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 29711,
     "status": "ok",
     "timestamp": 1734095775630,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "0jQ2rswHa5-o",
    "outputId": "75908687-de73-4826-b83e-27159465f61d"
   },
   "outputs": [],
   "source": [
    "!pip install ragas==0.2.8\n",
    "!pip install deepeval==1.4.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c9eaa90-1bd3-4817-a1bd-c48f6d484d58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EITC17hwfu__"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50615d00-39f5-48c4-a891-c0738745c299",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6664,
     "status": "ok",
     "timestamp": 1734095792300,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "yEh2olNvfvAA",
    "outputId": "0ef138d1-d440-4742-f430-70553130f4aa"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12362339-d60f-4475-9532-7876d4ea85fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "pm_mx0v-fvAA"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44957716-6fc3-4f05-a68f-c55e857c2119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1734095793871,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "Jhfb4gMUfvAC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85c4f997-28ce-437f-a152-46b61719a790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jiokYxD8fvAC"
   },
   "source": [
    "### Open AI Embedding Models\n",
    "\n",
    "LangChain enables us to access Open AI embedding models which include the newest models: a smaller and highly efficient `text-embedding-3-small` model, and a larger and more powerful `text-embedding-3-large` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32ce5396-5827-4eaf-bc0e-5e62271df223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 2699,
     "status": "ok",
     "timestamp": 1734095806085,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "-On4AS0HfvAD"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bed64bc9-f95e-4f16-8bbf-3f757e91784b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "afzeN_WkHIz2"
   },
   "source": [
    "## Loading and Processing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e6add4b-efdb-421e-a70d-4a8645f8bcdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RA_-hzHbFeSP"
   },
   "source": [
    "### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdb74145-758c-4670-ba51-7fa3f0a99764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4661,
     "status": "ok",
     "timestamp": 1734095814389,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "RZFMYH-yFhWn",
    "outputId": "00619159-fb81-4883-fbc3-7ab9d4c356ce"
   },
   "outputs": [],
   "source": [
    "# if you can't download using the following code\n",
    "# go to https://drive.google.com/file/d/1QkSY9W5RyaBnY8c5FLIsmpPVXoHTQ-fb/view?usp=sharing download it\n",
    "# manually upload it on colab\n",
    "!gdown 1QkSY9W5RyaBnY8c5FLIsmpPVXoHTQ-fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a36a27d8-721b-417f-9218-ae0953de81f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "wMlxKZ_5jIdE"
   },
   "source": [
    "### Load and Process JSON Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9d2412a-4a95-4eae-8473-b1263a949289",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1734095814986,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "RZ5y0NfzHPhg",
    "outputId": "335d55de-e7bf-4b32-b496-f7bb1b4e8b05"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./rag_eval_docs.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fe038b1-f339-4ce9-b4ef-c1dcdb09b3f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734095814986,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "wE4l0DG7tpTI",
    "outputId": "3b151538-c291-4c16-ee09-c3cabd223152"
   },
   "outputs": [],
   "source": [
    "docs = df.to_dict(orient='records')\n",
    "docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40784df7-1b1a-4874-9c58-ad58274dd4ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734095814986,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "yICyAF85h2DO",
    "outputId": "74cfef9f-072b-486b-b069-da1bf505af05"
   },
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "processed_docs = []\n",
    "\n",
    "for doc in docs:\n",
    "    metadata = {\n",
    "        \"title\": doc['title'],\n",
    "        \"id\": doc['id'],\n",
    "    }\n",
    "    data = doc['context']\n",
    "    processed_docs.append(Document(page_content=data, metadata=metadata))\n",
    "processed_docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75996dd5-1dda-45d9-a228-374f396de98d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Daqn6Hglw9Nk"
   },
   "source": [
    "## Index Document Chunks and Embeddings in Vector DB\n",
    "\n",
    "Here we initialize a connection to a Chroma vector DB client, and also we want to save to disk, so we simply initialize the Chroma client and pass the directory where we want the data to be saved to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f7e365f-a855-49f9-a759-8d99ad0dd2b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 2590,
     "status": "ok",
     "timestamp": 1734095818818,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "EYjyZdCyw9Nl"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# create vector DB of docs and embeddings - takes < 30s on Colab\n",
    "chroma_db = Chroma.from_documents(documents=processed_docs,\n",
    "                                  collection_name='my_db',\n",
    "                                  embedding=openai_embed_model,\n",
    "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
    "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
    "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "                                  persist_directory=\"./my_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46d4b641-d287-40d9-8fff-5987a7741c79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "B-0qbbpjw9Nl"
   },
   "source": [
    "### Load Vector DB from disk\n",
    "\n",
    "This is just to show once you have a vector database on disk you can just load and create a connection to it anytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eec9b317-1766-4e6a-82db-531db716822f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1734095818819,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "PI3ITuGZw9Nl"
   },
   "outputs": [],
   "source": [
    "# load from disk\n",
    "chroma_db = Chroma(persist_directory=\"./my_db\",\n",
    "                   collection_name='my_db',\n",
    "                   embedding_function=openai_embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b2c2635-b306-4e88-aa68-bb82315f6206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1734095819136,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "Udsb8xyVw9Nl",
    "outputId": "ec4fea0d-089d-4868-c2d3-a66403407680"
   },
   "outputs": [],
   "source": [
    "chroma_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "410c291e-3f5f-4ec2-b397-8175518e472f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "njfZOOVZxj1a"
   },
   "source": [
    "### Semantic Similarity based Retrieval\n",
    "\n",
    "We use simple cosine similarity here and retrieve the top 3 similar documents based on the user input query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22ec996f-672c-4fcc-b03e-8d3900ded703",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1734095819939,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "tV1l6HYdxj1b"
   },
   "outputs": [],
   "source": [
    "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                                              search_kwargs={\"k\": 3, \"score_threshold\": 0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12e1439d-f213-4fe9-833d-2a8f927ca741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1734095822009,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "nUIJG_bDxj1c"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_docs(docs):\n",
    "    for doc in docs:\n",
    "        print('Metadata:', doc.metadata)\n",
    "        print('Content Brief:')\n",
    "        display(Markdown(doc.page_content))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbbdf502-bdc6-4bf5-adb0-cd2d3bc995a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "executionInfo": {
     "elapsed": 1206,
     "status": "ok",
     "timestamp": 1734095824222,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "PIh4xGv2xj1c",
    "outputId": "15871aaa-e3d9-41e3-d5cf-086cd27e8e5b"
   },
   "outputs": [],
   "source": [
    "query = \"what is AI?\"\n",
    "top_docs = similarity_retriever.invoke(query)\n",
    "display_docs(top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d25d0323-8064-41b9-b400-d2c4a91c5bb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1734095825289,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "S_PXFMcJxuyO",
    "outputId": "784ca418-9a0f-41da-a96f-cf7d546db820"
   },
   "outputs": [],
   "source": [
    "query = \"how do plants survive?\"\n",
    "top_docs = similarity_retriever.invoke(query)\n",
    "display_docs(top_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "743930d7-5d0f-4e9d-807b-20dfaf2084ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gQFWv7YUyVII"
   },
   "source": [
    "## Build the RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8a4a354-3ad5-48f3-a0c5-b6b97d23b3c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734095826589,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "PHOrfGXKyVIJ"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n",
    "                Answer the following question using only the following pieces of retrieved context.\n",
    "                If the answer is not in the context, do not make up answers, just say that you don't know.\n",
    "                Keep the answer to the point based on the information from the context.\n",
    "\n",
    "                Question:\n",
    "                {question}\n",
    "\n",
    "                Context:\n",
    "                {context}\n",
    "\n",
    "                Answer:\n",
    "            \"\"\"\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "005b3c5b-9e35-4979-94c1-77fe3f3db4d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1734095828216,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "KmWeCB4yyVIJ"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "src_rag_response_chain = (\n",
    "    {\n",
    "        \"context\": (itemgetter('context')\n",
    "                        |\n",
    "                    RunnableLambda(format_docs)),\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "        |\n",
    "    rag_prompt_template\n",
    "        |\n",
    "    chatgpt\n",
    "        |\n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_w_sources = (\n",
    "    {\n",
    "        \"context\": similarity_retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "        |\n",
    "    RunnablePassthrough.assign(response=src_rag_response_chain)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcc3e164-a4ea-498d-a294-b5558dd4bb98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1333,
     "status": "ok",
     "timestamp": 1734095830720,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "xvj_eGIWyVIJ",
    "outputId": "facb3195-a81b-49b2-c230-8a9c0d242f77"
   },
   "outputs": [],
   "source": [
    "query = \"What is AI?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79feb790-4f3c-43ff-b117-3e8762c3472a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 786,
     "status": "ok",
     "timestamp": 1734095832413,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "pXtezDlZzadt",
    "outputId": "0f780c0a-f3ae-413f-f773-4bc9a384b82b"
   },
   "outputs": [],
   "source": [
    "query = \"How do plants survive?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88b0ac04-8452-41c7-8ea0-1bd223c44b03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MTTk1BaCBfYa"
   },
   "source": [
    "# Retriever Evaluation Metrics\n",
    "\n",
    "![](https://i.imgur.com/5S4FhMB.png)\n",
    "\n",
    "The retrieval process generally includes these steps:\n",
    "\n",
    "- Convert the initial input query into an embedding using an embedding model of your choice (e.g., OpenAI's `text-embedding-3` model).\n",
    "- Conduct a vector search with the embedded input on a vector database that holds your vectorized knowledge base, retrieving the top-K most \"similar\" document chunks.\n",
    "- Optionally user a Reranker to rerank the retrieved results\n",
    "\n",
    "\n",
    "Key Metrics to Evaluate here include:\n",
    "\n",
    "- Contextual Precision\n",
    "- Contextual Recall\n",
    "- Contextual Relevancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d4b9c03-88eb-480d-8818-3281e1dce5b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gQOoZNPzDdjY"
   },
   "source": [
    "## Contextual Precision\n",
    "\n",
    "The contextual precision metric measures your RAG pipeline's retriever by evaluating whether document chunks (nodes) in your `retrieval_context` that are relevant to the given `input` are ranked higher than irrelevant ones.\n",
    "\n",
    "`deepeval`'s contextual precision metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a judge.\n",
    "\n",
    "In `deepeval`, to use the ContextualPrecisionMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n",
    "\n",
    "- `input` : Input Query\n",
    "- `actual_output` : Actual LLM Response (not used in the computation)\n",
    "- `expected_output` : Expected LLM Response (ground truth answer)\n",
    "- `retrieval_context` : Top-N retrieved document chunks (nodes) from Vector DB\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/oVwrRAU.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98fee6a9-a9ee-409a-a82f-74bb08c3f4de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1400,
     "status": "ok",
     "timestamp": 1734095838031,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "deG08v9sF0pY",
    "outputId": "8905b41c-2671-4a66-889c-eb7423d3343d"
   },
   "outputs": [],
   "source": [
    "query = \"What is AI?\"\n",
    "response = rag_chain_w_sources.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "509ebdb4-1b67-4ff1-b059-a937f176dcd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "FXisPv9hSbSL"
   },
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83e27c8d-6a7d-4de7-872e-43bb5049dc89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734095838362,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "v9cW2lv1IzIx",
    "outputId": "d9fdaa17-172c-4026-971a-dc418ed41c82"
   },
   "outputs": [],
   "source": [
    "retrieved_context = [doc.page_content for doc in response['context']]\n",
    "retrieved_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36d16b5a-442e-4bbd-8044-ac3fdf463793",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734095840510,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "Bm8St8H7F5nS"
   },
   "outputs": [],
   "source": [
    "human_answer = \"\"\"AI, also known as Artificial Intelligence is used to build complex systems for applications\n",
    "                  like virtual assistants, robotics and autonomous vehicles.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea6a017b-bc10-48df-9779-f05b4f591171",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1734095841851,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "nOhNhwphJEfU",
    "outputId": "9504fe9d-340b-4cdd-da6a-71d88d96ee49"
   },
   "outputs": [],
   "source": [
    "new_context = ['Machine Learning is the study of algorithms which learn with more data',\n",
    "               'AI is known as Artificial Intelligence'] + retrieved_context\n",
    "new_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13ea9336-a615-45cb-924c-64c9342f82d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9005,
     "status": "ok",
     "timestamp": 1734095853038,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "2Urkt1YHIuK8",
    "outputId": "8736b357-0964-4c4c-b00c-d008ea353895"
   },
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import ContextualPrecisionMetric\n",
    "from deepeval import evaluate\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=response['question'],\n",
    "    actual_output=response['response'],\n",
    "    expected_output=human_answer,\n",
    "    retrieval_context=new_context\n",
    ")\n",
    "\n",
    "metric = ContextualPrecisionMetric(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o\",\n",
    "    include_reason=True,\n",
    "    verbose_mode=True\n",
    ")\n",
    "\n",
    "result = evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95df2e5e-7300-4868-ae1c-dd3b9feb7a69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1734095863827,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "00qrXrl9JY06",
    "outputId": "07ae6595-2dcc-4908-9d5b-7fd5da06e859"
   },
   "outputs": [],
   "source": [
    "print('Sucess:', result.test_results[0].metrics_data[0].success)\n",
    "print('Score:', result.test_results[0].metrics_data[0].score)\n",
    "print('Reason:', result.test_results[0].metrics_data[0].reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d171d551-224f-46b0-89da-338999a49bf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "uTDmP7-dLRlp"
   },
   "source": [
    "## Contextual Recall\n",
    "\n",
    "The contextual recall metric measures the quality of your RAG pipeline's retriever by evaluating the extent of which the `retrieval_context` aligns with the `expected_output`.\n",
    "\n",
    "`deepeval`'s contextual recall metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a Judge.\n",
    "\n",
    "In `deepeval`, to use the ContextualRecallMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n",
    "\n",
    "- `input` : Input Query (not used in the computation)\n",
    "- `actual_output` : Actual LLM Response (not used in the computation)\n",
    "- `expected_output` : Expected LLM Response (ground truth answer)\n",
    "- `retrieval_context` : Top-N retrieved document chunks (nodes) from Vector DB\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/PDbwuX5.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3856d0f0-5970-422f-878f-75f0ba81196b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhnDaJvELRlq",
    "outputId": "c2cc9da2-ca24-41f6-a7d0-53890dacb488"
   },
   "outputs": [],
   "source": [
    "query = \"What is AI?\"\n",
    "response = rag_chain_w_sources.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1706141-cec1-4f6c-a733-598dc9e2f217",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "SRdTNvgESiaC"
   },
   "source": [
    "### Example 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ce87eea-5b8c-488a-b35d-ffa7184a6049",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uv7FKS6XLRlr",
    "outputId": "76f5611a-9ed0-4120-dd20-abbfafef7221"
   },
   "outputs": [],
   "source": [
    "retrieved_context = [doc.page_content for doc in response['context']]\n",
    "retrieved_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "012c0c29-3be5-4006-9b77-a52f98250666",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "90_guzmVLRls"
   },
   "outputs": [],
   "source": [
    "human_answer = \"\"\"AI, also known as Artificial Intelligence is used to build complex systems for applications\n",
    "                  like virtual assistants, robotics and autonomous vehicles.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "505c658c-4fb3-4a33-a19d-8c380403934f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84eNVGrwLRlt",
    "outputId": "f522e7cd-e815-4634-a180-9e3347630fe1"
   },
   "outputs": [],
   "source": [
    "new_context = ['NVIDIA makes chips for AI', 'AI is an acronym for Artificial Intellence']\n",
    "new_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9fba24a-0264-4a5f-aa33-244b13b511ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Of-wta5OLRlt",
    "outputId": "267e8858-71f1-41a8-d27d-e80f5f635cd8"
   },
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import ContextualRecallMetric\n",
    "from deepeval import evaluate\n",
    "\n",
    "test_case1 = LLMTestCase(\n",
    "    input=response['question'],\n",
    "    actual_output=response['response'],\n",
    "    expected_output=human_answer,\n",
    "    retrieval_context=retrieved_context\n",
    ")\n",
    "\n",
    "test_case2 = LLMTestCase(\n",
    "    input=response['question'],\n",
    "    actual_output=response['response'],\n",
    "    expected_output=human_answer,\n",
    "    retrieval_context=new_context\n",
    ")\n",
    "\n",
    "metric = ContextualRecallMetric(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o\",\n",
    "    include_reason=True,\n",
    "    verbose_mode=True\n",
    ")\n",
    "\n",
    "result = evaluate([test_case1, test_case2], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc205eaf-804d-4bbb-903a-908434645930",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13c3vhCQLRlt",
    "outputId": "bcae6817-0a1c-4ec6-ae51-7b2ca301be03"
   },
   "outputs": [],
   "source": [
    "print('Sucess:', result.test_results[0].metrics_data[0].success)\n",
    "print('Score:', result.test_results[0].metrics_data[0].score)\n",
    "print('Reason:', result.test_results[0].metrics_data[0].reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd924b8c-720f-44d8-9ee6-552d4e29077d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-bbC5jelN9v",
    "outputId": "f86d6460-af92-4cb3-c90f-d6b8984cec82"
   },
   "outputs": [],
   "source": [
    "print('Sucess:', result.test_results[1].metrics_data[0].success)\n",
    "print('Score:', result.test_results[1].metrics_data[0].score)\n",
    "print('Reason:', result.test_results[1].metrics_data[0].reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47140171-afc1-4cdf-9102-f1a3a91df344",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "SfHpMTVvSx7h"
   },
   "source": [
    "## Contextual Relevancy\n",
    "\n",
    "The contextual relevancy metric measures the quality of your RAG pipeline's retriever by evaluating the overall relevance of the information presented in your `retrieval_context` for a given `input`.\n",
    "\n",
    "`deepeval`'s contextual relevancy metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a Judge.\n",
    "\n",
    "In `deepeval`, to use the ContextualRelevancyMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n",
    "\n",
    "- `input` : Input Query\n",
    "- `actual_output` : Actual LLM Response (not used in the computation)\n",
    "- `retrieval_context` : Top-N retrieved document chunks (nodes) from Vector DB\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/VLKoEsI.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81abe1cd-1d29-4cb0-bf08-b947d965a0a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QI5H2AWqSx7h",
    "outputId": "89ad1a10-6299-4a0b-cea1-49bdbea2e0f5"
   },
   "outputs": [],
   "source": [
    "query = \"What is AI?\"\n",
    "response = rag_chain_w_sources.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55aaa3ff-5c22-4ef0-964c-1f3b33db39e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "45UdHqalSx7i"
   },
   "source": [
    "### Example 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3d78c36-f7ab-48b5-a080-d812641b4454",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOpExtxiSx7i",
    "outputId": "2420dba1-4969-45df-923a-5ce5577f60af"
   },
   "outputs": [],
   "source": [
    "retrieved_context = [doc.page_content for doc in response['context']]\n",
    "retrieved_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7de2e77e-508e-4c3a-bbed-e3c7ef62dddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyAtudlSSx7k",
    "outputId": "9d4a3240-3268-4f5e-d61b-3f8e55c0d51a"
   },
   "outputs": [],
   "source": [
    "new_context = ['NVIDIA makes chips for AI', 'Google and Microsoft are battling out the market share for AI Chatbots'] + retrieved_context\n",
    "new_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70df5754-f978-4aa1-af42-957c70dca14d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2_fQqaFUSx7l",
    "outputId": "34468573-ef29-489e-8b4d-1cc27cca3714"
   },
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import ContextualRelevancyMetric\n",
    "from deepeval import evaluate\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=response['question'],\n",
    "    actual_output=response['response'],\n",
    "    expected_output=human_answer,\n",
    "    retrieval_context=new_context\n",
    ")\n",
    "\n",
    "metric = ContextualRelevancyMetric(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o\",\n",
    "    include_reason=True,\n",
    "    verbose_mode=True\n",
    ")\n",
    "\n",
    "result = evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31ff3d07-9152-45ee-a728-d32c2ae8bc38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NnZIKnxmSx7l",
    "outputId": "f73af640-72dd-4949-d462-c9219cd35168"
   },
   "outputs": [],
   "source": [
    "print('Sucess:', result.test_results[0].metrics_data[0].success)\n",
    "print('Score:', result.test_results[0].metrics_data[0].score)\n",
    "print('Reason:', result.test_results[0].metrics_data[0].reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e0e8dc7-036f-4de3-88a3-55b5ed757180",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ZlekplN_WC5A"
   },
   "source": [
    "# Generator Evaluation Metrics\n",
    "\n",
    "![](https://i.imgur.com/GaMHy7w.png)\n",
    "\n",
    "The generation step, which comes after retrieval, generally includes:\n",
    "\n",
    "- Building a prompt that combines the initial input with the context retrieved in the previous step.\n",
    "- Feeding this prompt to your LLM, which produces the final generated response.\n",
    "\n",
    "\n",
    "Key Metrics to Evaluate here include:\n",
    "\n",
    "- Answer Relevancy\n",
    "- Faithfulness\n",
    "- Hallucination Check\n",
    "- Custom LLM as a Judge (G-Eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33bf149b-34b7-46b2-b476-224600d3191b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "bCsfBjF5l_sz"
   },
   "source": [
    "## LLM-based Answer Relevancy - DeepEval\n",
    "\n",
    "The answer relevancy metric measures the quality of your RAG pipeline's generator by evaluating how relevant the `actual_output` of your LLM application is compared to the provided `input`.\n",
    "\n",
    "`deepeval`'s answer relevancy metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a Judge.\n",
    "\n",
    "In `deepeval`, to use the AnswerRelevancyMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n",
    "\n",
    "- `input` : Input Query\n",
    "- `actual_output` : Actual LLM Response\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/GbNSCFC.png)\n",
    "\n",
    "\n",
    "\n",
    "## Semantic Similarity based Answer Relevancy - RAGAS\n",
    "\n",
    "DeepEval has bindings to Ragas which enables us to use the RAGASAnswerRelevancyMetric which focuses on assessing how pertinent the generated answer is to the given query using cosine similarity. A lower score is assigned to answers that are incomplete or contain redundant information and higher scores indicate better relevancy.\n",
    "\n",
    "![](https://i.imgur.com/vq1ytZ3.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65587888-f81f-4dfc-a45c-c63e3c838e4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1210,
     "status": "ok",
     "timestamp": 1734095873218,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "2nWBbl_3l_s0",
    "outputId": "e32d6c8f-6484-4ba6-b9ee-2be7da70d804"
   },
   "outputs": [],
   "source": [
    "query = \"What is AI?\"\n",
    "response = rag_chain_w_sources.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2773deca-bf0d-43c9-81b7-8e95f7d153ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "81EpPklYl_s1"
   },
   "source": [
    "### Example - DeepEval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e9305c8-5399-48ec-9228-694c12ed98e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3675,
     "status": "ok",
     "timestamp": 1734095878632,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "2klPvY0Al_s2",
    "outputId": "78f646f0-bf75-4b67-b458-33346528fd59"
   },
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval import evaluate\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=response['question'],\n",
    "    actual_output=response['response'],\n",
    ")\n",
    "\n",
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o\",\n",
    "    include_reason=True,\n",
    "    verbose_mode=True\n",
    ")\n",
    "\n",
    "result = evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c738912-7a6f-487f-9c59-f38738f3e7d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734095878632,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "JR5A3ZhPp6Dz",
    "outputId": "552510ec-1894-4a35-bcca-e830f48b6fe9"
   },
   "outputs": [],
   "source": [
    "print('Sucess:', result.test_results[0].metrics_data[0].success)\n",
    "print('Score:', result.test_results[0].metrics_data[0].score)\n",
    "print('Reason:', result.test_results[0].metrics_data[0].reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15a8585d-09cc-45c3-9a49-ce13fcf3a26f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9vZNbqkwx-Sj"
   },
   "source": [
    "### Example - RAGAS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb797f46-1f5c-487c-990e-c985edfc4c7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620,
     "referenced_widgets": [
      "8890484b6c3e4018907b96b026510712",
      "0a1982c87e18425a97c43a61c18f928b",
      "d7e48662099b409baeb15177af124bb5",
      "d3d8515a3b194fb3b1fdc820607a00bf",
      "ce0f9b8f431246da93ebbe3c5cb8b026",
      "28c6583c344341599988c3dad3070cc8",
      "9d4be022d51847e8a1ccd0a9eb885de2",
      "7614ca4667f948ccba8f980a1ae4722d",
      "ab7499442d7648168ca9415bda596e05",
      "ad467cc9f9884950ada71fbb95cfccbd",
      "c5bd0a78f28749e39a63421f0da20446"
     ]
    },
    "executionInfo": {
     "elapsed": 5490,
     "status": "ok",
     "timestamp": 1734095893121,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "VyssN8E4pv-U",
    "outputId": "449d537e-ac37-47a7-cbbc-84b673781abc"
   },
   "outputs": [],
   "source": [
    "from deepeval.metrics.ragas import RAGASAnswerRelevancyMetric\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=response['question'],\n",
    "    actual_output=response['response'],\n",
    ")\n",
    "\n",
    "metric = RAGASAnswerRelevancyMetric(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o\",\n",
    "    embeddings=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "result = evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efc93360-ab76-4316-86e9-acf19e722268",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1734095897061,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "WAubWCbzl_s3",
    "outputId": "2e878c34-3b16-4214-d5e8-d65dd47b5184"
   },
   "outputs": [],
   "source": [
    "print('Sucess:', result.test_results[0].metrics_data[0].success)\n",
    "print('Score:', result.test_results[0].metrics_data[0].score)\n",
    "print('Reason:', result.test_results[0].metrics_data[0].reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50dbb016-4ab7-4720-bb0b-8371b1722117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tlZajG6R1EUc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e627de7f-feed-4e6a-914f-5bcfe6f3c5ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "JmdnS3rw1EhX"
   },
   "source": [
    "## Faithfulness\n",
    "\n",
    "The faithfulness metric measures the quality of your RAG pipeline's generator by evaluating whether the `actual_output` factually aligns with the contents of your `retrieval_context`.\n",
    "\n",
    "`deepeval`'s faithfulness metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a Judge.\n",
    "\n",
    "In `deepeval`, to use the FaithfulnessMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n",
    "\n",
    "- `input` : Input Query (not used in the computation)\n",
    "- `actual_output` : Actual LLM Response\n",
    "- `retrieval_context` : Top-N retrieved document chunks (nodes) from Vector DB\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/OCSFPTb.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6e7c4d9-707f-4311-8da1-ff24cc34f9eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPm0hd3m1EhY",
    "outputId": "1fc21ab4-c554-4b6b-a732-a1e45c1503ce"
   },
   "outputs": [],
   "source": [
    "query = \"What is AI?\"\n",
    "response = rag_chain_w_sources.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e09101f-84cf-4fdf-a690-dc14d7cfe6b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tzoXGIqh1EhZ"
   },
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5115b8db-b9f4-4929-a02a-0884ab1c6098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-p0SPQqW166X",
    "outputId": "60e3f71c-95c1-48d6-a1a8-26a6f17501b4"
   },
   "outputs": [],
   "source": [
    "retrieved_context = [doc.page_content for doc in response['context']]\n",
    "retrieved_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56089ffb-74c7-4c60-a088-70056c1b7848",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3hw-CRSG1EhZ",
    "outputId": "fd8d4b8a-df2f-462d-bbe7-f7e584519602"
   },
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import FaithfulnessMetric\n",
    "from deepeval import evaluate\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=response['question'],\n",
    "    actual_output=response['response'],\n",
    "    retrieval_context=retrieved_context\n",
    ")\n",
    "\n",
    "metric = FaithfulnessMetric(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o\",\n",
    "    include_reason=True,\n",
    "    verbose_mode=True\n",
    ")\n",
    "\n",
    "result = evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "daf6944a-0c99-4824-bf9c-981524ab938b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kDPBfo71EhZ",
    "outputId": "699f306e-344e-4ac3-ea64-b845d6e9bc82"
   },
   "outputs": [],
   "source": [
    "print('Sucess:', result.test_results[0].metrics_data[0].success)\n",
    "print('Score:', result.test_results[0].metrics_data[0].score)\n",
    "print('Reason:', result.test_results[0].metrics_data[0].reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1a93d4c-56f6-481b-a298-1573314e0603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "3OEaZBlf5Ijm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "808dc093-90bd-4cb3-a4bd-c14e763d1891",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "LrIyB4rA5I36"
   },
   "source": [
    "## Hallucination Check\n",
    "\n",
    "The hallucination metric determines whether your LLM generates factually correct information by comparing the `actual_output` to the provided (human ground truth) `context`.\n",
    "\n",
    "`deepeval`'s hallucination metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a Judge.\n",
    "\n",
    "In `deepeval`, to use the HallucinationMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n",
    "\n",
    "- `input` : Input Query (not used in the computation)\n",
    "- `actual_output` : Actual LLM Response\n",
    "- `context` : Human Ground Truth Context Document Chunks (Nodes)\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/qyVBKU2.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd24b98d-07a8-4859-953c-7774580edc44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGeeQFHy5I37",
    "outputId": "85afd6d4-bfda-4e1f-bbd8-07266bce8ebc"
   },
   "outputs": [],
   "source": [
    "query = \"What is AI?\"\n",
    "response = rag_chain_w_sources.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f61af9c3-d654-4157-b228-6d4918a7916d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L3uQFN3I5I37"
   },
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6b20bd1-bf36-497d-b3bd-e4ae2b81d30f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VGxjvNZM5I38",
    "outputId": "199dcfe7-6521-42d3-e711-416f67f3b26d"
   },
   "outputs": [],
   "source": [
    "retrieved_context = [doc.page_content for doc in response['context']]\n",
    "retrieved_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f577dd7-d22d-4194-af44-e08802745116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pgjaKdKR6O4_",
    "outputId": "addeede2-fd07-421e-83d1-4475e38b9c69"
   },
   "outputs": [],
   "source": [
    "human_ground_truth_context = [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n",
    "                              \"Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.\"]\n",
    "human_ground_truth_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "869fb096-d869-4f22-a53b-60094d3d2139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "id": "XXl6z6Cq5I38",
    "outputId": "85693856-dd93-46bb-87d5-bcc5abf0933a"
   },
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import HallucinationMetric\n",
    "from deepeval import evaluate\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=response['question'],\n",
    "    actual_output=response['response'],\n",
    "    context=human_ground_truth_context\n",
    ")\n",
    "\n",
    "metric = HallucinationMetric(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o\",\n",
    "    include_reason=True,\n",
    "    verbose_mode=True\n",
    ")\n",
    "\n",
    "result = evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdd69775-3b7b-4390-8953-e7174b96189a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NNV-zh4f5I38",
    "outputId": "e12a69ed-48e4-49b7-fe0b-69572ab4b52d"
   },
   "outputs": [],
   "source": [
    "print('Sucess:', result.test_results[0].metrics_data[0].success)\n",
    "print('Score:', result.test_results[0].metrics_data[0].score)\n",
    "print('Reason:', result.test_results[0].metrics_data[0].reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc5fe577-75a2-4544-998a-268faeaf2129",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "W6VU09PE6jOj"
   },
   "outputs": [],
   "source": [
    "ai_response = 'AI refers to machines mimicking human intelligence to produce cyborgs and electric sheep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3e6aace-05db-4339-98b7-a5a7c9917798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "id": "8jBVsZui6k_S",
    "outputId": "a232645d-c59c-4264-da67-58283c77595e"
   },
   "outputs": [],
   "source": [
    "test_case = LLMTestCase(\n",
    "    input=response['question'],\n",
    "    actual_output=ai_response,\n",
    "    context=human_ground_truth_context\n",
    ")\n",
    "\n",
    "metric = HallucinationMetric(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o\",\n",
    "    include_reason=True,\n",
    "    verbose_mode=True\n",
    ")\n",
    "\n",
    "result = evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "921ea2dd-fbeb-4d41-adfb-22887ce1a0b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sthkQ2_F6wwW",
    "outputId": "bf71ad6e-ee28-485a-8bea-614cb9b279eb"
   },
   "outputs": [],
   "source": [
    "print('Sucess:', result.test_results[0].metrics_data[0].success)\n",
    "print('Score:', result.test_results[0].metrics_data[0].score)\n",
    "print('Reason:', result.test_results[0].metrics_data[0].reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f51651c-9209-4a52-9bba-b6c0889caeb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "h0-E1OjJF3ak"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13161434-8a0f-45e2-b21a-bb8810f3048e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "amGTDvrCF3r8"
   },
   "source": [
    "## Custom LLM as a Judge (G-Eval)\n",
    "\n",
    "G-Eval is a framework that uses LLMs with chain-of-thoughts (CoT) to evaluate LLM outputs based on __ANY__ custom criteria.\n",
    "\n",
    "The G-Eval metric is the most versatile type of metric `deepeval` has to offer, and is capable of evaluating almost any use case with good accuracy.\n",
    "\n",
    "Here you are free to describe your custom evaluation process in detail using prompts in `evaluation_steps`.\n",
    "\n",
    "In `deepeval`, to use the GEval, you'll have to provide the following arguments when creating an `LLMTestCase`:\n",
    "\n",
    "- `input` : Input Query (not used in the computation)\n",
    "- `actual_output` : Actual LLM Response\n",
    "\n",
    "You'll also need to supply any additional arguments such as `expected_output` and `context` if your evaluation criteria depends on these parameters.\n",
    "\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/IuODLKQ.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cff5a20f-6e3d-43d8-bd4e-ef3e6cd6e47c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1848,
     "status": "ok",
     "timestamp": 1734094010873,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "-ZdDU9pDF3r8",
    "outputId": "644174a0-6aba-40b3-c6ab-c9c74f1f420d"
   },
   "outputs": [],
   "source": [
    "query = \"What is AI?\"\n",
    "response = rag_chain_w_sources.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4d9390f-d4e5-4416-b00a-56ec5ee20415",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "vLbxFHQ-F3r9"
   },
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "450da362-e935-4fe2-b6c2-a1c874b310a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734094012121,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "h5kDpnMKF3r9",
    "outputId": "631cfcc6-047c-455a-c82b-2fa098238370"
   },
   "outputs": [],
   "source": [
    "retrieved_context = [doc.page_content for doc in response['context']]\n",
    "retrieved_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aef086be-dfcd-435d-b256-5fc9ff2683e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1734094013406,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "eA88dIX2KClW",
    "outputId": "26367487-75c1-4aad-a658-07e1368c4499"
   },
   "outputs": [],
   "source": [
    "ai_response = response['response']\n",
    "ai_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab2ab1b3-de45-4ff6-b423-fd9f10cc0376",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734094014859,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "xk2n7gfnLGZD",
    "outputId": "50f499dd-629d-45f3-ac73-bc867331fba8"
   },
   "outputs": [],
   "source": [
    "ai_response = 'AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like electric sheep and cyborg kittens'\n",
    "ai_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "379ea565-4cdc-461b-952e-c9ef09beb2f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734094016313,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "InzJ2ro184f-",
    "outputId": "ac74d394-22ec-477c-cfe3-77729421011e"
   },
   "outputs": [],
   "source": [
    "human_answer = \"\"\"AI, also known as Artificial Intelligence is used to build complex systems for applications\n",
    "                  like virtual assistants, robotics and autonomous vehicles.\"\"\"\n",
    "human_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "672a2048-79c6-4899-86e2-84c5697e4b60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 943
    },
    "id": "Hl2PbM8ZF3r-",
    "outputId": "8f6fe87a-d5af-477d-f06f-0482cf1d5005"
   },
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval import evaluate\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=response['question'],\n",
    "    actual_output=ai_response,\n",
    "    expected_output=human_answer,\n",
    "    retrieval_context=retrieved_context\n",
    ")\n",
    "\n",
    "metric = GEval(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o\",\n",
    "    name=\"RAG Fact Checker\",\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Create a list of statements from 'actual output'\",\n",
    "        \"Validate if they are relevant and answers the given question in 'input', penalize if any statements are irrelevant\",\n",
    "        \"Also Validate if they exist in 'expected output', penalize if any statements are missing or factually wrong\",\n",
    "        \"Also validate if these statements are grounded in the 'retrieval context' and penalize if they are missing or factually wrong\",\n",
    "        \"Finally also penalize if any statements seem to be invented or made up and do not make sense factually given the 'input' and 'retrieval context'\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT,\n",
    "                       LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "                       LLMTestCaseParams.EXPECTED_OUTPUT,\n",
    "                       LLMTestCaseParams.RETRIEVAL_CONTEXT],\n",
    "    verbose_mode=True\n",
    ")\n",
    "\n",
    "result = evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a27e5d36-d44d-4640-9ee0-b6bfb45d406b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UJYPsYlF3r-",
    "outputId": "8667470e-21da-4676-dbb5-5de6d82e2284"
   },
   "outputs": [],
   "source": [
    "print('Sucess:', result.test_results[0].metrics_data[0].success)\n",
    "print('Score:', result.test_results[0].metrics_data[0].score)\n",
    "print('Reason:', result.test_results[0].metrics_data[0].reason)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "M7_Deep_Dive_into_RAG_Evaluation_Metrics",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a1982c87e18425a97c43a61c18f928b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c6583c344341599988c3dad3070cc8",
      "placeholder": "​",
      "style": "IPY_MODEL_9d4be022d51847e8a1ccd0a9eb885de2",
      "value": "Evaluating: 100%"
     }
    },
    "28c6583c344341599988c3dad3070cc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7614ca4667f948ccba8f980a1ae4722d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8890484b6c3e4018907b96b026510712": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a1982c87e18425a97c43a61c18f928b",
       "IPY_MODEL_d7e48662099b409baeb15177af124bb5",
       "IPY_MODEL_d3d8515a3b194fb3b1fdc820607a00bf"
      ],
      "layout": "IPY_MODEL_ce0f9b8f431246da93ebbe3c5cb8b026"
     }
    },
    "9d4be022d51847e8a1ccd0a9eb885de2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab7499442d7648168ca9415bda596e05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad467cc9f9884950ada71fbb95cfccbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5bd0a78f28749e39a63421f0da20446": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce0f9b8f431246da93ebbe3c5cb8b026": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3d8515a3b194fb3b1fdc820607a00bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad467cc9f9884950ada71fbb95cfccbd",
      "placeholder": "​",
      "style": "IPY_MODEL_c5bd0a78f28749e39a63421f0da20446",
      "value": " 1/1 [00:03&lt;00:00,  3.12s/it]"
     }
    },
    "d7e48662099b409baeb15177af124bb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7614ca4667f948ccba8f980a1ae4722d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ab7499442d7648168ca9415bda596e05",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
