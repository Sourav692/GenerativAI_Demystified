{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcd0d24e-0967-4482-b3f0-d6e8908a24c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Reference Link:** [Building AI Agents with LangChain (Analytics Vidhya)](https://courses.analyticsvidhya.com/courses/take/building-ai-agents-with-langchain/lessons/62141622-introduction-to-agents-and-tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8e3ad4e-a61d-47ee-b116-01cd1caa5fa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1kiH8lf1y4sD"
   },
   "source": [
    "# Build a Multi-User Conversational Tool-Calling Agentic AI Research Assistant with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c984670-b568-4ac1-923f-059fae794419",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NYBpZTjLnEXb"
   },
   "source": [
    "This demo will cover building AI Agents with the legacy LangChain `AgentExecutor`. These are fine for getting started, but for working with more advanced agents, LangChain recommends to use LangGraph, which we will cover in the future demos.\n",
    "\n",
    "Agents are systems that use an LLM as a reasoning engine to determine which actions to take and what the inputs to those actions should be. The results of those actions can then be fed back into the agent and it determines whether more actions are needed, or whether it is okay to stop.\n",
    "\n",
    "Here we will build a multi-user Conversational Agent which can refer to previous conversations and give more contextual answers by storing agent messages to a SQL database\n",
    "\n",
    "![](https://i.imgur.com/lHWqaT9.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be08b0d9-8290-45da-9b1c-21ae6a632a15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L1KvMtf54l0d"
   },
   "source": [
    "## Install OpenAI, and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca99c70a-cf9f-4126-bf1c-2cc34daf48dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2evPp14fy258",
    "outputId": "8f7fcca6-1101-4488-c0c7-0ffe0307cf69"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain==0.3.14\n",
    "!pip install -q langchain-openai==0.3.0\n",
    "!pip install -q langchain-community==0.3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "506aa106-3177-48e9-8664-26fa134cc75b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AakmY6B_zYte",
    "outputId": "4be48016-fc58-4992-9b93-a13f4c358026"
   },
   "outputs": [],
   "source": [
    "!pip install -q markitdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffbece94-c687-45ce-b149-7443183f1e83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H9c37cLnSrbg"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55b03f51-72cb-4f6f-93b4-0d7bf0e2b81f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv3JzCEx_PAd",
    "outputId": "f9111545-cbad-4b45-c073-d2fe2b35fe70"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Open AI API Key: ··········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bca4654b-db10-46d2-8ff6-500e6fb53c77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ucWRRI3QztL2"
   },
   "source": [
    "## Enter Tavily Search API Key\n",
    "\n",
    "Get a free API key from [here](https://tavily.com/#api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db46b103-1c77-4377-a102-7eb1a7e86b0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mK-1WLzOrJdb",
    "outputId": "06b5df28-b09c-449e-d2b3-b0630c7efa60"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Tavily Search API Key: ··········\n"
     ]
    }
   ],
   "source": [
    "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04c52805-ab83-466b-9742-6fd29c76613e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Ce5arICZEEov"
   },
   "source": [
    "## Enter WeatherAPI API Key\n",
    "\n",
    "Get a free API key from [here](https://www.weatherapi.com/signup.aspx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2caf1360-895b-4b67-aaa7-ad1371c8cb5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpAMz1XgEEov",
    "outputId": "78e31000-cb94-4b68-cd9f-e360d2cd7480"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter WeatherAPI API Key: ··········\n"
     ]
    }
   ],
   "source": [
    "WEATHER_API_KEY = getpass('Enter WeatherAPI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb9a3bb3-150d-4a56-8a2c-ad69206447d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1T0s0um5Svfa"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d45ffb6-83d6-4b39-ac95-3142b98509a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x1YSuHNF_lbh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d508b8ca-4e0b-4398-93b2-e87d9a0fc232",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "howf-v0ARWbv"
   },
   "source": [
    "## Create Tools\n",
    "\n",
    "Here we create two custom tools which are wrappers on top of the [Tavily API](https://tavily.com/#api) and [WeatherAPI](https://www.weatherapi.com/)\n",
    "\n",
    "- Web Search tool with information extraction\n",
    "- Weather tool\n",
    "\n",
    "![](https://i.imgur.com/TyPAYXE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "511966b0-a6fe-48ee-b4ce-55774b6e0808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ue8xgu9WpuPi",
    "outputId": "fc5f62c8-d5a1-4e33-846f-9cf4bb8eccea"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from markitdown import MarkItDown\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "import requests\n",
    "import json\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5,\n",
    "                                  search_depth='advanced',\n",
    "                                  include_answer=False,\n",
    "                                  include_raw_content=True)\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\"\n",
    "})\n",
    "md = MarkItDown(requests_session=session)\n",
    "\n",
    "@tool\n",
    "def search_web_extract_info(query: str) -> list:\n",
    "    \"\"\"Search the web for a query and extracts useful information from the search links.\"\"\"\n",
    "    print('Calling web search tool')\n",
    "    results = tavily_tool.invoke(query)\n",
    "    docs = []\n",
    "\n",
    "    def extract_content(url):\n",
    "        \"\"\"Helper function to extract content from a URL.\"\"\"\n",
    "        extracted_info = md.convert(url)\n",
    "        text_title = extracted_info.title.strip()\n",
    "        text_content = extracted_info.text_content.strip()\n",
    "        return text_title + '\\n' + text_content\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for result in tqdm(results):\n",
    "            try:\n",
    "                future = executor.submit(extract_content, result['url'])\n",
    "                # Wait for up to 60 seconds for the task to complete\n",
    "                content = future.result(timeout=60)\n",
    "                docs.append(content)\n",
    "            except TimeoutError:\n",
    "                print(f\"Extraction timed out for url: {result['url']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting from url: {result['url']} - {e}\")\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(query: str) -> list:\n",
    "    \"\"\"Search weatherapi to get the current weather of the queried location.\"\"\"\n",
    "    print('Calling weather tool')\n",
    "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
    "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
    "\n",
    "    response = requests.get(complete_url)\n",
    "    data = response.json()\n",
    "    if data.get(\"location\"):\n",
    "        return data\n",
    "    else:\n",
    "        return \"Weather Data Not Found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c817534-54c9-468a-b013-f20fe32be58d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "c7kvwG3SmREW"
   },
   "source": [
    "## Build and Test AI Agent\n",
    "\n",
    "Now that we have defined the tools and the LLM, we can create the agent. We will be using a tool calling agent to bind the tools to the agent with a prompt. We will also add in the capability to store historical conversations as memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a53433b-ef50-40b9-8065-5c6edc0c9d66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grNq1I6_5dxC",
    "outputId": "42022951-93f7-4958-e5bf-052567f9f4ec"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"Act as a helpful assistant.\\n                You run in a loop of Thought, Action, PAUSE, Observation.\\n                At the end of the loop, you output an Answer.\\n                Use Thought to describe your thoughts about the question you have been asked.\\n                Use Action to run one of the actions available to you - then return PAUSE.\\n                Observation will be the result of running those actions.\\n                Repeat till you get to the answer for the given user query.\\n\\n                Use the following workflow format:\\n                  Question: the input task you must solve\\n                  Thought: you should always think about what to do\\n                  Action: the action to take which can be any of the following:\\n                            - break it into smaller steps if needed\\n                            - see if you can answer the given task with your trained knowledge\\n                            - call the most relevant tools at your disposal mentioned below in case you need more information\\n                  Action Input: the input to the action\\n                  Observation: the result of the action\\n                  ... (this Thought/Action/Action Input/Observation can repeat N times)\\n                  Thought: I now know the final answer\\n                  Final Answer: the final answer to the original input question\\n\\n                Tools at your disposal to perform tasks as needed:\\n                  - get_weather: whenever user asks get the weather of a place.\\n                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\\n             \"), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "SYS_PROMPT = \"\"\"Act as a helpful assistant.\n",
    "                You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "                At the end of the loop, you output an Answer.\n",
    "                Use Thought to describe your thoughts about the question you have been asked.\n",
    "                Use Action to run one of the actions available to you - then return PAUSE.\n",
    "                Observation will be the result of running those actions.\n",
    "                Repeat till you get to the answer for the given user query.\n",
    "\n",
    "                Use the following workflow format:\n",
    "                  Question: the input task you must solve\n",
    "                  Thought: you should always think about what to do\n",
    "                  Action: the action to take which can be any of the following:\n",
    "                            - break it into smaller steps if needed\n",
    "                            - see if you can answer the given task with your trained knowledge\n",
    "                            - call the most relevant tools at your disposal mentioned below in case you need more information\n",
    "                  Action Input: the input to the action\n",
    "                  Observation: the result of the action\n",
    "                  ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "                  Thought: I now know the final answer\n",
    "                  Final Answer: the final answer to the original input question\n",
    "\n",
    "                Tools at your disposal to perform tasks as needed:\n",
    "                  - get_weather: whenever user asks get the weather of a place.\n",
    "                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\n",
    "             \"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
    "        (\"human\", \"{query}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_template.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0932ee03-dc70-452e-b4ce-9c6c7f16f442",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jlJwVepDmsZw"
   },
   "source": [
    "Now, we can initalize the agent with the LLM, the prompt, and the tools.\n",
    "\n",
    "The agent is responsible for taking in input and deciding what actions to take.\n",
    "\n",
    "REMEMBER the Agent does not execute those actions - that is done by the AgentExecutor\n",
    "\n",
    "Note that we are passing in the model `chatgpt`, not `chatgpt_with_tools`.\n",
    "\n",
    "That is because `create_tool_calling_agent` will call `.bind_tools` for us under the hood.\n",
    "\n",
    "This should ideally be used with an LLM which supports tool \\ function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3d65001-dccb-4fd1-b5dc-84fc84ad912f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "u4NMA82HpueH"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "tools = [search_web_extract_info, get_weather]\n",
    "agent = create_tool_calling_agent(chatgpt, tools, prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "870e8f11-7b15-4bed-a452-cbab809c97ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "TiL70NCrmkkW"
   },
   "source": [
    "Finally, we combine the `agent` (the brains) with the `tools` inside the `AgentExecutor` (which will repeatedly call the agent and execute tools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa7208ad-1292-40e3-8418-bfb753b659ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "vAuGe5G5pugJ"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent,\n",
    "                               tools=tools,\n",
    "                               early_stopping_method='force',\n",
    "                               max_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f2505e9-5bac-4d89-9ad9-f5709a416983",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "OXqgT0Yth892",
    "outputId": "deb88704-907a-4a18-fa21-02e0c69d05d5"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"As of my last update, Nvidia's Q4 2024 earnings call has not occurred. However, I can provide a general outline of what is typically discussed during such earnings calls. When Nvidia holds its Q4 2024 earnings call, you can expect the following key points to be covered:\\n\\n1. **Financial Performance**: Discussion of revenue, net income, earnings per share, and other key financial metrics compared to previous quarters and the same quarter in the prior year.\\n\\n2. **Segment Performance**: Insights into the performance of different business segments, such as gaming, data center, professional visualization, and automotive.\\n\\n3. **Market Trends**: Commentary on market conditions affecting Nvidia's business, including demand for GPUs, AI, and other technologies.\\n\\n4. **Product Updates**: Information on recent product launches, updates, and future product roadmaps.\\n\\n5. **Strategic Initiatives**: Discussion of strategic priorities, including partnerships, acquisitions, and investments in research and development.\\n\\n6. **Guidance**: Forward-looking statements regarding expectations for the next quarter and the fiscal year, including revenue and margin forecasts.\\n\\n7. **Q&A Session**: Responses to questions from analysts and investors, providing additional insights into Nvidia's operations and strategy.\\n\\nFor the most accurate and detailed information, you should refer to the official transcript or recording of the earnings call once it is available.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\"\"\n",
    "response = chatgpt.invoke(query)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13d974fc-c1a8-45b1-9f1b-7a6c6ca2908b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07nRAXEwY7Ea",
    "outputId": "0510692b-15ea-42dd-a52d-9957f939f8b9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling web search tool\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:01<00:07,  1.98s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting from url: https://thetranscript.net/transcript/5857/nvidia-q4-2024-earnings-call-transcript - 'NoneType' object has no attribute 'strip'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:05<00:01,  1.45s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting from url: https://www.earningscall.ai/stock/analyze/NVDA-2024-Q4 - 'NoneType' object has no attribute 'strip'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\"\"\n",
    "response = agent_executor.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6003a99-4185-4c3b-90e0-18bf5db7d7f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ne8x7JqGPMmf",
    "outputId": "55f31718-3876-4385-976b-fa8e1a9eb57c"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'query': \"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\",\n",
       " 'output': \"In Nvidia's Q4 2024 earnings call, several key points were highlighted:\\n\\n1. **Record Financial Performance**: Nvidia reported a record quarterly revenue of $22.1 billion, a 22% increase from the previous quarter and a 265% increase year-over-year. The full-year revenue reached $60.9 billion, up 126% from the previous year.\\n\\n2. **Data Center Growth**: The data center segment achieved a record $18.4 billion in revenue for the quarter, marking a 27% rise from Q3 and a 409% year-over-year growth. This growth was driven by the demand for Nvidia's Hopper GPU computing platform and InfiniBand networking.\\n\\n3. **AI and Accelerated Computing**: Nvidia emphasized the transition from general-purpose to accelerated computing, driven by the demand for AI and generative AI applications. The company is focusing on AI factories and AI infrastructure to support this shift.\\n\\n4. **Gross Margin and Profitability**: The gross margin improved to 76.0% in Q4, up from 74.0% in Q3 and 63.3% the previous year. Net income for Q4 was $12.3 billion, a 33% increase from Q3 and a 769% increase year-over-year.\\n\\n5. **Gaming and Other Segments**: Gaming revenue was $2.87 billion, up 56% year-over-year. Nvidia also reported growth in its Pro Visualization and Automotive segments.\\n\\n6. **Future Outlook**: Nvidia anticipates Q1 fiscal 2025 revenue to be around $24 billion, with continued growth in data center and Pro Visualization segments. The company expects gross margins to remain strong.\\n\\n7. **Challenges and Innovations**: Nvidia acknowledged the challenges in the semiconductor industry, including rapid technological advancements and competition. The company is focusing on innovation and new product cycles to maintain its market position.\\n\\nOverall, Nvidia's Q4 2024 earnings call highlighted the company's strong financial performance, driven by its leadership in AI and accelerated computing, and its strategic focus on innovation and growth across various sectors.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34996506-44bf-4766-9d47-d9cf247a52ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "H2_MM2jrPRya",
    "outputId": "11c6065b-3c22-4509-e643-f2e97e1ab370"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "In Nvidia's Q4 2024 earnings call, several key points were highlighted:\n",
       "\n",
       "1. **Record Financial Performance**: Nvidia reported a record quarterly revenue of $22.1 billion, a 22% increase from the previous quarter and a 265% increase year-over-year. The full-year revenue reached $60.9 billion, up 126% from the previous year.\n",
       "\n",
       "2. **Data Center Growth**: The data center segment achieved a record $18.4 billion in revenue for the quarter, marking a 27% rise from Q3 and a 409% year-over-year growth. This growth was driven by the demand for Nvidia's Hopper GPU computing platform and InfiniBand networking.\n",
       "\n",
       "3. **AI and Accelerated Computing**: Nvidia emphasized the transition from general-purpose to accelerated computing, driven by the demand for AI and generative AI applications. The company is focusing on AI factories and AI infrastructure to support this shift.\n",
       "\n",
       "4. **Gross Margin and Profitability**: The gross margin improved to 76.0% in Q4, up from 74.0% in Q3 and 63.3% the previous year. Net income for Q4 was $12.3 billion, a 33% increase from Q3 and a 769% increase year-over-year.\n",
       "\n",
       "5. **Gaming and Other Segments**: Gaming revenue was $2.87 billion, up 56% year-over-year. Nvidia also reported growth in its Pro Visualization and Automotive segments.\n",
       "\n",
       "6. **Future Outlook**: Nvidia anticipates Q1 fiscal 2025 revenue to be around $24 billion, with continued growth in data center and Pro Visualization segments. The company expects gross margins to remain strong.\n",
       "\n",
       "7. **Challenges and Innovations**: Nvidia acknowledged the challenges in the semiconductor industry, including rapid technological advancements and competition. The company is focusing on innovation and new product cycles to maintain its market position.\n",
       "\n",
       "Overall, Nvidia's Q4 2024 earnings call highlighted the company's strong financial performance, driven by its leadership in AI and accelerated computing, and its strategic focus on innovation and growth across various sectors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(response['output']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1027b6c0-0c18-4d98-8106-060a76884425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "id": "riHUt00KE_3q",
    "outputId": "23717c5a-f5b4-48a2-bf15-947526b37281"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling web search tool\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.44it/s]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "In Intel's Q4 2024 earnings call, the company reported a profit of $2.7 billion, compared to a loss of $0.7 billion in the same period the previous year. The earnings per share (EPS) were $0.63, up from a loss of $0.16 per share last year. Excluding certain items, adjusted earnings were $2.3 billion or $0.54 per share, surpassing analysts' expectations of $0.45 per share. Revenue for the quarter was $15.4 billion, up from $14.0 billion the previous year. For the next quarter, Intel provided guidance for EPS of $0.13 and revenue between $12.2 billion and $13.2 billion."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"\"\"Summarize the key points discussed in Intel's Q4 2024 earnings call\"\"\"\n",
    "response = agent_executor.invoke({\"query\": query})\n",
    "display(Markdown(response['output']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dfbb5d6-454a-4fe5-a78a-3d946a4e6d16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "id": "GfBHtCzJFKdb",
    "outputId": "383a447a-bc43-401b-921a-a5a36ff8882b"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "To provide an accurate assessment of a company's future outlook, I would need to know which specific companies you are interested in comparing. Please provide the names of the companies you would like to evaluate."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"\"\"which company's future outlook looks to be better?\n",
    "        \"\"\"\n",
    "response = agent_executor.invoke({\"query\": query})\n",
    "display(Markdown(response['output']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce0ede78-16b8-4e5e-ba41-83d9a0cae7db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "DQQAx3B7xrl-"
   },
   "source": [
    "The agent is doing pretty well but unfortunately it doesn't remember conversations. We will use some user-session based memory to store this and dive deeper into this in the next video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f5d0f3d-2769-4cf6-a5b5-1bf70a17fe3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Cw9mxPskx734"
   },
   "source": [
    "## Build and Test Multi-User Conversational AI Agent\n",
    "\n",
    "We will now use `SQLChatMessageHistory` which we learnt in the previous module to store separate conversation histories per user or session.\n",
    "\n",
    "This will help us build a conversational Agentic Chatbot which will be accessed by many users at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc607d28-3d03-4e54-8cc6-1e7df5c1b756",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUG09xD5zd2N",
    "outputId": "d3a5e771-912b-43a4-80b8-0342783dbe54"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'memory.db': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# removes the memory database file - usually not needed\n",
    "# you can run this only when you want to remove ALL conversation histories\n",
    "# ok if you get rm: cannot remove 'memory.db': No such file or directory  because initially no memory exists\n",
    "!rm memory.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c585a8e-90ac-4121-9c47-a57327ad4e88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_XSzUrlyZyFF"
   },
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# used to retrieve conversation history from database\n",
    "# based on a specific user or session ID\n",
    "def get_session_history_db(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
    "\n",
    "# create a conversation chain + agent which can load memory based on specific user or session id\n",
    "agentic_chatbot = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history_db,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# function to call the agent show results per user session\n",
    "from IPython.display import display, Markdown\n",
    "def chat_with_agent(prompt: str, session_id: str):\n",
    "    response = agentic_chatbot.invoke({\"query\": prompt},\n",
    "                                      {'configurable': { 'session_id': session_id}})\n",
    "    display(Markdown(response['output']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5588e326-ca65-4cab-83a8-b03cbe193489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "vYTNL_iJ6ibC"
   },
   "source": [
    "Let's now simulate User 1 using the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e83d54e2-6b9a-4a6d-94b7-39c7f8f44410",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "irMU68Ds0NTm",
    "outputId": "0d251ab7-5e47-4149-b562-2c25b88afbd8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/history.py:608: LangChainDeprecationWarning: `connection_string` was deprecated in LangChain 0.2.2 and will be removed in 1.0. Use connection instead.\n  message_history = self.get_session_history(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling web search tool\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:03,  1.13it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting from url: https://www.earningscall.ai/stock/analyze/NVDA-2024-Q4 - 'NoneType' object has no attribute 'strip'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 40%|████      | 2/5 [00:01<00:02,  1.15it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting from url: https://www.getrecall.ai/summary/earnings-reports/listen-nvidia-delivers-q4-fy24-earnings-call-dollarnvda - 'NoneType' object has no attribute 'strip'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:05<00:01,  1.46s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting from url: https://www.investiment.io/symbols/NVDA/earnings/transcripts/2024/4 - 'NoneType' object has no attribute 'strip'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.06s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting from url: https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/ - 403 Client Error: Forbidden for url: https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "Nvidia's Q4 2024 earnings call highlighted several key points:\n",
       "\n",
       "1. **Financial Performance**: Nvidia reported a record revenue of $22.1 billion for Q4, up 22% sequentially and 265% year-over-year. The fiscal year 2024 revenue was $60.9 billion, up 126% from the previous year.\n",
       "\n",
       "2. **Data Center Growth**: Data center revenue reached $18.4 billion in Q4, driven by the NVIDIA Hopper GPU computing platform and InfiniBand networking. The demand for AI infrastructure, particularly for generative AI and large language models, was a significant growth driver.\n",
       "\n",
       "3. **AI and Generative AI**: Nvidia emphasized the growing adoption of AI across industries, with significant contributions from AI inference. The company is collaborating with major tech firms like Google and Microsoft to enhance AI capabilities.\n",
       "\n",
       "4. **Gaming Sector**: Gaming revenue was $2.87 billion, up 56% year-over-year. Nvidia launched the GeForce RTX 40 Super Series GPUs, which saw strong consumer demand.\n",
       "\n",
       "5. **Automotive and Other Sectors**: Automotive revenue was $281 million, with Nvidia DRIVE platform adoption continuing to grow. The company is also seeing increased demand in healthcare and financial services for AI applications.\n",
       "\n",
       "6. **Geographical Performance**: While growth was strong globally, data center revenue in China declined due to U.S. export control regulations. Nvidia is shipping alternative products to China that do not require a license.\n",
       "\n",
       "7. **Future Outlook**: Nvidia expects Q1 2025 revenue to be around $24 billion, with continued growth in data center and professional visualization sectors.\n",
       "\n",
       "Overall, Nvidia's earnings call underscored its strong financial performance, driven by significant growth in AI and data center sectors, and its strategic collaborations to enhance AI capabilities across various industries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_id = 'john001'\n",
    "prompt = \"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\n",
    "chat_with_agent(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab8315e4-3ccb-412f-8695-b4883ae1a046",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "XT4vtvku0TBW",
    "outputId": "34930943-0543-4f06-bb55-04ab680cca5a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling web search tool\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.46it/s]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "Intel's Q4 2024 earnings call highlighted several key points:\n",
       "\n",
       "1. **Financial Performance**: Intel reported a profit of $2.67 billion for Q4, compared to a loss of $0.7 billion in the same period last year. Earnings per share (EPS) were $0.63, up from a loss of $0.16 per share last year. Adjusted earnings were $2.3 billion or $0.54 per share, exceeding analysts' expectations of $0.45 per share.\n",
       "\n",
       "2. **Revenue**: The company posted revenue of $15.4 billion for Q4, up from $14.0 billion in the same period last year, surpassing the expected $15.14 billion.\n",
       "\n",
       "3. **Guidance**: For the next quarter, Intel provided guidance for EPS of $0.13 and revenue between $12.2 billion and $13.2 billion.\n",
       "\n",
       "4. **Market Conditions**: Intel's performance was bolstered by improvements in its data center and client computing groups, despite ongoing challenges in the PC market.\n",
       "\n",
       "5. **Strategic Initiatives**: Intel continues to focus on its IDM 2.0 strategy, which includes expanding its manufacturing capabilities and investing in new technologies to drive future growth.\n",
       "\n",
       "Overall, Intel's Q4 2024 earnings call reflected a strong recovery from the previous year's losses, with better-than-expected financial results and a positive outlook for the upcoming quarter."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"What about Intel?\"\n",
    "chat_with_agent(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e68cb3b-c73a-4e4c-ad6c-18f7395d7ecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "u-sz15g8YGNA",
    "outputId": "73eec36b-8363-4ddb-a8c8-a9a9c5396153"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "Based on the Q4 2024 earnings calls for both Nvidia and Intel, Nvidia appears to be performing better overall. Here are some key comparisons:\n",
       "\n",
       "1. **Revenue Growth**: Nvidia reported a record revenue of $22.1 billion for Q4, with a significant year-over-year growth of 265%. In contrast, Intel's revenue for Q4 was $15.4 billion, with a more modest increase from the previous year.\n",
       "\n",
       "2. **Profitability**: Nvidia's strong financial performance is highlighted by its substantial revenue growth and profitability driven by its data center and AI sectors. Intel, while profitable, showed a recovery from a previous loss, indicating a turnaround rather than explosive growth.\n",
       "\n",
       "3. **Market Drivers**: Nvidia's growth is largely driven by the booming demand for AI infrastructure and generative AI, areas where it has a strong market position. Intel's growth, while positive, is more focused on recovering from past challenges and stabilizing its core businesses.\n",
       "\n",
       "4. **Future Outlook**: Nvidia's guidance for the next quarter suggests continued strong growth, particularly in data centers and AI. Intel's guidance, while positive, indicates a more cautious outlook with lower expected revenue compared to Nvidia.\n",
       "\n",
       "Overall, Nvidia's performance and growth prospects, particularly in AI and data centers, position it as the stronger performer compared to Intel in this period."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Which company seems to be doing better?\"\n",
    "chat_with_agent(prompt, user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "460542ec-861d-4c33-94e5-3d0eaf8c0ff6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "B4zIlISy6m-x"
   },
   "source": [
    "Let's now simulate User 2 using the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09ed63c9-eb8c-4b7a-b8af-dbbd02c6ee67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "ta1RUF_81RxX",
    "outputId": "c2996859-5fe7-4ef1-bd21-0ee5257afc93"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling weather tool\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "The weather in Bangalore today is as follows:\n",
       "\n",
       "- **Condition**: Mist\n",
       "- **Temperature**: 18.3°C (64.9°F)\n",
       "- **Feels Like**: 18.3°C (64.9°F)\n",
       "- **Wind**: 6.7 mph (10.8 kph) from the East-Southeast (ESE)\n",
       "- **Wind Gusts**: Up to 10.6 mph (17.0 kph)\n",
       "- **Humidity**: 94%\n",
       "- **Cloud Cover**: 50%\n",
       "- **Pressure**: 1016.0 mb (30.0 in)\n",
       "- **Precipitation**: 0.0 mm (0.0 in)\n",
       "- **Visibility**: 2.0 km (1.0 mile)\n",
       "- **UV Index**: 0.4\n",
       "- **Dew Point**: 15.3°C (59.5°F)\n",
       "\n",
       "The weather is currently misty with moderate humidity and low visibility."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_id = 'bond007'\n",
    "prompt = \"how is the weather in Bangalore today? Show detailed statistics\"\n",
    "chat_with_agent(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1606e8c3-7aee-4df3-9270-0d0ac6035546",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "vfn_Wxxg42rZ",
    "outputId": "c695b4fc-0d20-44f8-bfa4-646ac682c9f2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling weather tool\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "The weather in Dubai today is as follows:\n",
       "\n",
       "- **Condition**: Clear\n",
       "- **Temperature**: 16.2°C (61.2°F)\n",
       "- **Feels Like**: 16.2°C (61.2°F)\n",
       "- **Wind**: 12.3 mph (19.8 kph) from the East (E)\n",
       "- **Wind Gusts**: Up to 21.9 mph (35.2 kph)\n",
       "- **Humidity**: 45%\n",
       "- **Cloud Cover**: 0% (Clear skies)\n",
       "- **Pressure**: 1021.0 mb (30.15 in)\n",
       "- **Precipitation**: 0.0 mm (0.0 in)\n",
       "- **Visibility**: 6.0 km (3.0 miles)\n",
       "- **UV Index**: 0.0\n",
       "- **Dew Point**: 5.0°C (41.1°F)\n",
       "\n",
       "The weather is clear with moderate wind and low humidity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_id = 'bond007'\n",
    "prompt = \"what about Dubai?\"\n",
    "chat_with_agent(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7427d4ce-2250-4ac7-b611-78ca94612b77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "I7jjxtmz6Qzi",
    "outputId": "34323085-f10f-4552-a919-98382dc8a812"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "Dubai is currently hotter than Bangalore. The temperature in Dubai is 16.2°C (61.2°F), while in Bangalore, it is 18.3°C (64.9°F)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_id = 'bond007'\n",
    "prompt = \"which city is hotter?\"\n",
    "chat_with_agent(prompt, user_id)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "M3_Build_a_Multi_User_Conversational_Tool_Calling_Agentic_AI_Research_Assistant",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
