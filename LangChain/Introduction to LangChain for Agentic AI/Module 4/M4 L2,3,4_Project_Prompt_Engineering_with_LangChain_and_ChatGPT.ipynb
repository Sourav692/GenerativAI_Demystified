{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "631357b1-327f-45a2-ba4e-87d21ac1a0a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XTzBUFWQ-OWj"
   },
   "source": [
    "# Project: Prompt Engineering with LangChain and ChatGPT for real-world tasks\n",
    "\n",
    "In this notebook you will leverage ChatGPT and LangChain to solve and do a few mini-projects based on some real-world scenarios:\n",
    "\n",
    "- Mini-Project 1: Review Analyst\n",
    "- Mini-Project 2: Research Paper Analyst\n",
    "- Mini-Project 3: Social Media Marketing Analyst\n",
    "- Mini-Project 4: IT Support Analyst\n",
    "\n",
    "___[Created By: Dipanjan (DJ)](https://www.linkedin.com/in/dipanjans/)___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17630c1a-3373-47f8-8fc7-d979a90bf582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L1KvMtf54l0d"
   },
   "source": [
    "## Install OpenAI and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "435dda06-fc9c-49fa-a113-89d5001e06dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.3.11 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (0.3.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain==0.3.11) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain==0.3.11) (2.0.41)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain==0.3.11) (3.12.13)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain==0.3.11) (0.3.63)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain==0.3.11) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain==0.3.11) (0.2.11)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain==0.3.11) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain==0.3.11) (2.11.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain==0.3.11) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain==0.3.11) (9.1.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (6.5.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (1.20.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.11) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.11) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.11) (1.0.0)\n",
      "Requirement already satisfied: anyio in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.11) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.11) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.11) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.3.11) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.3.11) (2.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (1.3.1)\n",
      "Requirement already satisfied: langchain-openai==0.2.12 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (0.2.12)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-openai==0.2.12) (0.3.63)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.55.3 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-openai==0.2.12) (1.57.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-openai==0.2.12) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.2.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (4.13.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.11.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.0.0)\n",
      "Requirement already satisfied: anyio in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2024.11.6)\n",
      "Requirement already satisfied: langchain-community==0.3.11 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (0.3.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (2.0.41)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (3.12.13)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (0.4.1)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.11 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (0.3.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (0.3.63)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (0.2.11)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (2.10.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-community==0.3.11) (9.1.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (6.5.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.11.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.0)\n",
      "Requirement already satisfied: anyio in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.11) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-community==0.3.11) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-community==0.3.11) (2.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sourav.banerjee/Documents/Github Codebase/GenerativAI_Demystified/.venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.3.11\n",
    "!pip install langchain-openai==0.2.12\n",
    "!pip install langchain-community==0.3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa8c790-80ea-4a68-8506-51b8f65d8e1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8435e955-31a4-4b16-855c-1bc0ee15785b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PtBa7rlWJWH3"
   },
   "source": [
    "## Enter API Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28ce8c0c-4c4a-4388-bd3d-c33c31371910",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Y6RD7As2sm8G"
   },
   "source": [
    "#### Enter your Open AI Key here\n",
    "\n",
    "You can get the key from [here](https://platform.openai.com/api-keys) after creating an account or signing in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77980500-15ee-49ce-94c9-353cd7ea2881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ogxBkS6ZnnC",
    "outputId": "4b411016-531d-4c31-85fc-b06cac039cc7"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Please enter your Open AI API Key here: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "baf060a0-9514-4bda-9675-ff1c7d0148c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "T5rOqCyianbP"
   },
   "source": [
    "## Setup necessary system environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c9c861c-d697-4909-8f0b-42dc4708cf3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1PIStD04Zp9p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe0b21d1-f924-4f1f-85de-f4b2332dbe02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "VDWhgxCy5bA6"
   },
   "source": [
    "## Load Necessary Dependencies and ChatGPT LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec502dc1-581b-4620-8773-657411b59920",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9GYhyRFRuJXG"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e827dcff-9c1a-415a-b8dc-495b593c26a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "mY2bapqfuWq1"
   },
   "outputs": [],
   "source": [
    "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f2f1415-d63e-437c-98bc-d236b3b6210b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "AeDkpvGDhMGV"
   },
   "source": [
    "## Mini-Project 1: Review Analyst\n",
    "\n",
    "You are building an AI system to be able to look at customer reviews and do some complex analysis. for each review get ChatGPT to do the following:\n",
    "\n",
    "  - Summarize the review. The summary should be at most 3 lines.\n",
    "  - Highlight both the positives and negatives\n",
    "  - Display the overall sentiment of the review (positive, negative, neutral)\n",
    "  - Display a list of 3 - 5 emotions expressed by the customer in the review\n",
    "  - If the sentiment is positive or neutral write an email and thank them for the review\n",
    "  - If the sentiment is negative apologize and write an email with an appropriate response\n",
    "\n",
    "Try to get the response in a nice structured format using an output parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4446b4cc-f2d7-42e7-a28a-f245b4e17e12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9P_TrLpRAIXM"
   },
   "source": [
    "### Access Customer Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91dc7726-3154-45f5-9526-e70024e68625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "hRbBZB57hT0G"
   },
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    f\"\"\"\n",
    "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
    "    The sound quality is impressively clear with just the right amount of bass.\n",
    "    It's also waterproof, which tested true during a recent splashing incident.\n",
    "    Though it's compact, the volume can really fill the space.\n",
    "    The price was a bargain for such high-quality sound.\n",
    "    Shipping was also on point, arriving two days early in secure packaging.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Purchased a new gaming keyboard because of its rave reviews about responsiveness and backlighting.\n",
    "    It hasn't disappointed. The keys have a satisfying click and the LED colors are vibrant,\n",
    "    enhancing my gaming experience significantly. Price-wise, it's quite competitive,\n",
    "    and I feel like I got a good deal. The delivery was swift, and it came well-protected,\n",
    "    ensuring no damage during transport.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Ordered a set of wireless earbuds for running, and they've been a letdown.\n",
    "    The sound constantly cuts out, and the fit is uncomfortable after only a few minutes of use.\n",
    "    They advertised a 12-hour battery life, but I'm barely getting four hours.\n",
    "    Considering the cost, I expected better quality and performance.\n",
    "    They did arrive on time, but the positives end there. I'm already looking into a return.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    The tablet stand I bought was touted as being sturdy and adjustable,\n",
    "    but it's anything but. It wobbles with the slightest touch,\n",
    "    and the angles are not holding up as promised. It feels like a breeze could knock it over.\n",
    "    It was also pricier than others I've seen, which adds to the disappointment.\n",
    "    It did arrive promptly, but what's the use if the product doesn't meet basic expectations?\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Needed a new kitchen blender, but this model has been a nightmare.\n",
    "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
    "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
    "    I thought the brand meant quality, but this product has proven me wrong.\n",
    "    Plus, it arrived three days late. Definitely not worth the expense.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48828d33-eec3-451d-a9ff-58d94f50563e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Rz9SIYmYALOm"
   },
   "source": [
    "### Define Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6728d78e-6b92-43ee-91f7-3d7cb5833c2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "HK0u7biN7uDh"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define your desired data structure - like a python data class.\n",
    "class ReviewAnalysisResponse(BaseModel):\n",
    "    summary: str = Field(description=\"A brief summary of the customer review with maximum 3 lines\")\n",
    "    positives: list = Field(description=\"A list showing the positives mentioned by the customer in the review if any - max 3 points\")\n",
    "    negatives: list = Field(description=\"A list showing the negatives mentioned by the customer in the review if any - max 3 points\")\n",
    "    sentiment: str = Field(description=\"One word showing the sentiment of the review - positive, negative or neutral\")\n",
    "    emotions: list = Field(description=\"A list of 3 - 5 emotions expressed by the customer in the review\")\n",
    "    email: str = Field(description=\"Detailed email to the customer based on the sentiment\")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=ReviewAnalysisResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95ce0b49-edd7-48b0-b1a1-63cafd4179ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Fc8awL6dAONh"
   },
   "source": [
    "### Create the input prompt for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85ebd6f8-a922-4815-bc3a-9f51d2828a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "0TylxOCZ85O1"
   },
   "outputs": [],
   "source": [
    "# create the final prompt with formatting instructions from the parser\n",
    "prompt_txt = \"\"\"\n",
    "             Analyze the given customer review below and generate the response based on the instructions\n",
    "             mentioned below in the format instructions.\n",
    "             Also remember to write a detailed email response for the email field based on these conditions:\n",
    "               - email should be addressed to Dear Customer and signed with Service Agent\n",
    "               - thank them if the review is positive or neutral\n",
    "               - apologize if the review is negative\n",
    "\n",
    "             Format Instructions:\n",
    "             {format_instructions}\n",
    "\n",
    "             Review:\n",
    "             {review}\n",
    "            \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_txt,\n",
    "    input_variables=[\"review\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fea28ae-bd14-488f-83ca-7d688e51a842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EE0l_m31AQ5k"
   },
   "source": [
    "### Create a LCEL LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cec1070-102a-4e18-8b32-f57a6228be95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "SWfHWjm-9HuD"
   },
   "outputs": [],
   "source": [
    "# create a simple LCEL chain to take the prompt, pass it to the LLM, enforce response format using the parser\n",
    "chain = (prompt\n",
    "           |\n",
    "         chatgpt\n",
    "           |\n",
    "         parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c80d0e2e-ed1c-431c-b1e1-f7aa261c77cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "70ivaPOrATnR"
   },
   "source": [
    "### Format the input reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b02838f-0d84-48eb-8814-2ba7934277b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBPSeLKA9N5M",
    "outputId": "824d7e82-06d4-4ac4-a4d3-8a8f2df74a2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': \"\\n    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\\n    The sound quality is impressively clear with just the right amount of bass.\\n    It's also waterproof, which tested true during a recent splashing incident.\\n    Though it's compact, the volume can really fill the space.\\n    The price was a bargain for such high-quality sound.\\n    Shipping was also on point, arriving two days early in secure packaging.\\n    \"}\n"
     ]
    }
   ],
   "source": [
    "reviews_formatted = [{'review': review} for review in reviews]\n",
    "print(reviews_formatted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a292be73-5595-4b9b-9aac-5c5982adf90b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MHbJvZlYAVcH"
   },
   "source": [
    "### Get responses from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5830a82-3fc0-4976-9484-addc3bc4e983",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tpH9R-iO9Wbq"
   },
   "outputs": [],
   "source": [
    "responses = chain.map().invoke(reviews_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "711040eb-ce85-47d8-ba13-f3d81d51ac63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "z7wS4_lnAYAL"
   },
   "source": [
    "### View LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dab423a5-e5fe-4be7-a4ac-b00d8b4245ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NaC9oaRY-15M",
    "outputId": "2f2b0706-b14e-4af8-9b94-5f8d0901d911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary='The customer is highly satisfied with the Bluetooth speaker, praising its sound quality, waterproof feature, and value for money. They also appreciated the prompt shipping.' positives=['Impressive sound quality with clear audio and good bass', 'Waterproof feature tested successfully', 'Compact size with powerful volume'] negatives=[] sentiment='positive' emotions=['satisfaction', 'happiness', 'excitement'] email=\"Dear Customer,\\n\\nThank you for your wonderful review! We're thrilled to hear that you are enjoying your new Bluetooth speaker and that it met your expectations in terms of sound quality, waterproof capability, and value for money. We also appreciate your feedback on the prompt shipping. If you have any further questions or need assistance, feel free to reach out.\\n\\nBest regards,\\nService Agent\"\n"
     ]
    }
   ],
   "source": [
    "print(responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33873ad6-52a7-40f3-bf14-caefe253d5ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VN7PfKvBbGZV",
    "outputId": "fc05d56f-7586-433a-be5a-fcc8ff63ce6d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/xkrl1q210t5_4t4hvbx286800000gp/T/ipykernel_70281/632561186.py:1: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  responses[0].dict()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary': 'The customer is highly satisfied with the Bluetooth speaker, praising its sound quality, waterproof feature, and value for money. They also appreciated the prompt shipping.',\n",
       " 'positives': ['Impressive sound quality with clear audio and good bass',\n",
       "  'Waterproof feature tested successfully',\n",
       "  'Compact size with powerful volume'],\n",
       " 'negatives': [],\n",
       " 'sentiment': 'positive',\n",
       " 'emotions': ['satisfaction', 'happiness', 'excitement'],\n",
       " 'email': \"Dear Customer,\\n\\nThank you for your wonderful review! We're thrilled to hear that you are enjoying your new Bluetooth speaker and that it met your expectations in terms of sound quality, waterproof capability, and value for money. We also appreciate your feedback on the prompt shipping. If you have any further questions or need assistance, feel free to reach out.\\n\\nBest regards,\\nService Agent\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d19cf9-8980-4380-8183-69c685fff176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHJpeC5f9ZfK",
    "outputId": "de7bfe78-63db-45c5-c40b-493a9f714538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary:\n",
      "The customer is highly satisfied with the Bluetooth speaker, praising its sound quality, waterproof feature, and value for money. They also appreciated the prompt shipping.\n",
      "positives:\n",
      "['Impressive sound quality with clear audio and good bass', 'Waterproof feature tested successfully', 'Compact size with powerful volume']\n",
      "negatives:\n",
      "[]\n",
      "sentiment:\n",
      "positive\n",
      "emotions:\n",
      "['satisfaction', 'happiness', 'excitement']\n",
      "email:\n",
      "Dear Customer,\n",
      "\n",
      "Thank you for your wonderful review! We're thrilled to hear that you are enjoying your new Bluetooth speaker and that it met your expectations in terms of sound quality, waterproof capability, and value for money. We also appreciate your feedback on the prompt shipping. If you have any further questions or need assistance, feel free to reach out.\n",
      "\n",
      "Best regards,\n",
      "Service Agent\n",
      "-----\n",
      "\n",
      "\n",
      "summary:\n",
      "The customer is highly satisfied with their new gaming keyboard, praising its responsiveness, backlighting, and competitive pricing. They also appreciated the swift delivery and protective packaging.\n",
      "positives:\n",
      "['Responsive keys with a satisfying click', 'Vibrant LED colors enhancing gaming experience', 'Competitive pricing and good deal']\n",
      "negatives:\n",
      "[]\n",
      "sentiment:\n",
      "positive\n",
      "emotions:\n",
      "['satisfaction', 'excitement', 'contentment']\n",
      "email:\n",
      "Dear Customer,\n",
      "\n",
      "Thank you for your wonderful review! We are thrilled to hear that you are enjoying your new gaming keyboard and that it has met your expectations in terms of responsiveness and backlighting. It's great to know that you found the pricing competitive and that the delivery was swift and secure.\n",
      "\n",
      "We appreciate your feedback and hope you continue to have an excellent gaming experience with your new keyboard!\n",
      "\n",
      "Best regards,\n",
      "Service Agent\n",
      "-----\n",
      "\n",
      "\n",
      "summary:\n",
      "The customer is disappointed with the wireless earbuds due to sound issues, uncomfortable fit, and poor battery life. They are considering a return.\n",
      "positives:\n",
      "['Arrived on time']\n",
      "negatives:\n",
      "['Sound cuts out', 'Uncomfortable fit', 'Poor battery life']\n",
      "sentiment:\n",
      "negative\n",
      "emotions:\n",
      "['disappointment', 'frustration', 'dissatisfaction']\n",
      "email:\n",
      "Dear Customer,\n",
      "\n",
      "Thank you for your feedback regarding the wireless earbuds. We sincerely apologize for the issues you've experienced with the sound quality, fit, and battery life. Your satisfaction is important to us, and we understand how disappointing it can be when a product does not meet your expectations. \n",
      "\n",
      "Please let us know if you would like assistance with the return process or if there is anything else we can do to help.\n",
      "\n",
      "Best regards,\n",
      "Service Agent\n",
      "-----\n",
      "\n",
      "\n",
      "summary:\n",
      "The customer expressed disappointment with the tablet stand's stability and adjustability, stating it wobbles easily and does not hold angles well. They also found it overpriced despite prompt delivery.\n",
      "positives:\n",
      "['Arrived promptly']\n",
      "negatives:\n",
      "['Wobbles with slightest touch', 'Angles do not hold up', 'Pricier than others']\n",
      "sentiment:\n",
      "negative\n",
      "emotions:\n",
      "['disappointment', 'frustration', 'dissatisfaction']\n",
      "email:\n",
      "Dear Customer,\n",
      "\n",
      "Thank you for your feedback regarding the tablet stand. We sincerely apologize for the disappointment you experienced with its stability and adjustability. Your concerns are important to us, and we will address them with our product team to ensure improvements are made. If you have any further questions or need assistance, please feel free to reach out.\n",
      "\n",
      "Best regards,\n",
      "Service Agent\n",
      "-----\n",
      "\n",
      "\n",
      "summary:\n",
      "The customer is dissatisfied with the kitchen blender, citing performance issues, noise, and delivery delays.\n",
      "positives:\n",
      "[]\n",
      "negatives:\n",
      "['Struggles with tougher foods', 'Incredibly noisy', \"'Easy-clean' feature is ineffective\", 'Arrived three days late']\n",
      "sentiment:\n",
      "negative\n",
      "emotions:\n",
      "['frustration', 'disappointment', 'anger']\n",
      "email:\n",
      "Dear Customer,\n",
      "\n",
      "Thank you for taking the time to share your feedback regarding the kitchen blender. We sincerely apologize for the issues you have experienced with its performance, noise level, and the delivery delay. Your satisfaction is important to us, and we are committed to addressing your concerns. \n",
      "\n",
      "Please feel free to reach out to us for any further assistance or to discuss a possible resolution. \n",
      "\n",
      "Thank you for your understanding.\n",
      "\n",
      "Best regards,\n",
      "Service Agent\n",
      "-----\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/xkrl1q210t5_4t4hvbx286800000gp/T/ipykernel_70281/2992996444.py:2: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  for k,v in response.dict().items():\n"
     ]
    }
   ],
   "source": [
    "for response in responses:\n",
    "  for k,v in response.dict().items():\n",
    "    print(f'{k}:\\n{v}')\n",
    "  print('-----')\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e2bed6f-33a4-4553-b276-80b15507fd7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "4VgCY3aV-7AI",
    "outputId": "252507c5-ecfa-4fff-f47e-34e42f92ba2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/xkrl1q210t5_4t4hvbx286800000gp/T/ipykernel_70281/1175396765.py:3: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  pd.DataFrame(response.dict() for response in responses)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>emotions</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The customer is highly satisfied with the Blue...</td>\n",
       "      <td>[Impressive sound quality with clear audio and...</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[satisfaction, happiness, excitement]</td>\n",
       "      <td>Dear Customer,\\n\\nThank you for your wonderful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The customer is highly satisfied with their ne...</td>\n",
       "      <td>[Responsive keys with a satisfying click, Vibr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[satisfaction, excitement, contentment]</td>\n",
       "      <td>Dear Customer,\\n\\nThank you for your wonderful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The customer is disappointed with the wireless...</td>\n",
       "      <td>[Arrived on time]</td>\n",
       "      <td>[Sound cuts out, Uncomfortable fit, Poor batte...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[disappointment, frustration, dissatisfaction]</td>\n",
       "      <td>Dear Customer,\\n\\nThank you for your feedback ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The customer expressed disappointment with the...</td>\n",
       "      <td>[Arrived promptly]</td>\n",
       "      <td>[Wobbles with slightest touch, Angles do not h...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[disappointment, frustration, dissatisfaction]</td>\n",
       "      <td>Dear Customer,\\n\\nThank you for your feedback ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The customer is dissatisfied with the kitchen ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Struggles with tougher foods, Incredibly nois...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[frustration, disappointment, anger]</td>\n",
       "      <td>Dear Customer,\\n\\nThank you for taking the tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  The customer is highly satisfied with the Blue...   \n",
       "1  The customer is highly satisfied with their ne...   \n",
       "2  The customer is disappointed with the wireless...   \n",
       "3  The customer expressed disappointment with the...   \n",
       "4  The customer is dissatisfied with the kitchen ...   \n",
       "\n",
       "                                           positives  \\\n",
       "0  [Impressive sound quality with clear audio and...   \n",
       "1  [Responsive keys with a satisfying click, Vibr...   \n",
       "2                                  [Arrived on time]   \n",
       "3                                 [Arrived promptly]   \n",
       "4                                                 []   \n",
       "\n",
       "                                           negatives sentiment  \\\n",
       "0                                                 []  positive   \n",
       "1                                                 []  positive   \n",
       "2  [Sound cuts out, Uncomfortable fit, Poor batte...  negative   \n",
       "3  [Wobbles with slightest touch, Angles do not h...  negative   \n",
       "4  [Struggles with tougher foods, Incredibly nois...  negative   \n",
       "\n",
       "                                         emotions  \\\n",
       "0           [satisfaction, happiness, excitement]   \n",
       "1         [satisfaction, excitement, contentment]   \n",
       "2  [disappointment, frustration, dissatisfaction]   \n",
       "3  [disappointment, frustration, dissatisfaction]   \n",
       "4            [frustration, disappointment, anger]   \n",
       "\n",
       "                                               email  \n",
       "0  Dear Customer,\\n\\nThank you for your wonderful...  \n",
       "1  Dear Customer,\\n\\nThank you for your wonderful...  \n",
       "2  Dear Customer,\\n\\nThank you for your feedback ...  \n",
       "3  Dear Customer,\\n\\nThank you for your feedback ...  \n",
       "4  Dear Customer,\\n\\nThank you for taking the tim...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(response.dict() for response in responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c62b2da-54eb-4bfa-aabc-22caf3da177c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "eEtB1IOimA0i"
   },
   "source": [
    "## Mini-Project 2: Research Paper Analyst\n",
    "\n",
    "Make ChatGPT act as an AI expert and transform the given research paper abstract based on the nature of the audience mentioned below.\n",
    "\n",
    "- Short summary of maximum 10 lines for a general audience\n",
    "- Detailed report for a healthcare company. Have bullet points for pros and cons of ethics in Generative AI as mentioned in the paper\n",
    "- Detailed report for a generative AI company solving healthcare problems. Have bullet points for key points mentioned for Generative AI for text, images and structured data based healthcare\n",
    "\n",
    "Try to use `ChatPromptTemplate` so you can have a conversation with ChatGPT for each of the above tasks using conversational prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97a9aa69-8d76-4b87-849f-8d7c6cccd99d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gjiheMsOMUO6"
   },
   "source": [
    "### Access the Research Paper Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1abe7ebc-646d-494b-9989-964ae29ab6c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4FnITE6zhV-9"
   },
   "outputs": [],
   "source": [
    "paper_abstract = f\"\"\"\n",
    "The widespread use of ChatGPT and other emerging technology powered by generative\n",
    "artificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\n",
    "high-stakes applications such as healthcare.13 However, less clear is how to resolve such\n",
    "issues beyond following guidelines and regulations that are still under discussion and\n",
    "development. On the other hand, other types of generative AI have been used to synthesize\n",
    "images and other types of data for research and practical purposes, which have resolved some\n",
    "ethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\n",
    "of ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\n",
    "generative AI via a systematic scoping review of relevant existing research in healthcare, and\n",
    "reduce the gaps by proposing an ethics checklist for comprehensive assessment and\n",
    "transparent documentation of ethical discussions in generative AI development. While the\n",
    "checklist can be readily integrated into the current peer review and publication system to\n",
    "enhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\n",
    "products) to help users establish reasonable trust in their capabilities.\n",
    "\n",
    "Current ethical discussions on generative AI in healthcare\n",
    "We conducted a systematic scoping review to analyse current ethical discussions on\n",
    "generative AI in healthcare. Our search in four major academic research databases for\n",
    "relevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\n",
    "detailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\n",
    "which 193 articles were included for analysis based on application data modality (text, image,\n",
    "or structured data), ethical issues discussed, generative AI involved, and whether generative\n",
    "AI causes or offers technical solutions for issues raised.\n",
    "\n",
    "Generative AI for text data-based healthcare\n",
    "Forty-one of the 193 articles discussed ethical considerations pertaining to generative AI\n",
    "applications for text data, with 20 articles describing methodological developments or\n",
    "applications of generative AI and the other 21 articles describing review-type works on this\n",
    "topic. Although some of these review-type articles used the general term generative AI, the\n",
    "main body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\n",
    "discussions on ethical issues, whereas the other 12 articles only briefly touched on some\n",
    "ethical aspects.\n",
    "Among the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\n",
    "specifically by GPT in 16 of the articles), covering a wide range of application scenarios and\n",
    "considered the application of all 10 ethical principles identified in the review (see Figure 1),\n",
    "as well as other less discussed concerns such as human-AI interaction, and the rights of\n",
    "LLMs to be considered as co-authors in scientific papers. One paper only commented briefly\n",
    "on the need for ethical considerations in LLMs and is summarised in the Others category.\n",
    "Although all ethical principles are equally important, some are discussed more often than\n",
    "others, e.g., non-maleficence (also referred to in the literature as benevolence), equity, and\n",
    "privacy.\n",
    "Fifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\n",
    "confidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\n",
    "autoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\n",
    "medical text, to reduce disparity by providing accessible services and assistance, to detect\n",
    "health-related misinformation, to generate trusted content, and to improve accountability or\n",
    "transparency over existing approaches. While most articles focused on either identifying\n",
    "ethical issues caused by generative AI or proposing generative AI-based solutions, three\n",
    "articles discussed both to provide a more balanced perspective.\n",
    "\n",
    "Generative AI for image and structured data-based healthcare\n",
    "Unlike the diverse application scenarios of generative AI based on text data, for image and\n",
    "structured data, this use of generative AI focuses on data synthesis and encryption. Hence the\n",
    "majority of articles discussed the methodological developments of generative AI as giving\n",
    "rise to a more distinctive and focused set of ethical issues.\n",
    "5\n",
    "Notably, of the 98 articles on image data and 58 articles on structured data, more than half\n",
    "(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\n",
    "brief motivation for methodological developments or as a general discussion point. The rest\n",
    "included more in-depth discussions or evaluations of ethical issues. Among these 155 articles\n",
    "(as one article covered multiple modalities), 11 articles were review-type work, where 10\n",
    "articles reviewed methods that mentioned one or two ethical perspectives, and only one\n",
    "article24 discussed detailed ethical concerns on generative AI applications.\n",
    "Resolving privacy issues was the main aim of articles for these two data modalities (n=74 for\n",
    "image data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\n",
    "data using GAN. Eight articles on image data and 9 articles on structured data used\n",
    "generative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\n",
    "existing databases. For both data modalities, we did not see explicit discussions on resolving\n",
    "autonomy, integrity, or morality issues using generative AI, and for structured data the articles\n",
    "additionally lacked discussions on trust or transparency.\n",
    "Only 11 articles for image data selectively discussed some ethical issues that generative AI\n",
    "can give rise to, without specific discussions regarding autonomy, integrity, or morality. For\n",
    "structured data, only 4 articles discussed equity, privacy, or data security issues caused by\n",
    "generative AI. Only two articles on structured data included both the cause and resolving\n",
    "perspectives by discussing ethical issues that may arise from limitations of methods\n",
    "proposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e50c6da-cc3a-4cbc-9b4e-32ab1f71a908",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "sI2cwvpIMaGJ"
   },
   "source": [
    "### Create a prompt template for paper analysis and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8748744d-5a42-440a-8742-96e22ffa9938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "E5S9fvwrYZ6u"
   },
   "outputs": [],
   "source": [
    "SYS_PROMPT = \"\"\"\n",
    "Act as a Artificial Intelligence Expert.\n",
    "Transform the input research paper abstract given below\n",
    "based on the instruction input by the user.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        (\"human\", \"{instruction}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "054eee80-a68d-4b43-8d0e-78337fa755bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['instruction'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\nAct as a Artificial Intelligence Expert.\\nTransform the input research paper abstract given below\\nbased on the instruction input by the user.\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['instruction'], input_types={}, partial_variables={}, template='{instruction}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9248bf5c-d418-415e-87b1-f86eca8ecc1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PqEOQ4VZMfaC"
   },
   "source": [
    "### Create a simple LCEL LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89197ffb-0c8f-41db-b7c5-75f06ebe9881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "uc8fNUiXDUAC"
   },
   "outputs": [],
   "source": [
    "chain = (prompt\n",
    "            |\n",
    "         chatgpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "340696ff-3e84-47ba-a347-09a8e4ecad16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "r2mbR5lfMkF8"
   },
   "source": [
    "### Generate the first summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#         (\"system\", \"Act as an expert in real estate and provide very detailed answers with examples\"),\n",
    "#         (\"human\", \"what is your name?\"),\n",
    "#         (\"ai\", \"my name is AIBot\"),\n",
    "#         (\"human\", \"{user_prompt}\"),\n",
    "# ]\n",
    "# chat_template = ChatPromptTemplate.from_messages(messages)\n",
    "# chain1 = (chat_template\n",
    "#          |\n",
    "#          chatgpt)\n",
    "# resp = chain1.invoke({\"user_prompt\": \"explain commercial real estate to me\"})\n",
    "# # text_prompts = [\"what is your name?\", \"explain commercial real estate to me\"]\n",
    "# # chat_prompts = [chat_template.format(user_prompt=prompt) for prompt in text_prompts]\n",
    "# # chat_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYS_PROMPT = \"\"\"\n",
    "# Act as a Artificial Intelligence Expert.\n",
    "# Transform the input research paper abstract given below\n",
    "# based on the instruction input by the user.\n",
    "# \"\"\"\n",
    "# prompt_txt = f\"\"\"\n",
    "# Based on the following research paper abstract,\n",
    "# create the summary report of maximum 10 lines\n",
    "# for a general audience\n",
    "\n",
    "# Abstract:\n",
    "# {paper_abstract}\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", SYS_PROMPT),\n",
    "#         (\"human\", \"{prompt_txt}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# chain2 = (prompt\n",
    "#          |\n",
    "#          chatgpt)\n",
    "# resp = chain2.invoke({\"prompt_txt\": prompt_txt})\n",
    "# print(resp.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dd56a4a-3a6b-4211-9a04-55e8adb2127b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L8cgurf6Ytds"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_txt = f\"\"\"\n",
    "Based on the following research paper abstract,\n",
    "create the summary report of maximum 10 lines\n",
    "for a general audience\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "messages = [HumanMessage(content=prompt_txt)]\n",
    "user_instruction = {'instruction': messages}\n",
    "\n",
    "response = chain.invoke(user_instruction)\n",
    "messages.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='\\nBased on the following research paper abstract,\\ncreate the summary report of maximum 10 lines\\nfor a general audience\\n\\nAbstract:\\n\\nThe widespread use of ChatGPT and other emerging technology powered by generative\\nartificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\\nhigh-stakes applications such as healthcare.13 However, less clear is how to resolve such\\nissues beyond following guidelines and regulations that are still under discussion and\\ndevelopment. On the other hand, other types of generative AI have been used to synthesize\\nimages and other types of data for research and practical purposes, which have resolved some\\nethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\\nof ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\\ngenerative AI via a systematic scoping review of relevant existing research in healthcare, and\\nreduce the gaps by proposing an ethics checklist for comprehensive assessment and\\ntransparent documentation of ethical discussions in generative AI development. While the\\nchecklist can be readily integrated into the current peer review and publication system to\\nenhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\\nproducts) to help users establish reasonable trust in their capabilities.\\n\\nCurrent ethical discussions on generative AI in healthcare\\nWe conducted a systematic scoping review to analyse current ethical discussions on\\ngenerative AI in healthcare. Our search in four major academic research databases for\\nrelevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\\ndetailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\\nwhich 193 articles were included for analysis based on application data modality (text, image,\\nor structured data), ethical issues discussed, generative AI involved, and whether generative\\nAI causes or offers technical solutions for issues raised.\\n\\nGenerative AI for text data-based healthcare\\nForty-one of the 193 articles discussed ethical considerations pertaining to generative AI\\napplications for text data, with 20 articles describing methodological developments or\\napplications of generative AI and the other 21 articles describing review-type works on this\\ntopic. Although some of these review-type articles used the general term generative AI, the\\nmain body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\\ndiscussions on ethical issues, whereas the other 12 articles only briefly touched on some\\nethical aspects.\\nAmong the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\\nspecifically by GPT in 16 of the articles), covering a wide range of application scenarios and\\nconsidered the application of all 10 ethical principles identified in the review (see Figure 1),\\nas well as other less discussed concerns such as human-AI interaction, and the rights of\\nLLMs to be considered as co-authors in scientific papers. One paper only commented briefly\\non the need for ethical considerations in LLMs and is summarised in the Others category.\\nAlthough all ethical principles are equally important, some are discussed more often than\\nothers, e.g., non-maleficence (also referred to in the literature as benevolence), equity, and\\nprivacy.\\nFifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\\nconfidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\\nautoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\\nmedical text, to reduce disparity by providing accessible services and assistance, to detect\\nhealth-related misinformation, to generate trusted content, and to improve accountability or\\ntransparency over existing approaches. While most articles focused on either identifying\\nethical issues caused by generative AI or proposing generative AI-based solutions, three\\narticles discussed both to provide a more balanced perspective.\\n\\nGenerative AI for image and structured data-based healthcare\\nUnlike the diverse application scenarios of generative AI based on text data, for image and\\nstructured data, this use of generative AI focuses on data synthesis and encryption. Hence the\\nmajority of articles discussed the methodological developments of generative AI as giving\\nrise to a more distinctive and focused set of ethical issues.\\n5\\nNotably, of the 98 articles on image data and 58 articles on structured data, more than half\\n(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\\nbrief motivation for methodological developments or as a general discussion point. The rest\\nincluded more in-depth discussions or evaluations of ethical issues. Among these 155 articles\\n(as one article covered multiple modalities), 11 articles were review-type work, where 10\\narticles reviewed methods that mentioned one or two ethical perspectives, and only one\\narticle24 discussed detailed ethical concerns on generative AI applications.\\nResolving privacy issues was the main aim of articles for these two data modalities (n=74 for\\nimage data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\\ndata using GAN. Eight articles on image data and 9 articles on structured data used\\ngenerative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\\nexisting databases. For both data modalities, we did not see explicit discussions on resolving\\nautonomy, integrity, or morality issues using generative AI, and for structured data the articles\\nadditionally lacked discussions on trust or transparency.\\nOnly 11 articles for image data selectively discussed some ethical issues that generative AI\\ncan give rise to, without specific discussions regarding autonomy, integrity, or morality. For\\nstructured data, only 4 articles discussed equity, privacy, or data security issues caused by\\ngenerative AI. Only two articles on structured data included both the cause and resolving\\nperspectives by discussing ethical issues that may arise from limitations of methods\\nproposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The research paper explores the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The study found that while many articles address ethical issues related to text-based generative AI, discussions on image and structured data are less comprehensive. The authors emphasize the importance of addressing ethical concerns to build trust in AI technologies used in healthcare.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 129, 'prompt_tokens': 1320, 'total_tokens': 1449, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, id='run--af211c6a-5981-4d6d-ac73-9fa6e4f0fe6e-0', usage_metadata={'input_tokens': 1320, 'output_tokens': 129, 'total_tokens': 1449, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e4ffc9d-ac41-496f-a4bd-000d313a7ad0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': [HumanMessage(content='\\nBased on the following research paper abstract,\\ncreate the summary report of maximum 10 lines\\nfor a general audience\\n\\nAbstract:\\n\\nThe widespread use of ChatGPT and other emerging technology powered by generative\\nartificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\\nhigh-stakes applications such as healthcare.13 However, less clear is how to resolve such\\nissues beyond following guidelines and regulations that are still under discussion and\\ndevelopment. On the other hand, other types of generative AI have been used to synthesize\\nimages and other types of data for research and practical purposes, which have resolved some\\nethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\\nof ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\\ngenerative AI via a systematic scoping review of relevant existing research in healthcare, and\\nreduce the gaps by proposing an ethics checklist for comprehensive assessment and\\ntransparent documentation of ethical discussions in generative AI development. While the\\nchecklist can be readily integrated into the current peer review and publication system to\\nenhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\\nproducts) to help users establish reasonable trust in their capabilities.\\n\\nCurrent ethical discussions on generative AI in healthcare\\nWe conducted a systematic scoping review to analyse current ethical discussions on\\ngenerative AI in healthcare. Our search in four major academic research databases for\\nrelevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\\ndetailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\\nwhich 193 articles were included for analysis based on application data modality (text, image,\\nor structured data), ethical issues discussed, generative AI involved, and whether generative\\nAI causes or offers technical solutions for issues raised.\\n\\nGenerative AI for text data-based healthcare\\nForty-one of the 193 articles discussed ethical considerations pertaining to generative AI\\napplications for text data, with 20 articles describing methodological developments or\\napplications of generative AI and the other 21 articles describing review-type works on this\\ntopic. Although some of these review-type articles used the general term generative AI, the\\nmain body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\\ndiscussions on ethical issues, whereas the other 12 articles only briefly touched on some\\nethical aspects.\\nAmong the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\\nspecifically by GPT in 16 of the articles), covering a wide range of application scenarios and\\nconsidered the application of all 10 ethical principles identified in the review (see Figure 1),\\nas well as other less discussed concerns such as human-AI interaction, and the rights of\\nLLMs to be considered as co-authors in scientific papers. One paper only commented briefly\\non the need for ethical considerations in LLMs and is summarised in the Others category.\\nAlthough all ethical principles are equally important, some are discussed more often than\\nothers, e.g., non-maleficence (also referred to in the literature as benevolence), equity, and\\nprivacy.\\nFifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\\nconfidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\\nautoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\\nmedical text, to reduce disparity by providing accessible services and assistance, to detect\\nhealth-related misinformation, to generate trusted content, and to improve accountability or\\ntransparency over existing approaches. While most articles focused on either identifying\\nethical issues caused by generative AI or proposing generative AI-based solutions, three\\narticles discussed both to provide a more balanced perspective.\\n\\nGenerative AI for image and structured data-based healthcare\\nUnlike the diverse application scenarios of generative AI based on text data, for image and\\nstructured data, this use of generative AI focuses on data synthesis and encryption. Hence the\\nmajority of articles discussed the methodological developments of generative AI as giving\\nrise to a more distinctive and focused set of ethical issues.\\n5\\nNotably, of the 98 articles on image data and 58 articles on structured data, more than half\\n(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\\nbrief motivation for methodological developments or as a general discussion point. The rest\\nincluded more in-depth discussions or evaluations of ethical issues. Among these 155 articles\\n(as one article covered multiple modalities), 11 articles were review-type work, where 10\\narticles reviewed methods that mentioned one or two ethical perspectives, and only one\\narticle24 discussed detailed ethical concerns on generative AI applications.\\nResolving privacy issues was the main aim of articles for these two data modalities (n=74 for\\nimage data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\\ndata using GAN. Eight articles on image data and 9 articles on structured data used\\ngenerative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\\nexisting databases. For both data modalities, we did not see explicit discussions on resolving\\nautonomy, integrity, or morality issues using generative AI, and for structured data the articles\\nadditionally lacked discussions on trust or transparency.\\nOnly 11 articles for image data selectively discussed some ethical issues that generative AI\\ncan give rise to, without specific discussions regarding autonomy, integrity, or morality. For\\nstructured data, only 4 articles discussed equity, privacy, or data security issues caused by\\ngenerative AI. Only two articles on structured data included both the cause and resolving\\nperspectives by discussing ethical issues that may arise from limitations of methods\\nproposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\\n\\n', additional_kwargs={}, response_metadata={}), AIMessage(content='The research paper explores the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The review analyzed 2,859 articles, focusing on ethical issues related to text, image, and structured data. While many articles addressed ethical concerns, there remains a lack of comprehensive discussions on autonomy and integrity. The proposed checklist could help users better understand and trust generative AI technologies.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 139, 'prompt_tokens': 1320, 'total_tokens': 1459, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, id='run--eed958d2-c3ba-4dcd-820a-36a83053e625-0', usage_metadata={'input_tokens': 1320, 'output_tokens': 139, 'total_tokens': 1459, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "print(user_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2beb66f5-c998-4f7c-abef-05f4c14fb315",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The increasing use of generative artificial intelligence (AI), such as ChatGPT, raises important ethical concerns, particularly in sensitive fields like healthcare. This research paper reviews existing literature on these ethical issues and identifies gaps in current discussions. It proposes an ethics checklist to help researchers assess and document ethical considerations in generative AI development. The review analyzed 2,859 articles, focusing on applications involving text, images, and structured data. While many articles addressed ethical issues, particularly related to large language models (LLMs), there is a notable lack of comprehensive discussions on privacy, autonomy, and bias in generative AI applications. The proposed checklist aims to enhance transparency and trust in generative AI technologies, benefiting both researchers and users.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize the chat model\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define system prompt for context\n",
    "sys_prompt = \"\"\"Act as an Artificial Intelligence Expert. \n",
    "Transform the input research paper abstract based on the instruction input by the user.\"\"\"\n",
    "\n",
    "# Create a prompt template\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sys_prompt),\n",
    "    (\"human\", \"{instruction}\")\n",
    "])\n",
    "\n",
    "# Define reusable function for invoking chat with instruction\n",
    "def generate_response(instruction_text: str) -> str:\n",
    "    messages = [HumanMessage(content=instruction_text)]\n",
    "    user_instruction = {'instruction': messages}\n",
    "    return chatgpt.invoke(chat_prompt.format_messages(**user_instruction))\n",
    "\n",
    "# Example research paper abstract\n",
    "paper_abstract = paper_abstract\n",
    "\n",
    "# First task: Create a summary report\n",
    "summary_instruction = f\"\"\"\n",
    "Based on the following research paper abstract, create a summary report of maximum 10 lines for a general audience.\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "response = generate_response(summary_instruction)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "913c4990-d759-4f3d-a320-da307661ff22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Report:\n",
      " Sure! Please provide the content of the research paper abstract that you would like me to summarize.\n",
      "Detailed Report:\n",
      " Sure! Please provide the research paper abstract you would like me to transform into a detailed report for a healthcare company.\n",
      "content='Please provide the content of the research paper abstract that you would like me to transform into a summary report.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 63, 'total_tokens': 84, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None} id='run--f791e037-1fb6-468e-9557-d285eb256a8a-0' usage_metadata={'input_tokens': 63, 'output_tokens': 21, 'total_tokens': 84, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize the chat model\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define system-level prompt for context\n",
    "SYS_PROMPT = \"\"\"Act as an Artificial Intelligence Expert. \n",
    "Transform the input research paper abstract based on the instruction input by the user.\"\"\"\n",
    "\n",
    "# Create a chat prompt template\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYS_PROMPT),\n",
    "    (\"human\", \"{instruction}\")\n",
    "])\n",
    "\n",
    "# Build a chain for processing messages\n",
    "chain = chat_prompt | chatgpt\n",
    "\n",
    "# Define reusable function to interact with the chain\n",
    "def generate_response(instruction_text: str) -> str:\n",
    "    # Create a human message\n",
    "    messages = [HumanMessage(content=instruction_text)]\n",
    "    # Wrap messages in instruction dictionary as required\n",
    "    user_instruction = {'instruction': messages}\n",
    "    # Invoke the chain and return the response\n",
    "    response = chain.invoke(user_instruction)\n",
    "    return response.content\n",
    "\n",
    "# Example research paper abstract\n",
    "paper_abstract = \"\"\"(Long abstract content here)\"\"\"\n",
    "\n",
    "# First task: Create a summary report\n",
    "summary_instruction = f\"\"\"\n",
    "Based on the following research paper abstract, create a summary report of maximum 10 lines for a general audience.\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "summary_response = generate_response(summary_instruction)\n",
    "print(\"Summary Report:\\n\", summary_response)\n",
    "\n",
    "# Second task: Detailed report for a healthcare company\n",
    "detailed_instruction = f\"\"\"\n",
    "Using only the research paper abstract provided earlier, create a detailed report for a healthcare company.\n",
    "Include bullet points (3 max) for pros and cons of ethics in Generative AI.\n",
    "\"\"\"\n",
    "detailed_response = generate_response(detailed_instruction)\n",
    "print(\"Detailed Report:\\n\", detailed_response)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define system-level behavior for AI\n",
    "sys_prompt = \"\"\"Act as an Artificial Intelligence Expert. Transform the input research paper abstract based on the instruction input by the user.\"\"\"\n",
    "messages = [SystemMessage(content=sys_prompt)]\n",
    "\n",
    "# First user instruction\n",
    "paper_abstract = paper_abstract\n",
    "prompt_txt = f\"\"\"\n",
    "Based on the following research paper abstract, create the summary report of maximum 10 lines for a general audience\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "messages.append(HumanMessage(content=prompt_txt))\n",
    "response = chatgpt.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b5019cd-a968-4f9a-807b-210826bb6bc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVE4atsREzfp",
    "outputId": "76f21ec3-ee14-4fcb-c0ea-5f9066104b01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the content of the research paper abstract that you would like me to transform into a summary report.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f54d7b2a-ef61-478d-bfb8-12f982a4fe22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XYxJPOkdP9p",
    "outputId": "44e22b33-6d87-42f9-c436-85429ced96d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Act as an Artificial Intelligence Expert. Transform the input research paper abstract based on the instruction input by the user.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='\\nBased on the following research paper abstract, create the summary report of maximum 10 lines for a general audience\\n\\nAbstract:\\n(Long abstract content here)\\n', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "060e4ee5-77ad-4757-b303-c7fb261d76ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Us1V2RJQM_ry"
   },
   "source": [
    "### Generate the second summary report\n",
    "\n",
    "Here we add the previous LLM response and the new instructions to the list of messages and send the whole thing to the LLM so it has access to the historical conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b939d2-af64-4ff9-bc0b-49bc3e93e642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "X_wqbVYOI42b"
   },
   "outputs": [],
   "source": [
    "prompt_txt = f\"\"\"\n",
    "Use only the research paper abstract from earlier and create a detailed report for a healthcare company.\n",
    "In the report, also include bullet points (3 max) for pros and cons of ethics in Generative AI\n",
    "\"\"\"\n",
    "messages.append(HumanMessage(content=prompt_txt))\n",
    "user_instruction = {'instruction': messages}\n",
    "response = chain.invoke(user_instruction)\n",
    "messages.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1e74e0a-96bc-4a68-b06e-93f85895bcec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "up-RtmIfFrAV",
    "outputId": "5f99582f-6492-48fd-feac-a84003df4232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Please provide the actual content of the research paper abstract so I can assist you in transforming it into a summary report for a general audience and a detailed report for a healthcare company.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c237415-05c3-4929-8e42-1b421b46fe26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cC_wp-OBdxgh",
    "outputId": "6372b9a9-67c5-4745-b5ce-d64e16021521"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='\\nBased on the following research paper abstract,\\ncreate the summary report of maximum 10 lines\\nfor a general audience\\n\\nAbstract:\\n\\nThe widespread use of ChatGPT and other emerging technology powered by generative\\nartificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\\nhigh-stakes applications such as healthcare.13 However, less clear is how to resolve such\\nissues beyond following guidelines and regulations that are still under discussion and\\ndevelopment. On the other hand, other types of generative AI have been used to synthesize\\nimages and other types of data for research and practical purposes, which have resolved some\\nethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\\nof ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\\ngenerative AI via a systematic scoping review of relevant existing research in healthcare, and\\nreduce the gaps by proposing an ethics checklist for comprehensive assessment and\\ntransparent documentation of ethical discussions in generative AI development. While the\\nchecklist can be readily integrated into the current peer review and publication system to\\nenhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\\nproducts) to help users establish reasonable trust in their capabilities.\\n\\nCurrent ethical discussions on generative AI in healthcare\\nWe conducted a systematic scoping review to analyse current ethical discussions on\\ngenerative AI in healthcare. Our search in four major academic research databases for\\nrelevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\\ndetailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\\nwhich 193 articles were included for analysis based on application data modality (text, image,\\nor structured data), ethical issues discussed, generative AI involved, and whether generative\\nAI causes or offers technical solutions for issues raised.\\n\\nGenerative AI for text data-based healthcare\\nForty-one of the 193 articles discussed ethical considerations pertaining to generative AI\\napplications for text data, with 20 articles describing methodological developments or\\napplications of generative AI and the other 21 articles describing review-type works on this\\ntopic. Although some of these review-type articles used the general term generative AI, the\\nmain body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\\ndiscussions on ethical issues, whereas the other 12 articles only briefly touched on some\\nethical aspects.\\nAmong the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\\nspecifically by GPT in 16 of the articles), covering a wide range of application scenarios and\\nconsidered the application of all 10 ethical principles identified in the review (see Figure 1),\\nas well as other less discussed concerns such as human-AI interaction, and the rights of\\nLLMs to be considered as co-authors in scientific papers. One paper only commented briefly\\non the need for ethical considerations in LLMs and is summarised in the Others category.\\nAlthough all ethical principles are equally important, some are discussed more often than\\nothers, e.g., non-maleficence (also referred to in the literature as benevolence), equity, and\\nprivacy.\\nFifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\\nconfidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\\nautoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\\nmedical text, to reduce disparity by providing accessible services and assistance, to detect\\nhealth-related misinformation, to generate trusted content, and to improve accountability or\\ntransparency over existing approaches. While most articles focused on either identifying\\nethical issues caused by generative AI or proposing generative AI-based solutions, three\\narticles discussed both to provide a more balanced perspective.\\n\\nGenerative AI for image and structured data-based healthcare\\nUnlike the diverse application scenarios of generative AI based on text data, for image and\\nstructured data, this use of generative AI focuses on data synthesis and encryption. Hence the\\nmajority of articles discussed the methodological developments of generative AI as giving\\nrise to a more distinctive and focused set of ethical issues.\\n5\\nNotably, of the 98 articles on image data and 58 articles on structured data, more than half\\n(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\\nbrief motivation for methodological developments or as a general discussion point. The rest\\nincluded more in-depth discussions or evaluations of ethical issues. Among these 155 articles\\n(as one article covered multiple modalities), 11 articles were review-type work, where 10\\narticles reviewed methods that mentioned one or two ethical perspectives, and only one\\narticle24 discussed detailed ethical concerns on generative AI applications.\\nResolving privacy issues was the main aim of articles for these two data modalities (n=74 for\\nimage data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\\ndata using GAN. Eight articles on image data and 9 articles on structured data used\\ngenerative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\\nexisting databases. For both data modalities, we did not see explicit discussions on resolving\\nautonomy, integrity, or morality issues using generative AI, and for structured data the articles\\nadditionally lacked discussions on trust or transparency.\\nOnly 11 articles for image data selectively discussed some ethical issues that generative AI\\ncan give rise to, without specific discussions regarding autonomy, integrity, or morality. For\\nstructured data, only 4 articles discussed equity, privacy, or data security issues caused by\\ngenerative AI. Only two articles on structured data included both the cause and resolving\\nperspectives by discussing ethical issues that may arise from limitations of methods\\nproposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The research paper examines the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The study found that while many articles address ethical issues related to text-based generative AI, discussions on image and structured data are less comprehensive. Overall, the paper emphasizes the importance of integrating ethical considerations into the development and use of generative AI technologies.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 1320, 'total_tokens': 1453, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f2cd28694a', 'finish_reason': 'stop', 'logprobs': None}, id='run-17aef32e-02ec-4b82-90ed-74804fc9baa1-0', usage_metadata={'input_tokens': 1320, 'output_tokens': 133, 'total_tokens': 1453, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='\\nUse only the research paper abstract from earlier and create a detailed report for a healthcare company.\\nIn the report, also include bullet points (3 max) for pros and cons of ethics in Generative AI\\n', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='**Detailed Report on Ethical Considerations in Generative AI for Healthcare**\\n\\n**Introduction:**\\nThe rapid adoption of generative artificial intelligence (AI) technologies, such as ChatGPT, has raised significant ethical concerns, particularly in high-stakes fields like healthcare. This report synthesizes findings from a systematic review of existing literature on the ethical implications of generative AI in healthcare, highlighting current gaps and proposing a comprehensive ethics checklist to guide future developments.\\n\\n**Key Findings:**\\n- **Ethical Gaps Identified:** The review revealed that while there is a substantial amount of literature discussing ethical issues related to text-based generative AI, similar discussions for image and structured data applications are less comprehensive. This inconsistency highlights a need for more robust ethical frameworks across all modalities of generative AI.\\n  \\n- **Proposed Ethics Checklist:** To address these gaps, the report proposes an ethics checklist designed for the assessment and documentation of ethical considerations in generative AI development. This checklist can be integrated into existing peer review and publication processes, enhancing transparency and accountability in research and applications.\\n\\n- **Diverse Ethical Issues:** The review categorized ethical discussions into various themes, including privacy, equity, and the rights of AI systems. It was noted that while some articles focused on identifying ethical issues, others proposed generative AI solutions to mitigate these concerns, such as generating synthetic data to protect patient confidentiality.\\n\\n**Pros and Cons of Ethics in Generative AI:**\\n\\n**Pros:**\\n- **Enhanced Trust:** Implementing ethical guidelines can foster trust among users and stakeholders, ensuring that generative AI technologies are used responsibly and transparently.\\n- **Improved Accountability:** A structured approach to ethics can hold developers and organizations accountable for the implications of their AI systems, promoting responsible innovation.\\n- **Guidance for Development:** An ethics checklist provides a clear framework for researchers and developers, helping them navigate complex ethical landscapes and make informed decisions.\\n\\n**Cons:**\\n- **Potential for Stifling Innovation:** Overly stringent ethical regulations may hinder the rapid development and deployment of beneficial AI technologies in healthcare.\\n- **Complexity of Implementation:** Integrating ethical considerations into existing frameworks can be challenging, requiring significant resources and training for stakeholders.\\n- **Variability in Interpretation:** Different stakeholders may interpret ethical guidelines differently, leading to inconsistencies in application and enforcement.\\n\\n**Conclusion:**\\nAs generative AI continues to evolve and integrate into healthcare, addressing ethical considerations is paramount. The proposed ethics checklist serves as a valuable tool for guiding responsible AI development and ensuring that ethical discussions remain at the forefront of innovation in this critical field.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 514, 'prompt_tokens': 1742, 'total_tokens': 2256, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1152}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f2cd28694a', 'finish_reason': 'stop', 'logprobs': None}, id='run-487037ff-9465-48c2-8d97-2c9c9a50e34b-0', usage_metadata={'input_tokens': 1742, 'output_tokens': 514, 'total_tokens': 2256, 'input_token_details': {'audio': 0, 'cache_read': 1152}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c21814e1-e187-4067-8bbb-3604a14d3e86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xS2PGF6DNMky"
   },
   "source": [
    "### Generate the third summary report\n",
    "\n",
    "Here we add the previous LLM response and the new instructions to the list of messages and send the whole thing to the LLM so it has access to the historical conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aef69c08-3a03-45fa-9a51-b5e12402edb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "lD6sIrMVJrRx"
   },
   "outputs": [],
   "source": [
    "prompt_txt = f\"\"\"\n",
    "Use only the research paper abstract from earlier and create a detailed report for a generative AI company solving healthcare problems.\n",
    "In the report also include sections for key points mentioned around Generative AI for text, images and structured data based healthcare\n",
    "\"\"\"\n",
    "messages.append(HumanMessage(content=prompt_txt))\n",
    "user_instruction = {'instruction': messages}\n",
    "response = chain.invoke(user_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b26861fb-9982-4d9c-b734-b4026815614f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUjMVo63eZit",
    "outputId": "8e3ad813-30b5-4e3f-9b93-ce9a2e91397b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Please provide the actual content of the research paper abstract so I can assist you in transforming it into a summary report for a general audience and a detailed report for a generative AI company focused on solving healthcare problems.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16638780-7e1c-48d8-813f-fdc328123eb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "eX8i7Yg2NS9F"
   },
   "source": [
    "## Mini-Project 3: Social Media Marketing Analyst\n",
    "\n",
    "You have the technical fact sheets of one smartphone. Try some iterative prompt engineering and do the following:\n",
    "\n",
    "1. Generate marketing product description for the smartphone\n",
    "\n",
    "2. Custom product description which has the following:\n",
    "\n",
    "```\n",
    "The description should follow this format:\n",
    "\n",
    "Product Name: <Name of the smartphone>\n",
    "\n",
    "Description: <Brief Overview of the features>\n",
    "\n",
    "Product Specifications:\n",
    "<Table with key product feature specifications>\n",
    "\n",
    "The description should focus on the most important features\n",
    "a customer might look for in a phone including the foldable display screen, processing power, RAM, camera and battery life.\n",
    "\n",
    "After the description, the table should have the\n",
    "key specifications of the product. It should have two columns.\n",
    "The first column should have 'Feature'\n",
    "and the second column should have 'Specification'\n",
    "and try to put exact numeric values for features if they exist.\n",
    "Only put these features in the table - foldable display screen, processing power, RAM, camera and battery life\n",
    "```\n",
    "\n",
    "3. Custom product description focusing on specific aspects like display, camera and in less than 60 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "616c082d-8c5b-4130-b0e3-91cf166d90cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NmADan2jQmWt"
   },
   "source": [
    "### Access the product factsheet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2cbabcd-c823-46cf-a4e0-73be5a7e31f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tyaP_Ab_L9c5"
   },
   "outputs": [],
   "source": [
    "fact_sheet_mobile = \"\"\"\n",
    "PRODUCT NAME\n",
    "Samsung Galaxy Z Fold4 5G Black\n",
    "\n",
    "PRODUCT OVERVIEW\n",
    "Stands out. Stands up. Unfolds.\n",
    "The Galaxy Z Fold4 does a lot in one hand with its 15.73 cm(6.2-inch) Cover Screen.\n",
    "Unfolded, the 19.21 cm(7.6-inch) Main Screen lets you really get into the zone.\n",
    "Pushed-back bezels and the Under Display Camera means there's more screen\n",
    "and no black dot getting between you and the breathtaking Infinity Flex Display.\n",
    "Do more than more with Multi View. Whether toggling between texts or catching up\n",
    "on emails, take full advantage of the expansive Main Screen with Multi View.\n",
    "PC-like power thanks to Qualcomm Snapdragon 8+ Gen 1 processor in your pocket,\n",
    "transforms apps optimized with One UI to give you menus and more in a glance\n",
    "New Taskbar for PC-like multitasking. Wipe out tasks in fewer taps. Add\n",
    "apps to the Taskbar for quick navigation and bouncing between windows when\n",
    "you're in the groove.4 And with App Pair, one tap launches up to three apps,\n",
    "all sharing one super-productive screen\n",
    "Our toughest Samsung Galaxy foldables ever. From the inside out,\n",
    "Galaxy Z Fold4 is made with materials that are not only stunning,\n",
    "but stand up to life's bumps and fumbles. The front and rear panels,\n",
    "made with exclusive Corning Gorilla Glass Victus+, are ready to resist\n",
    "sneaky scrapes and scratches. With our toughest aluminum frame made with\n",
    "Armor Aluminum, this is one durable smartphone.\n",
    "Worlds first water resistant foldable smartphones. Be adventurous, rain\n",
    "or shine. You don't have to sweat the forecast when you've got one of the\n",
    "world's first water-resistant foldable smartphones.\n",
    "\n",
    "PRODUCT SPECS\n",
    "OS - Android 12.0\n",
    "RAM - 12 GB\n",
    "Product Dimensions - 15.5 x 13 x 0.6 cm; 263 Grams\n",
    "Batteries - 2 Lithium Ion batteries required. (included)\n",
    "Item model number - SM-F936BZKDINU_5\n",
    "Wireless communication technologies - Cellular\n",
    "Connectivity technologies - Bluetooth, Wi-Fi, USB, NFC\n",
    "GPS - True\n",
    "Special features - Fast Charging Support, Dual SIM, Wireless Charging, Built-In GPS, Water Resistant\n",
    "Other display features - Wireless\n",
    "Device interface - primary - Touchscreen\n",
    "Resolution - 2176x1812\n",
    "Other camera features - Rear, Front\n",
    "Form factor - Foldable Screen\n",
    "Colour - Phantom Black\n",
    "Battery Power Rating - 4400\n",
    "Whats in the box - SIM Tray Ejector, USB Cable\n",
    "Manufacturer - Samsung India pvt Ltd\n",
    "Country of Origin - China\n",
    "Item Weight - 263 g\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "476f5489-fa0d-4ab8-80cd-eb15ade3339c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "didH1ICSQrX0"
   },
   "source": [
    "### Create prompt template for the first advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c75da31e-2975-47ea-8d8e-f0f2ded39802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2EJ2PPzJN3U5"
   },
   "outputs": [],
   "source": [
    "prompt_txt = \"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "\n",
    "Write a brief product description\n",
    "\n",
    "Technical specifications:\n",
    "{fact_sheet_mobile}\n",
    "\"\"\"\n",
    "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4880ff22-d24e-4f77-97fe-9adb10a94d4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tq1SXWSBQuzJ"
   },
   "source": [
    "### Use an LCEL LLM Chain to generate the first advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58effc5d-55b0-417f-b348-51d884b6587f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Shlyf_lxOo1E"
   },
   "outputs": [],
   "source": [
    "chain = (chat_template\n",
    "            |\n",
    "         chatgpt)\n",
    "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f671b0-34bb-4c13-b7fc-51545aeea09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGlB6xteO-FP",
    "outputId": "3453137f-7d28-4625-a671-669800b02c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Product Description: Samsung Galaxy Z Fold4 5G - Phantom Black**\n",
      "\n",
      "Unleash the power of innovation with the Samsung Galaxy Z Fold4 5G in stunning Phantom Black. This groundbreaking foldable smartphone redefines versatility, seamlessly transitioning from a compact 6.2-inch Cover Screen to an expansive 7.6-inch Main Screen that immerses you in your favorite content. With its breathtaking Infinity Flex Display, enjoy a truly edge-to-edge experience, free from distractions.\n",
      "\n",
      "Powered by the Qualcomm Snapdragon 8+ Gen 1 processor and equipped with 12GB of RAM, the Galaxy Z Fold4 delivers PC-like performance right in your pocket. Effortlessly multitask with the new Taskbar and Multi View features, allowing you to toggle between apps and complete tasks with ease. Whether you're catching up on emails or enjoying your favorite shows, this smartphone is designed to keep you in the zone.\n",
      "\n",
      "Durability meets elegance with the Galaxy Z Fold4, featuring Corning Gorilla Glass Victus+ and Armor Aluminum for enhanced protection against life's everyday bumps. Plus, it's one of the world's first water-resistant foldable smartphones, so you can embrace adventure without worrying about the weather.\n",
      "\n",
      "With a powerful 4400mAh battery, fast charging support, and wireless charging capabilities, the Galaxy Z Fold4 is ready to keep up with your busy lifestyle. Experience the future of mobile technology today with the Samsung Galaxy Z Fold4 5G  where style meets functionality. \n",
      "\n",
      "**What's in the box:** SIM Tray Ejector, USB Cable. \n",
      "\n",
      "**Get yours now and redefine what a smartphone can do!**\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dee67196-18b7-4e63-99f5-6d90a457f9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "jPE1vZuTPgJs",
    "outputId": "9ca9384f-5b95-48f8-e18b-28ea9aa59aa7"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Product Description: Samsung Galaxy Z Fold4 5G - Phantom Black**\n",
       "\n",
       "Unleash the power of innovation with the Samsung Galaxy Z Fold4 5G in stunning Phantom Black. This groundbreaking foldable smartphone redefines versatility, seamlessly transitioning from a compact 6.2-inch Cover Screen to an expansive 7.6-inch Main Screen that immerses you in your favorite content. With its breathtaking Infinity Flex Display, enjoy a truly edge-to-edge experience, free from distractions.\n",
       "\n",
       "Powered by the Qualcomm Snapdragon 8+ Gen 1 processor and equipped with 12GB of RAM, the Galaxy Z Fold4 delivers PC-like performance right in your pocket. Effortlessly multitask with the new Taskbar and Multi View features, allowing you to toggle between apps and complete tasks with ease. Whether you're catching up on emails or enjoying your favorite shows, this smartphone is designed to keep you in the zone.\n",
       "\n",
       "Durability meets elegance with the Galaxy Z Fold4, featuring Corning Gorilla Glass Victus+ and Armor Aluminum for enhanced protection against life's everyday bumps. Plus, it's one of the world's first water-resistant foldable smartphones, so you can embrace adventure without worrying about the weather.\n",
       "\n",
       "With a powerful 4400mAh battery, fast charging support, and wireless charging capabilities, the Galaxy Z Fold4 is ready to keep up with your busy lifestyle. Experience the future of mobile technology today with the Samsung Galaxy Z Fold4 5G  where style meets functionality. \n",
       "\n",
       "**What's in the box:** SIM Tray Ejector, USB Cable. \n",
       "\n",
       "**Get yours now and redefine what a smartphone can do!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5888ef0-d2de-4a61-b235-01970aec4c35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "iqNQsEWPQ3qz"
   },
   "source": [
    "### Create prompt template for the second advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a276c62d-5b86-4df3-8f75-66844423ab6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "j-CsFl0FPA9z"
   },
   "outputs": [],
   "source": [
    "prompt_txt = \"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "\n",
    "The description should follow this format:\n",
    "\n",
    "Product Name: <Name of the smartphone>\n",
    "\n",
    "Description: <Brief Overview of the features>\n",
    "\n",
    "Product Specifications:\n",
    "<Table with key product feature specifications>\n",
    "\n",
    "The description should focus on the most important features\n",
    "a customer might look for in a phone including the foldable display screen, processing power, RAM, camera and battery life.\n",
    "\n",
    "After the description, the table should have the\n",
    "key specifications of the product. It should have two columns.\n",
    "The first column should have 'Feature'\n",
    "and the second column should have 'Specification'\n",
    "and try to put exact numeric values for features if they exist.\n",
    "Only put these features in the table - foldable display screen, processing power, RAM, camera and battery life\n",
    "\n",
    "Technical specifications:\n",
    "{fact_sheet_mobile}\n",
    "\"\"\"\n",
    "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eae9cdad-971d-4b61-b36b-58d035ed92df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "C6EmK1TkRADG"
   },
   "source": [
    "### Use an LCEL LLM Chain to generate the second advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "555a180b-4c42-4121-8a46-0ff6b2e701ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "uievnu1GPSgj"
   },
   "outputs": [],
   "source": [
    "chain = (chat_template\n",
    "            |\n",
    "         chatgpt)\n",
    "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b535aad-f1ed-45ff-86a5-1d44fd1a469d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fY4nEK3PUbU",
    "outputId": "e5ef446f-5b69-468e-f3be-db2ccb0c0a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Product Name:** Samsung Galaxy Z Fold4 5G Black\n",
      "\n",
      "**Description:**  \n",
      "Experience the future of mobile technology with the Samsung Galaxy Z Fold4 5G. This innovative smartphone features a stunning 7.6-inch Infinity Flex Display that unfolds to provide an immersive viewing experience, perfect for multitasking and entertainment. With its powerful Qualcomm Snapdragon 8+ Gen 1 processor and 12 GB of RAM, you can seamlessly run multiple apps and enjoy smooth performance. Capture every moment with the advanced camera system, and stay connected all day long with a robust 4400 mAh battery. Plus, with its water-resistant design and durable materials, the Galaxy Z Fold4 is built to withstand life's adventures.\n",
      "\n",
      "**Product Specifications:**\n",
      "\n",
      "| Feature                | Specification          |\n",
      "|-----------------------|------------------------|\n",
      "| Foldable Display Screen| 7.6 inches (Main), 6.2 inches (Cover) |\n",
      "| Processing Power      | Qualcomm Snapdragon 8+ Gen 1 |\n",
      "| RAM                   | 12 GB                  |\n",
      "| Camera                | Rear: Triple Camera, Front: 10 MP |\n",
      "| Battery Life          | 4400 mAh               |\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af7259f4-1b0b-41c6-a042-007d7c0afe35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "dsBjspPgPWX7",
    "outputId": "5465303d-b961-4053-aee2-b21562702ab7"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Product Name:** Samsung Galaxy Z Fold4 5G Black\n",
       "\n",
       "**Description:**  \n",
       "Experience the future of mobile technology with the Samsung Galaxy Z Fold4 5G. This innovative smartphone features a stunning 7.6-inch Infinity Flex Display that unfolds to provide an immersive viewing experience, perfect for multitasking and entertainment. With its powerful Qualcomm Snapdragon 8+ Gen 1 processor and 12 GB of RAM, you can seamlessly run multiple apps and enjoy smooth performance. Capture every moment with the advanced camera system, and stay connected all day long with a robust 4400 mAh battery. Plus, with its water-resistant design and durable materials, the Galaxy Z Fold4 is built to withstand life's adventures.\n",
       "\n",
       "**Product Specifications:**\n",
       "\n",
       "| Feature                | Specification          |\n",
       "|-----------------------|------------------------|\n",
       "| Foldable Display Screen| 7.6 inches (Main), 6.2 inches (Cover) |\n",
       "| Processing Power      | Qualcomm Snapdragon 8+ Gen 1 |\n",
       "| RAM                   | 12 GB                  |\n",
       "| Camera                | Rear: Triple Camera, Front: 10 MP |\n",
       "| Battery Life          | 4400 mAh               |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "272a3643-3ab0-434c-9c62-267256f96877",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "oPytTJ6KQ50L"
   },
   "source": [
    "### Create prompt template for the third advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "666b6b6a-1b34-4c35-8270-59d2b29ff042",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1nB4OZp0PcN6"
   },
   "outputs": [],
   "source": [
    "prompt_txt = \"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "\n",
    "Write a catchy product description with some emojis,\n",
    "which uses at most 60 words\n",
    "and focuses on the most important things about the smartphone\n",
    "which might matter to users like display and camera\n",
    "\n",
    "Technical specifications:\n",
    "{fact_sheet_mobile}\n",
    "\"\"\"\n",
    "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd293b27-f4f9-4c3b-b4ab-b660dcc40c6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4wKXMaZbRCxO"
   },
   "source": [
    "### Use an LCEL LLM Chain to generate the third advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb049082-172d-4fc1-ba7a-74543c4878db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "hDAYappnQXN4"
   },
   "outputs": [],
   "source": [
    "chain = (chat_template\n",
    "            |\n",
    "         chatgpt)\n",
    "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03f7c8fb-b380-4c89-87a7-2681989738f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_QMf99GQZZo",
    "outputId": "905076b3-c9a7-43e8-aeb3-3822ba1a2997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unfold a new world with the Samsung Galaxy Z Fold4 5G!  Experience stunning visuals on a 7.6-inch Infinity Flex Display and capture every moment with its advanced camera system. With lightning-fast performance and water resistance, this foldable powerhouse is built for adventure. Elevate your multitasking game and do more, effortlessly! \n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9478d275-0e2c-4ea5-8da3-12f87a2b800e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "tc7LJylgQa9j",
    "outputId": "3c983edb-f88d-4caf-8bcc-1d7a2b907a4e"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Unfold a new world with the Samsung Galaxy Z Fold4 5G!  Experience stunning visuals on a 7.6-inch Infinity Flex Display and capture every moment with its advanced camera system. With lightning-fast performance and water resistance, this foldable powerhouse is built for adventure. Elevate your multitasking game and do more, effortlessly! "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dde6c9b-b8bb-4a57-842d-cb94321b9f3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EGvqHtrZRqTs"
   },
   "source": [
    "## Mini-Project 4 - IT Support Analyst\n",
    "\n",
    "Ask ChatGPT to act as a IT support agent, process each customer IT ticket message and output the response in JSON with the following fields\n",
    "\n",
    "```\n",
    "orig_msg: The original customer message\n",
    "orig_lang: Detected language of the customer message e.g. Spanish\n",
    "category: 1-2 word describing the category of the problem\n",
    "trans_msg: Translated customer message in English\n",
    "response: Response to the customer in orig_lang\n",
    "trans_response: Response to the customer in English\n",
    "```\n",
    "\n",
    "Try to use a JSON parser to get the responses in JSON for each ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07023d0e-3370-4221-9fa9-194eb052afb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7g40fksfTNpQ"
   },
   "source": [
    "### Define Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7503c87-5b8a-4515-8e9c-0a4f441c400f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "F7yEig9NRvsB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure - like a python data class.\n",
    "class ITSupportResponse(BaseModel):\n",
    "    orig_msg: str = Field(description=\"The original customer IT support query message\")\n",
    "    orig_lang: str = Field(description=\"Detected language of the customer message e.g. Spanish\")\n",
    "    category: str = Field(description=\"1-2 word describing the category of the problem\")\n",
    "    trans_msg: str = Field(description=\"Translated customer IT support query message in English\")\n",
    "    response: str = Field(description=\"Response to the customer in their original language - orig_lang\")\n",
    "    trans_response: str = Field(description=\"Response to the customer in English\")\n",
    "\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=ITSupportResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "befb07bf-eb9c-4403-aa61-9faa14e70c0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "TEQL4DhYTZug"
   },
   "source": [
    "### Create the input prompt for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "958ac9b6-7bfd-4a35-a1fd-6f61719d7ca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XbT3tGUUSIct"
   },
   "outputs": [],
   "source": [
    "# create the final prompt with formatting instructions from the parser\n",
    "prompt_txt = \"\"\"\n",
    "             Act as an Information Technology (IT) customer support agent.\n",
    "             For the IT support message mentioned below\n",
    "             use the following output format when generating the output response\n",
    "\n",
    "             Output format instructions:\n",
    "             {format_instructions}\n",
    "\n",
    "             Customer IT support message:\n",
    "             {it_support_msg}\n",
    "             \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_txt,\n",
    "    input_variables=[\"it_support_msg\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab2eb974-20aa-404a-90e9-b5465a3f393e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RMA7qY1XTeeR"
   },
   "source": [
    "### Create a LCEL LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bafb0fef-19c8-46a3-b741-2cbb9335eb51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Le18crwjSnY_"
   },
   "outputs": [],
   "source": [
    "# create a simple LCEL chain to take the prompt, pass it to the LLM, enforce response format using the parser\n",
    "llm_chain = (prompt\n",
    "              |\n",
    "            chatgpt\n",
    "              |\n",
    "            parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcaf9216-1cb3-42e9-9092-63d33ab044ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "li4TbuTGTj2H"
   },
   "source": [
    "### Access Customer IT Support ticket data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a08d71ef-99b7-4f39-a7f3-230d5ed75b07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdlcULKISsC2",
    "outputId": "16eb3869-ef21-46cf-c5b3-f63e4ce7a585"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'it_support_msg': 'No consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_support_queue = [\n",
    "    \"No consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.\",\n",
    "    \"Ho problemi a stampare i documenti da remoto. Il lavoro non viene inviato alla stampante di rete.\",\n",
    "    \"\",\n",
    "    \"       ,    .   .\",\n",
    "    \"Internet balantm ok yava ve bazen tamamen kesiliyor. Yardm eder misiniz?\",\n",
    "    \"    .   . , .\"\n",
    "]\n",
    "\n",
    "formatted_msgs = [{\"it_support_msg\": msg}\n",
    "                    for msg in it_support_queue]\n",
    "formatted_msgs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb826750-9915-44dc-b709-b632487d77d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MuTYg0GyTtei"
   },
   "source": [
    "### Get responses from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a829b33d-208d-4a53-9e12-189a4528735f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "adEaXYtsSxWa"
   },
   "outputs": [],
   "source": [
    "responses = llm_chain.map().invoke(formatted_msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d21c6287-fce3-406f-8028-22cc430e6abb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7iVZrIqITu3j"
   },
   "source": [
    "### View LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85c56636-051e-4667-9e9d-e8f7a5502820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgbcB5K7S3z0",
    "outputId": "a35f454e-51cf-403b-a931-2aeae6e83b9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orig_msg': 'No consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.',\n",
       " 'orig_lang': 'Portuguese',\n",
       " 'category': 'Sync Issue',\n",
       " 'trans_msg': 'I cannot sync my contacts with the phone. I always receive a failure message.',\n",
       " 'response': 'Por favor, verifique se voc est conectado  internet e tente reiniciar o telefone. Se o problema persistir, considere desinstalar e reinstalar o aplicativo de contatos.',\n",
       " 'trans_response': 'Please check if you are connected to the internet and try restarting the phone. If the problem persists, consider uninstalling and reinstalling the contacts app.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef34174e-235b-447d-b04a-158bc07e4784",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9U5mhraS65l",
    "outputId": "8f350fc6-97e8-4116-b838-f26b4ca05194"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02e16d43-3e99-4c5b-a619-876f9752ada2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "xD3rJqPGS-bd",
    "outputId": "7d13c32a-6007-478f-f2d7-9bcefeb89b08"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_msg</th>\n",
       "      <th>orig_lang</th>\n",
       "      <th>category</th>\n",
       "      <th>trans_msg</th>\n",
       "      <th>response</th>\n",
       "      <th>trans_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No consigo sincronizar meus contatos com o te...</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>Sync Issue</td>\n",
       "      <td>I cannot sync my contacts with the phone. I al...</td>\n",
       "      <td>Por favor, verifique se voc est conectado  ...</td>\n",
       "      <td>Please check if you are connected to the inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ho problemi a stampare i documenti da remoto. ...</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Printing Issue</td>\n",
       "      <td>I have problems printing documents remotely. T...</td>\n",
       "      <td>Mi dispiace sapere che hai problemi a stampare...</td>\n",
       "      <td>I'm sorry to hear that you're having trouble p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Printer Issue</td>\n",
       "      <td>I replaced the printer toner, but the print qu...</td>\n",
       "      <td>...</td>\n",
       "      <td>After replacing the toner, print quality can s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>       , ...</td>\n",
       "      <td>Russian</td>\n",
       "      <td>Login Issue</td>\n",
       "      <td>I cannot log into the time tracking system, an...</td>\n",
       "      <td>,      ...</td>\n",
       "      <td>Please check your credentials and ensure you a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Internet balantm ok yava ve bazen tamamen ...</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Internet Issue</td>\n",
       "      <td>My internet connection is very slow and someti...</td>\n",
       "      <td>Balant sorunlarnz zmek iin birka adm...</td>\n",
       "      <td>We can take a few steps to resolve your connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>    . ...</td>\n",
       "      <td>Russian</td>\n",
       "      <td>Update Issue</td>\n",
       "      <td>I cannot install the security update. An error...</td>\n",
       "      <td>, ,     ...</td>\n",
       "      <td>Please check that you have enough disk space t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            orig_msg  ...                                     trans_response\n",
       "0  No consigo sincronizar meus contatos com o te...  ...  Please check if you are connected to the inter...\n",
       "1  Ho problemi a stampare i documenti da remoto. ...  ...  I'm sorry to hear that you're having trouble p...\n",
       "2            ...  After replacing the toner, print quality can s...\n",
       "3         , ...  ...  Please check your credentials and ensure you a...\n",
       "4  Internet balantm ok yava ve bazen tamamen ...  ...  We can take a few steps to resolve your connec...\n",
       "5      . ...  ...  Please check that you have enough disk space t...\n",
       "\n",
       "[6 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(responses)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa8e1f26-d321-400b-8e4d-f563386f94ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IKS3-MEFTyjM"
   },
   "source": [
    "Try out more use-cases based on your own problems using what you learnt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "313bf6bd-786e-48e2-b5f9-d64174bf1d25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "M4 L2,3,4_Project_Prompt_Engineering_with_LangChain_and_ChatGPT",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
