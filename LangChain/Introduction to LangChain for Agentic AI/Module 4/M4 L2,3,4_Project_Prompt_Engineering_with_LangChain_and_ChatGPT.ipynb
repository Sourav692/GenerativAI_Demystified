{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "631357b1-327f-45a2-ba4e-87d21ac1a0a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XTzBUFWQ-OWj"
   },
   "source": [
    "# Project: Prompt Engineering with LangChain and ChatGPT for real-world tasks\n",
    "\n",
    "In this notebook you will leverage ChatGPT and LangChain to solve and do a few mini-projects based on some real-world scenarios:\n",
    "\n",
    "- Mini-Project 1: Review Analyst\n",
    "- Mini-Project 2: Research Paper Analyst\n",
    "- Mini-Project 3: Social Media Marketing Analyst\n",
    "- Mini-Project 4: IT Support Analyst\n",
    "\n",
    "___[Created By: Dipanjan (DJ)](https://www.linkedin.com/in/dipanjans/)___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17630c1a-3373-47f8-8fc7-d979a90bf582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L1KvMtf54l0d"
   },
   "source": [
    "## Install OpenAI and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "435dda06-fc9c-49fa-a113-89d5001e06dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.11\n",
    "!pip install langchain-openai==0.2.12\n",
    "!pip install langchain-community==0.3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa8c790-80ea-4a68-8506-51b8f65d8e1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8435e955-31a4-4b16-855c-1bc0ee15785b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PtBa7rlWJWH3"
   },
   "source": [
    "## Enter API Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28ce8c0c-4c4a-4388-bd3d-c33c31371910",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Y6RD7As2sm8G"
   },
   "source": [
    "#### Enter your Open AI Key here\n",
    "\n",
    "You can get the key from [here](https://platform.openai.com/api-keys) after creating an account or signing in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77980500-15ee-49ce-94c9-353cd7ea2881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ogxBkS6ZnnC",
    "outputId": "4b411016-531d-4c31-85fc-b06cac039cc7"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Please enter your Open AI API Key here: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "baf060a0-9514-4bda-9675-ff1c7d0148c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "T5rOqCyianbP"
   },
   "source": [
    "## Setup necessary system environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c9c861c-d697-4909-8f0b-42dc4708cf3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1PIStD04Zp9p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe0b21d1-f924-4f1f-85de-f4b2332dbe02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "VDWhgxCy5bA6"
   },
   "source": [
    "## Load Necessary Dependencies and ChatGPT LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec502dc1-581b-4620-8773-657411b59920",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9GYhyRFRuJXG"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e827dcff-9c1a-415a-b8dc-495b593c26a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "mY2bapqfuWq1"
   },
   "outputs": [],
   "source": [
    "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f2f1415-d63e-437c-98bc-d236b3b6210b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "AeDkpvGDhMGV"
   },
   "source": [
    "## Mini-Project 1: Review Analyst\n",
    "\n",
    "You are building an AI system to be able to look at customer reviews and do some complex analysis. for each review get ChatGPT to do the following:\n",
    "\n",
    "  - Summarize the review. The summary should be at most 3 lines.\n",
    "  - Highlight both the positives and negatives\n",
    "  - Display the overall sentiment of the review (positive, negative, neutral)\n",
    "  - Display a list of 3 - 5 emotions expressed by the customer in the review\n",
    "  - If the sentiment is positive or neutral write an email and thank them for the review\n",
    "  - If the sentiment is negative apologize and write an email with an appropriate response\n",
    "\n",
    "Try to get the response in a nice structured format using an output parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4446b4cc-f2d7-42e7-a28a-f245b4e17e12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9P_TrLpRAIXM"
   },
   "source": [
    "### Access Customer Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91dc7726-3154-45f5-9526-e70024e68625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "hRbBZB57hT0G"
   },
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    f\"\"\"\n",
    "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
    "    The sound quality is impressively clear with just the right amount of bass.\n",
    "    It's also waterproof, which tested true during a recent splashing incident.\n",
    "    Though it's compact, the volume can really fill the space.\n",
    "    The price was a bargain for such high-quality sound.\n",
    "    Shipping was also on point, arriving two days early in secure packaging.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Purchased a new gaming keyboard because of its rave reviews about responsiveness and backlighting.\n",
    "    It hasn't disappointed. The keys have a satisfying click and the LED colors are vibrant,\n",
    "    enhancing my gaming experience significantly. Price-wise, it's quite competitive,\n",
    "    and I feel like I got a good deal. The delivery was swift, and it came well-protected,\n",
    "    ensuring no damage during transport.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Ordered a set of wireless earbuds for running, and they've been a letdown.\n",
    "    The sound constantly cuts out, and the fit is uncomfortable after only a few minutes of use.\n",
    "    They advertised a 12-hour battery life, but I'm barely getting four hours.\n",
    "    Considering the cost, I expected better quality and performance.\n",
    "    They did arrive on time, but the positives end there. I'm already looking into a return.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    The tablet stand I bought was touted as being sturdy and adjustable,\n",
    "    but it's anything but. It wobbles with the slightest touch,\n",
    "    and the angles are not holding up as promised. It feels like a breeze could knock it over.\n",
    "    It was also pricier than others I've seen, which adds to the disappointment.\n",
    "    It did arrive promptly, but what's the use if the product doesn't meet basic expectations?\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Needed a new kitchen blender, but this model has been a nightmare.\n",
    "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
    "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
    "    I thought the brand meant quality, but this product has proven me wrong.\n",
    "    Plus, it arrived three days late. Definitely not worth the expense.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48828d33-eec3-451d-a9ff-58d94f50563e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Rz9SIYmYALOm"
   },
   "source": [
    "### Define Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6728d78e-6b92-43ee-91f7-3d7cb5833c2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "HK0u7biN7uDh"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define your desired data structure - like a python data class.\n",
    "class ReviewAnalysisResponse(BaseModel):\n",
    "    summary: str = Field(description=\"A brief summary of the customer review with maximum 3 lines\")\n",
    "    positives: list = Field(description=\"A list showing the positives mentioned by the customer in the review if any - max 3 points\")\n",
    "    negatives: list = Field(description=\"A list showing the negatives mentioned by the customer in the review if any - max 3 points\")\n",
    "    sentiment: str = Field(description=\"One word showing the sentiment of the review - positive, negative or neutral\")\n",
    "    emotions: list = Field(description=\"A list of 3 - 5 emotions expressed by the customer in the review\")\n",
    "    email: str = Field(description=\"Detailed email to the customer based on the sentiment\")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=ReviewAnalysisResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95ce0b49-edd7-48b0-b1a1-63cafd4179ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Fc8awL6dAONh"
   },
   "source": [
    "### Create the input prompt for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85ebd6f8-a922-4815-bc3a-9f51d2828a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "0TylxOCZ85O1"
   },
   "outputs": [],
   "source": [
    "# create the final prompt with formatting instructions from the parser\n",
    "prompt_txt = \"\"\"\n",
    "             Analyze the given customer review below and generate the response based on the instructions\n",
    "             mentioned below in the format instructions.\n",
    "             Also remember to write a detailed email response for the email field based on these conditions:\n",
    "               - email should be addressed to Dear Customer and signed with Service Agent\n",
    "               - thank them if the review is positive or neutral\n",
    "               - apologize if the review is negative\n",
    "\n",
    "             Format Instructions:\n",
    "             {format_instructions}\n",
    "\n",
    "             Review:\n",
    "             {review}\n",
    "            \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_txt,\n",
    "    input_variables=[\"review\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fea28ae-bd14-488f-83ca-7d688e51a842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EE0l_m31AQ5k"
   },
   "source": [
    "### Create a LCEL LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cec1070-102a-4e18-8b32-f57a6228be95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "SWfHWjm-9HuD"
   },
   "outputs": [],
   "source": [
    "# create a simple LCEL chain to take the prompt, pass it to the LLM, enforce response format using the parser\n",
    "chain = (prompt\n",
    "           |\n",
    "         chatgpt\n",
    "           |\n",
    "         parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c80d0e2e-ed1c-431c-b1e1-f7aa261c77cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "70ivaPOrATnR"
   },
   "source": [
    "### Format the input reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b02838f-0d84-48eb-8814-2ba7934277b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBPSeLKA9N5M",
    "outputId": "824d7e82-06d4-4ac4-a4d3-8a8f2df74a2f"
   },
   "outputs": [],
   "source": [
    "reviews_formatted = [{'review': review} for review in reviews]\n",
    "reviews_formatted[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a292be73-5595-4b9b-9aac-5c5982adf90b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MHbJvZlYAVcH"
   },
   "source": [
    "### Get responses from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5830a82-3fc0-4976-9484-addc3bc4e983",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tpH9R-iO9Wbq"
   },
   "outputs": [],
   "source": [
    "responses = chain.map().invoke(reviews_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "711040eb-ce85-47d8-ba13-f3d81d51ac63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "z7wS4_lnAYAL"
   },
   "source": [
    "### View LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dab423a5-e5fe-4be7-a4ac-b00d8b4245ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NaC9oaRY-15M",
    "outputId": "2f2b0706-b14e-4af8-9b94-5f8d0901d911"
   },
   "outputs": [],
   "source": [
    "responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33873ad6-52a7-40f3-bf14-caefe253d5ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VN7PfKvBbGZV",
    "outputId": "fc05d56f-7586-433a-be5a-fcc8ff63ce6d"
   },
   "outputs": [],
   "source": [
    "responses[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d19cf9-8980-4380-8183-69c685fff176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHJpeC5f9ZfK",
    "outputId": "de7bfe78-63db-45c5-c40b-493a9f714538"
   },
   "outputs": [],
   "source": [
    "for response in responses:\n",
    "  for k,v in response.dict().items():\n",
    "    print(f'{k}:\\n{v}')\n",
    "  print('-----')\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e2bed6f-33a4-4553-b276-80b15507fd7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "4VgCY3aV-7AI",
    "outputId": "252507c5-ecfa-4fff-f47e-34e42f92ba2f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(response.dict() for response in responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c62b2da-54eb-4bfa-aabc-22caf3da177c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "eEtB1IOimA0i"
   },
   "source": [
    "## Mini-Project 2: Research Paper Analyst\n",
    "\n",
    "Make ChatGPT act as an AI expert and transform the given research paper abstract based on the nature of the audience mentioned below.\n",
    "\n",
    "- Short summary of maximum 10 lines for a general audience\n",
    "- Detailed report for a healthcare company. Have bullet points for pros and cons of ethics in Generative AI as mentioned in the paper\n",
    "- Detailed report for a generative AI company solving healthcare problems. Have bullet points for key points mentioned for Generative AI for text, images and structured data based healthcare\n",
    "\n",
    "Try to use `ChatPromptTemplate` so you can have a conversation with ChatGPT for each of the above tasks using conversational prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97a9aa69-8d76-4b87-849f-8d7c6cccd99d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gjiheMsOMUO6"
   },
   "source": [
    "### Access the Research Paper Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1abe7ebc-646d-494b-9989-964ae29ab6c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4FnITE6zhV-9"
   },
   "outputs": [],
   "source": [
    "paper_abstract = f\"\"\"\n",
    "The widespread use of ChatGPT and other emerging technology powered by generative\n",
    "artificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\n",
    "high-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\n",
    "issues beyond following guidelines and regulations that are still under discussion and\n",
    "development. On the other hand, other types of generative AI have been used to synthesize\n",
    "images and other types of data for research and practical purposes, which have resolved some\n",
    "ethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\n",
    "of ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\n",
    "generative AI via a systematic scoping review of relevant existing research in healthcare, and\n",
    "reduce the gaps by proposing an ethics checklist for comprehensive assessment and\n",
    "transparent documentation of ethical discussions in generative AI development. While the\n",
    "checklist can be readily integrated into the current peer review and publication system to\n",
    "enhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\n",
    "products) to help users establish reasonable trust in their capabilities.\n",
    "\n",
    "Current ethical discussions on generative AI in healthcare\n",
    "We conducted a systematic scoping review to analyse current ethical discussions on\n",
    "generative AI in healthcare. Our search in four major academic research databases for\n",
    "relevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\n",
    "detailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\n",
    "which 193 articles were included for analysis based on application data modality (text, image,\n",
    "or structured data), ethical issues discussed, generative AI involved, and whether generative\n",
    "AI causes or offers technical solutions for issues raised.\n",
    "\n",
    "Generative AI for text data-based healthcare\n",
    "Forty-one of the 193 articles discussed ethical considerations pertaining to generative AI\n",
    "applications for text data, with 20 articles describing methodological developments or\n",
    "applications of generative AI and the other 21 articles describing review-type works on this\n",
    "topic. Although some of these review-type articles used the general term “generative AI”, the\n",
    "main body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\n",
    "discussions on ethical issues, whereas the other 12 articles only briefly touched on some\n",
    "ethical aspects.\n",
    "Among the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\n",
    "specifically by GPT in 16 of the articles), covering a wide range of application scenarios and\n",
    "considered the application of all 10 ethical principles identified in the review (see Figure 1),\n",
    "as well as other less discussed concerns such as human-AI interaction, and the rights of\n",
    "LLMs to be considered as co-authors in scientific papers. One paper only commented briefly\n",
    "on the need for ethical considerations in LLMs and is summarised in the “Others” category.\n",
    "Although all ethical principles are equally important, some are discussed more often than\n",
    "others, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\n",
    "privacy.\n",
    "Fifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\n",
    "confidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\n",
    "autoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\n",
    "medical text, to reduce disparity by providing accessible services and assistance, to detect\n",
    "health-related misinformation, to generate trusted content, and to improve accountability or\n",
    "transparency over existing approaches. While most articles focused on either identifying\n",
    "ethical issues caused by generative AI or proposing generative AI-based solutions, three\n",
    "articles discussed both to provide a more balanced perspective.\n",
    "\n",
    "Generative AI for image and structured data-based healthcare\n",
    "Unlike the diverse application scenarios of generative AI based on text data, for image and\n",
    "structured data, this use of generative AI focuses on data synthesis and encryption. Hence the\n",
    "majority of articles discussed the methodological developments of generative AI as giving\n",
    "rise to a more distinctive and focused set of ethical issues.\n",
    "5\n",
    "Notably, of the 98 articles on image data and 58 articles on structured data, more than half\n",
    "(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\n",
    "brief motivation for methodological developments or as a general discussion point. The rest\n",
    "included more in-depth discussions or evaluations of ethical issues. Among these 155 articles\n",
    "(as one article covered multiple modalities), 11 articles were review-type work, where 10\n",
    "articles reviewed methods that mentioned one or two ethical perspectives, and only one\n",
    "article24 discussed detailed ethical concerns on generative AI applications.\n",
    "Resolving privacy issues was the main aim of articles for these two data modalities (n=74 for\n",
    "image data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\n",
    "data using GAN. Eight articles on image data and 9 articles on structured data used\n",
    "generative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\n",
    "existing databases. For both data modalities, we did not see explicit discussions on resolving\n",
    "autonomy, integrity, or morality issues using generative AI, and for structured data the articles\n",
    "additionally lacked discussions on trust or transparency.\n",
    "Only 11 articles for image data selectively discussed some ethical issues that generative AI\n",
    "can give rise to, without specific discussions regarding autonomy, integrity, or morality. For\n",
    "structured data, only 4 articles discussed equity, privacy, or data security issues caused by\n",
    "generative AI. Only two articles on structured data included both the cause and resolving\n",
    "perspectives by discussing ethical issues that may arise from limitations of methods\n",
    "proposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e50c6da-cc3a-4cbc-9b4e-32ab1f71a908",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "sI2cwvpIMaGJ"
   },
   "source": [
    "### Create a prompt template for paper analysis and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8748744d-5a42-440a-8742-96e22ffa9938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "E5S9fvwrYZ6u"
   },
   "outputs": [],
   "source": [
    "SYS_PROMPT = \"\"\"\n",
    "Act as a Artificial Intelligence Expert.\n",
    "Transform the input research paper abstract given below\n",
    "based on the instruction input by the user.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        (\"human\", \"{instruction}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "054eee80-a68d-4b43-8d0e-78337fa755bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9248bf5c-d418-415e-87b1-f86eca8ecc1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PqEOQ4VZMfaC"
   },
   "source": [
    "### Create a simple LCEL LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89197ffb-0c8f-41db-b7c5-75f06ebe9881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "uc8fNUiXDUAC"
   },
   "outputs": [],
   "source": [
    "chain = (prompt\n",
    "            |\n",
    "         chatgpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "340696ff-3e84-47ba-a347-09a8e4ecad16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "r2mbR5lfMkF8"
   },
   "source": [
    "### Generate the first summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dd56a4a-3a6b-4211-9a04-55e8adb2127b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L8cgurf6Ytds"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_txt = f\"\"\"\n",
    "Based on the following research paper abstract,\n",
    "create the summary report of maximum 10 lines\n",
    "for a general audience\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "messages = [HumanMessage(content=prompt_txt)]\n",
    "user_instruction = {'instruction': messages}\n",
    "\n",
    "response = chain.invoke(user_instruction)\n",
    "messages.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e4ffc9d-ac41-496f-a4bd-000d313a7ad0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2beb66f5-c998-4f7c-abef-05f4c14fb315",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize the chat model\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define system prompt for context\n",
    "sys_prompt = \"\"\"Act as an Artificial Intelligence Expert. \n",
    "Transform the input research paper abstract based on the instruction input by the user.\"\"\"\n",
    "\n",
    "# Create a prompt template\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sys_prompt),\n",
    "    (\"human\", \"{instruction}\")\n",
    "])\n",
    "\n",
    "# Define reusable function for invoking chat with instruction\n",
    "def generate_response(instruction_text: str) -> str:\n",
    "    messages = [HumanMessage(content=instruction_text)]\n",
    "    user_instruction = {'instruction': messages}\n",
    "    return chatgpt.invoke(chat_prompt.format_messages(**user_instruction))\n",
    "\n",
    "# Example research paper abstract\n",
    "paper_abstract = paper_abstract\n",
    "\n",
    "# First task: Create a summary report\n",
    "summary_instruction = f\"\"\"\n",
    "Based on the following research paper abstract, create a summary report of maximum 10 lines for a general audience.\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "response = generate_response(summary_instruction)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "913c4990-d759-4f3d-a320-da307661ff22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize the chat model\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define system-level prompt for context\n",
    "SYS_PROMPT = \"\"\"Act as an Artificial Intelligence Expert. \n",
    "Transform the input research paper abstract based on the instruction input by the user.\"\"\"\n",
    "\n",
    "# Create a chat prompt template\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYS_PROMPT),\n",
    "    (\"human\", \"{instruction}\")\n",
    "])\n",
    "\n",
    "# Build a chain for processing messages\n",
    "chain = chat_prompt | chatgpt\n",
    "\n",
    "# Define reusable function to interact with the chain\n",
    "def generate_response(instruction_text: str) -> str:\n",
    "    # Create a human message\n",
    "    messages = [HumanMessage(content=instruction_text)]\n",
    "    # Wrap messages in instruction dictionary as required\n",
    "    user_instruction = {'instruction': messages}\n",
    "    # Invoke the chain and return the response\n",
    "    response = chain.invoke(user_instruction)\n",
    "    return response.content\n",
    "\n",
    "# Example research paper abstract\n",
    "paper_abstract = \"\"\"(Long abstract content here)\"\"\"\n",
    "\n",
    "# First task: Create a summary report\n",
    "summary_instruction = f\"\"\"\n",
    "Based on the following research paper abstract, create a summary report of maximum 10 lines for a general audience.\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "summary_response = generate_response(summary_instruction)\n",
    "print(\"Summary Report:\\n\", summary_response)\n",
    "\n",
    "# Second task: Detailed report for a healthcare company\n",
    "detailed_instruction = f\"\"\"\n",
    "Using only the research paper abstract provided earlier, create a detailed report for a healthcare company.\n",
    "Include bullet points (3 max) for pros and cons of ethics in Generative AI.\n",
    "\"\"\"\n",
    "detailed_response = generate_response(detailed_instruction)\n",
    "print(\"Detailed Report:\\n\", detailed_response)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define system-level behavior for AI\n",
    "sys_prompt = \"\"\"Act as an Artificial Intelligence Expert. Transform the input research paper abstract based on the instruction input by the user.\"\"\"\n",
    "messages = [SystemMessage(content=sys_prompt)]\n",
    "\n",
    "# First user instruction\n",
    "paper_abstract = paper_abstract\n",
    "prompt_txt = f\"\"\"\n",
    "Based on the following research paper abstract, create the summary report of maximum 10 lines for a general audience\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "messages.append(HumanMessage(content=prompt_txt))\n",
    "response = chatgpt.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b5019cd-a968-4f9a-807b-210826bb6bc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVE4atsREzfp",
    "outputId": "76f21ec3-ee14-4fcb-c0ea-5f9066104b01"
   },
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b948783-5b52-439b-abe3-e329156d0034",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "hxvTIb4SdLd7",
    "outputId": "785b1e04-0427-4a4f-bd57-8b01363b6533"
   },
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f54d7b2a-ef61-478d-bfb8-12f982a4fe22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XYxJPOkdP9p",
    "outputId": "44e22b33-6d87-42f9-c436-85429ced96d7"
   },
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "060e4ee5-77ad-4757-b303-c7fb261d76ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Us1V2RJQM_ry"
   },
   "source": [
    "### Generate the second summary report\n",
    "\n",
    "Here we add the previous LLM response and the new instructions to the list of messages and send the whole thing to the LLM so it has access to the historical conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b939d2-af64-4ff9-bc0b-49bc3e93e642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "X_wqbVYOI42b"
   },
   "outputs": [],
   "source": [
    "prompt_txt = f\"\"\"\n",
    "Use only the research paper abstract from earlier and create a detailed report for a healthcare company.\n",
    "In the report, also include bullet points (3 max) for pros and cons of ethics in Generative AI\n",
    "\"\"\"\n",
    "messages.append(HumanMessage(content=prompt_txt))\n",
    "user_instruction = {'instruction': messages}\n",
    "response = chain.invoke(user_instruction)\n",
    "messages.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1e74e0a-96bc-4a68-b06e-93f85895bcec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "up-RtmIfFrAV",
    "outputId": "5f99582f-6492-48fd-feac-a84003df4232"
   },
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c237415-05c3-4929-8e42-1b421b46fe26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cC_wp-OBdxgh",
    "outputId": "6372b9a9-67c5-4745-b5ce-d64e16021521"
   },
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c21814e1-e187-4067-8bbb-3604a14d3e86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xS2PGF6DNMky"
   },
   "source": [
    "### Generate the third summary report\n",
    "\n",
    "Here we add the previous LLM response and the new instructions to the list of messages and send the whole thing to the LLM so it has access to the historical conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aef69c08-3a03-45fa-9a51-b5e12402edb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "lD6sIrMVJrRx"
   },
   "outputs": [],
   "source": [
    "prompt_txt = f\"\"\"\n",
    "Use only the research paper abstract from earlier and create a detailed report for a generative AI company solving healthcare problems.\n",
    "In the report also include sections for key points mentioned around Generative AI for text, images and structured data based healthcare\n",
    "\"\"\"\n",
    "messages.append(HumanMessage(content=prompt_txt))\n",
    "user_instruction = {'instruction': messages}\n",
    "response = chain.invoke(user_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b26861fb-9982-4d9c-b734-b4026815614f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUjMVo63eZit",
    "outputId": "8e3ad813-30b5-4e3f-9b93-ce9a2e91397b"
   },
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16638780-7e1c-48d8-813f-fdc328123eb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "eX8i7Yg2NS9F"
   },
   "source": [
    "## Mini-Project 3: Social Media Marketing Analyst\n",
    "\n",
    "You have the technical fact sheets of one smartphone. Try some iterative prompt engineering and do the following:\n",
    "\n",
    "1. Generate marketing product description for the smartphone\n",
    "\n",
    "2. Custom product description which has the following:\n",
    "\n",
    "```\n",
    "The description should follow this format:\n",
    "\n",
    "Product Name: <Name of the smartphone>\n",
    "​\n",
    "Description: <Brief Overview of the features>\n",
    "​\n",
    "Product Specifications:\n",
    "<Table with key product feature specifications>\n",
    "​\n",
    "The description should focus on the most important features\n",
    "a customer might look for in a phone including the foldable display screen, processing power, RAM, camera and battery life.\n",
    "​\n",
    "After the description, the table should have the\n",
    "key specifications of the product. It should have two columns.\n",
    "The first column should have 'Feature'\n",
    "and the second column should have 'Specification'\n",
    "and try to put exact numeric values for features if they exist.\n",
    "Only put these features in the table - foldable display screen, processing power, RAM, camera and battery life\n",
    "```\n",
    "\n",
    "3. Custom product description focusing on specific aspects like display, camera and in less than 60 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "616c082d-8c5b-4130-b0e3-91cf166d90cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NmADan2jQmWt"
   },
   "source": [
    "### Access the product factsheet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2cbabcd-c823-46cf-a4e0-73be5a7e31f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tyaP_Ab_L9c5"
   },
   "outputs": [],
   "source": [
    "fact_sheet_mobile = \"\"\"\n",
    "PRODUCT NAME\n",
    "Samsung Galaxy Z Fold4 5G Black\n",
    "​\n",
    "PRODUCT OVERVIEW\n",
    "Stands out. Stands up. Unfolds.\n",
    "The Galaxy Z Fold4 does a lot in one hand with its 15.73 cm(6.2-inch) Cover Screen.\n",
    "Unfolded, the 19.21 cm(7.6-inch) Main Screen lets you really get into the zone.\n",
    "Pushed-back bezels and the Under Display Camera means there's more screen\n",
    "and no black dot getting between you and the breathtaking Infinity Flex Display.\n",
    "Do more than more with Multi View. Whether toggling between texts or catching up\n",
    "on emails, take full advantage of the expansive Main Screen with Multi View.\n",
    "PC-like power thanks to Qualcomm Snapdragon 8+ Gen 1 processor in your pocket,\n",
    "transforms apps optimized with One UI to give you menus and more in a glance\n",
    "New Taskbar for PC-like multitasking. Wipe out tasks in fewer taps. Add\n",
    "apps to the Taskbar for quick navigation and bouncing between windows when\n",
    "you're in the groove.4 And with App Pair, one tap launches up to three apps,\n",
    "all sharing one super-productive screen\n",
    "Our toughest Samsung Galaxy foldables ever. From the inside out,\n",
    "Galaxy Z Fold4 is made with materials that are not only stunning,\n",
    "but stand up to life's bumps and fumbles. The front and rear panels,\n",
    "made with exclusive Corning Gorilla Glass Victus+, are ready to resist\n",
    "sneaky scrapes and scratches. With our toughest aluminum frame made with\n",
    "Armor Aluminum, this is one durable smartphone.\n",
    "World’s first water resistant foldable smartphones. Be adventurous, rain\n",
    "or shine. You don't have to sweat the forecast when you've got one of the\n",
    "world's first water-resistant foldable smartphones.\n",
    "​\n",
    "PRODUCT SPECS\n",
    "OS - Android 12.0\n",
    "RAM - 12 GB\n",
    "Product Dimensions - 15.5 x 13 x 0.6 cm; 263 Grams\n",
    "Batteries - 2 Lithium Ion batteries required. (included)\n",
    "Item model number - SM-F936BZKDINU_5\n",
    "Wireless communication technologies - Cellular\n",
    "Connectivity technologies - Bluetooth, Wi-Fi, USB, NFC\n",
    "GPS - True\n",
    "Special features - Fast Charging Support, Dual SIM, Wireless Charging, Built-In GPS, Water Resistant\n",
    "Other display features - Wireless\n",
    "Device interface - primary - Touchscreen\n",
    "Resolution - 2176x1812\n",
    "Other camera features - Rear, Front\n",
    "Form factor - Foldable Screen\n",
    "Colour - Phantom Black\n",
    "Battery Power Rating - 4400\n",
    "Whats in the box - SIM Tray Ejector, USB Cable\n",
    "Manufacturer - Samsung India pvt Ltd\n",
    "Country of Origin - China\n",
    "Item Weight - 263 g\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "476f5489-fa0d-4ab8-80cd-eb15ade3339c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "didH1ICSQrX0"
   },
   "source": [
    "### Create prompt template for the first advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c75da31e-2975-47ea-8d8e-f0f2ded39802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2EJ2PPzJN3U5"
   },
   "outputs": [],
   "source": [
    "prompt_txt = \"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "​\n",
    "Write a brief product description\n",
    "\n",
    "Technical specifications:\n",
    "{fact_sheet_mobile}\n",
    "\"\"\"\n",
    "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4880ff22-d24e-4f77-97fe-9adb10a94d4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tq1SXWSBQuzJ"
   },
   "source": [
    "### Use an LCEL LLM Chain to generate the first advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58effc5d-55b0-417f-b348-51d884b6587f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Shlyf_lxOo1E"
   },
   "outputs": [],
   "source": [
    "chain = (chat_template\n",
    "            |\n",
    "         chatgpt)\n",
    "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f671b0-34bb-4c13-b7fc-51545aeea09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGlB6xteO-FP",
    "outputId": "3453137f-7d28-4625-a671-669800b02c80"
   },
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dee67196-18b7-4e63-99f5-6d90a457f9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "jPE1vZuTPgJs",
    "outputId": "9ca9384f-5b95-48f8-e18b-28ea9aa59aa7"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5888ef0-d2de-4a61-b235-01970aec4c35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "iqNQsEWPQ3qz"
   },
   "source": [
    "### Create prompt template for the second advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a276c62d-5b86-4df3-8f75-66844423ab6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "j-CsFl0FPA9z"
   },
   "outputs": [],
   "source": [
    "prompt_txt = \"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "​\n",
    "The description should follow this format:\n",
    "\n",
    "Product Name: <Name of the smartphone>\n",
    "​\n",
    "Description: <Brief Overview of the features>\n",
    "​\n",
    "Product Specifications:\n",
    "<Table with key product feature specifications>\n",
    "​\n",
    "The description should focus on the most important features\n",
    "a customer might look for in a phone including the foldable display screen, processing power, RAM, camera and battery life.\n",
    "​\n",
    "After the description, the table should have the\n",
    "key specifications of the product. It should have two columns.\n",
    "The first column should have 'Feature'\n",
    "and the second column should have 'Specification'\n",
    "and try to put exact numeric values for features if they exist.\n",
    "Only put these features in the table - foldable display screen, processing power, RAM, camera and battery life\n",
    "\n",
    "Technical specifications:\n",
    "{fact_sheet_mobile}\n",
    "\"\"\"\n",
    "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eae9cdad-971d-4b61-b36b-58d035ed92df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "C6EmK1TkRADG"
   },
   "source": [
    "### Use an LCEL LLM Chain to generate the second advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "555a180b-4c42-4121-8a46-0ff6b2e701ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "uievnu1GPSgj"
   },
   "outputs": [],
   "source": [
    "chain = (chat_template\n",
    "            |\n",
    "         chatgpt)\n",
    "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b535aad-f1ed-45ff-86a5-1d44fd1a469d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fY4nEK3PUbU",
    "outputId": "e5ef446f-5b69-468e-f3be-db2ccb0c0a6b"
   },
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af7259f4-1b0b-41c6-a042-007d7c0afe35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "dsBjspPgPWX7",
    "outputId": "5465303d-b961-4053-aee2-b21562702ab7"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "272a3643-3ab0-434c-9c62-267256f96877",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "oPytTJ6KQ50L"
   },
   "source": [
    "### Create prompt template for the third advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "666b6b6a-1b34-4c35-8270-59d2b29ff042",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1nB4OZp0PcN6"
   },
   "outputs": [],
   "source": [
    "prompt_txt = \"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "​\n",
    "Write a catchy product description with some emojis,\n",
    "which uses at most 60 words\n",
    "and focuses on the most important things about the smartphone\n",
    "which might matter to users like display and camera\n",
    "\n",
    "Technical specifications:\n",
    "{fact_sheet_mobile}\n",
    "\"\"\"\n",
    "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd293b27-f4f9-4c3b-b4ab-b660dcc40c6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4wKXMaZbRCxO"
   },
   "source": [
    "### Use an LCEL LLM Chain to generate the third advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb049082-172d-4fc1-ba7a-74543c4878db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "hDAYappnQXN4"
   },
   "outputs": [],
   "source": [
    "chain = (chat_template\n",
    "            |\n",
    "         chatgpt)\n",
    "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03f7c8fb-b380-4c89-87a7-2681989738f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_QMf99GQZZo",
    "outputId": "905076b3-c9a7-43e8-aeb3-3822ba1a2997"
   },
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9478d275-0e2c-4ea5-8da3-12f87a2b800e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "tc7LJylgQa9j",
    "outputId": "3c983edb-f88d-4caf-8bcc-1d7a2b907a4e"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dde6c9b-b8bb-4a57-842d-cb94321b9f3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EGvqHtrZRqTs"
   },
   "source": [
    "## Mini-Project 4 - IT Support Analyst\n",
    "\n",
    "Ask ChatGPT to act as a IT support agent, process each customer IT ticket message and output the response in JSON with the following fields\n",
    "\n",
    "```\n",
    "orig_msg: The original customer message\n",
    "orig_lang: Detected language of the customer message e.g. Spanish\n",
    "category: 1-2 word describing the category of the problem\n",
    "trans_msg: Translated customer message in English\n",
    "response: Response to the customer in orig_lang\n",
    "trans_response: Response to the customer in English\n",
    "```\n",
    "\n",
    "Try to use a JSON parser to get the responses in JSON for each ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07023d0e-3370-4221-9fa9-194eb052afb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7g40fksfTNpQ"
   },
   "source": [
    "### Define Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7503c87-5b8a-4515-8e9c-0a4f441c400f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "F7yEig9NRvsB"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure - like a python data class.\n",
    "class ITSupportResponse(BaseModel):\n",
    "    orig_msg: str = Field(description=\"The original customer IT support query message\")\n",
    "    orig_lang: str = Field(description=\"Detected language of the customer message e.g. Spanish\")\n",
    "    category: str = Field(description=\"1-2 word describing the category of the problem\")\n",
    "    trans_msg: str = Field(description=\"Translated customer IT support query message in English\")\n",
    "    response: str = Field(description=\"Response to the customer in their original language - orig_lang\")\n",
    "    trans_response: str = Field(description=\"Response to the customer in English\")\n",
    "\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=ITSupportResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "befb07bf-eb9c-4403-aa61-9faa14e70c0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "TEQL4DhYTZug"
   },
   "source": [
    "### Create the input prompt for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "958ac9b6-7bfd-4a35-a1fd-6f61719d7ca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XbT3tGUUSIct"
   },
   "outputs": [],
   "source": [
    "# create the final prompt with formatting instructions from the parser\n",
    "prompt_txt = \"\"\"\n",
    "             Act as an Information Technology (IT) customer support agent.\n",
    "             For the IT support message mentioned below\n",
    "             use the following output format when generating the output response\n",
    "\n",
    "             Output format instructions:\n",
    "             {format_instructions}\n",
    "\n",
    "             Customer IT support message:\n",
    "             {it_support_msg}\n",
    "             \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_txt,\n",
    "    input_variables=[\"it_support_msg\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab2eb974-20aa-404a-90e9-b5465a3f393e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RMA7qY1XTeeR"
   },
   "source": [
    "### Create a LCEL LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bafb0fef-19c8-46a3-b741-2cbb9335eb51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Le18crwjSnY_"
   },
   "outputs": [],
   "source": [
    "# create a simple LCEL chain to take the prompt, pass it to the LLM, enforce response format using the parser\n",
    "llm_chain = (prompt\n",
    "              |\n",
    "            chatgpt\n",
    "              |\n",
    "            parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcaf9216-1cb3-42e9-9092-63d33ab044ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "li4TbuTGTj2H"
   },
   "source": [
    "### Access Customer IT Support ticket data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a08d71ef-99b7-4f39-a7f3-230d5ed75b07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdlcULKISsC2",
    "outputId": "16eb3869-ef21-46cf-c5b3-f63e4ce7a585"
   },
   "outputs": [],
   "source": [
    "it_support_queue = [\n",
    "    \"Não consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.\",\n",
    "    \"Ho problemi a stampare i documenti da remoto. Il lavoro non viene inviato alla stampante di rete.\",\n",
    "    \"プリンターのトナーを交換しましたが、印刷品質が低下しています。サポートが必要です。\",\n",
    "    \"Я не могу войти в систему учета времени, появляется сообщение об ошибке. Мне нужна помощь.\",\n",
    "    \"Internet bağlantım çok yavaş ve bazen tamamen kesiliyor. Yardım eder misiniz?\",\n",
    "    \"Не могу установить обновление безопасности. Появляется код ошибки. Помогите, пожалуйста.\"\n",
    "]\n",
    "\n",
    "formatted_msgs = [{\"it_support_msg\": msg}\n",
    "                    for msg in it_support_queue]\n",
    "formatted_msgs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb826750-9915-44dc-b709-b632487d77d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MuTYg0GyTtei"
   },
   "source": [
    "### Get responses from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a829b33d-208d-4a53-9e12-189a4528735f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "adEaXYtsSxWa"
   },
   "outputs": [],
   "source": [
    "responses = llm_chain.map().invoke(formatted_msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d21c6287-fce3-406f-8028-22cc430e6abb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7iVZrIqITu3j"
   },
   "source": [
    "### View LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85c56636-051e-4667-9e9d-e8f7a5502820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgbcB5K7S3z0",
    "outputId": "a35f454e-51cf-403b-a931-2aeae6e83b9d"
   },
   "outputs": [],
   "source": [
    "responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef34174e-235b-447d-b04a-158bc07e4784",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9U5mhraS65l",
    "outputId": "8f350fc6-97e8-4116-b838-f26b4ca05194"
   },
   "outputs": [],
   "source": [
    "type(responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02e16d43-3e99-4c5b-a619-876f9752ada2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "xD3rJqPGS-bd",
    "outputId": "7d13c32a-6007-478f-f2d7-9bcefeb89b08"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(responses)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa8e1f26-d321-400b-8e4d-f563386f94ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IKS3-MEFTyjM"
   },
   "source": [
    "Try out more use-cases based on your own problems using what you learnt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "313bf6bd-786e-48e2-b5f9-d64174bf1d25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "M4 L2,3,4_Project_Prompt_Engineering_with_LangChain_and_ChatGPT",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
