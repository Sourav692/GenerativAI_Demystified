{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkZ-tYIsqsAP"
      },
      "source": [
        "# Exploring LLM Chains with LCEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLED4tsoFhll",
        "outputId": "dc4407fa-fa89-43d2-cf87-1c62b63e6eea"
      },
      "outputs": [],
      "source": [
        "# Updated package versions and import paths \n",
        "# Ensures consistency with changes in earlier modules!pip install langchain==0.3.21\n",
        "!pip install langchain-openai==0.3.9\n",
        "!pip install langchain-community==0.3.19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1hjA4hPFhlo",
        "outputId": "21acd81f-d239-4747-d0e7-c535f0267972"
      },
      "outputs": [],
      "source": [
        "# for drawing text graphs\n",
        "!pip install grandalf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9c37cLnSrbg"
      },
      "source": [
        "## Enter Open AI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv3JzCEx_PAd"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T0s0um5Svfa"
      },
      "source": [
        "## Setup Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oeckxFBcc0E"
      },
      "source": [
        "## Load Connection to LLM\n",
        "\n",
        "Here we create a connection to ChatGPT to use later in our chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHa9LMOfcOCV"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "# Updated parameter name from model_name to model:\n",
        "chatgpt = ChatOpenAI(model='gpt-4o-mini', temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD3EKYm8M8gg"
      },
      "source": [
        "## Working with LangChain Chains\n",
        "\n",
        "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components. Also running on multiple data points can be done easily with chains.\n",
        "\n",
        "Chain's are the legacy interface for \"chained\" applications. We define a Chain very generically as a sequence of calls to components, which can include other chains.\n",
        "\n",
        "Here we will be using LCEL chains exclusively"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng-9uxLActTT"
      },
      "source": [
        "### LLM Chain with LCEL\n",
        "\n",
        "LangChain Expression Language (LCEL) connects prompts, models, parsers and retrieval components using a `|` pipe operator.\n",
        "\n",
        "Any runnables can be \"chained\" together into sequences. The output of the previous runnable's `.invoke()` call is passed as input to the next runnable. This can be done using the pipe operator `(|)`, or the more explicit `.pipe()` method, which does the same thing.\n",
        "\n",
        "The resulting `RunnableSequence` is itself a runnable, which means it can be invoked, streamed, or further chained just like any other runnable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfB6RuGLWjDT"
      },
      "outputs": [],
      "source": [
        "# Updated import paths for prompt templates:\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_txt = \"\"\"Explain to me about {topic} in 3 bullet points\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_txt)\n",
        "\n",
        "# you can also write this as llm_chain = prompt | chatgpt\n",
        "\n",
        "llm_chain = (\n",
        "    prompt\n",
        "      |\n",
        "    chatgpt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXoy-gLKW9qN",
        "outputId": "1316f87f-b4b3-4fc6-edf2-b15ce05d2e55"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(llm_chain.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMwrxRbHYynr",
        "outputId": "d1bec615-aee7-4975-fd01-7d8c20c7bb24"
      },
      "outputs": [],
      "source": [
        "print(llm_chain.get_graph().draw_ascii())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7BJKifvZNYO",
        "outputId": "227ba54c-bcd7-4f20-aa23-9b10dc155ed3"
      },
      "outputs": [],
      "source": [
        "response = llm_chain.invoke({'topic': 'Generative AI'})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_eErT0PZXWk",
        "outputId": "adb1dd3e-ddc6-4f8c-ed80-03dd259657ca"
      },
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmnzxWuhZgwv"
      },
      "source": [
        "Adding an output parser now to just get the response as a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqXIww5vZctH"
      },
      "outputs": [],
      "source": [
        "# Updated import path for output parsers:\n",
        "from langchain.output_parsers.str_output import StrOutputParser\n",
        "\n",
        "# chain with an output parser\n",
        "llm_chain = (\n",
        "    prompt\n",
        "      |\n",
        "    chatgpt\n",
        "      |\n",
        "    StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMO_Vz2KZ-M8",
        "outputId": "e1c59861-a767-45b4-dd14-42b8b6acb3e2"
      },
      "outputs": [],
      "source": [
        "display(Image(llm_chain.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh72M_cKa6Lk",
        "outputId": "83e98b45-6ec3-44fb-f34b-2f88976c30a4"
      },
      "outputs": [],
      "source": [
        "response = llm_chain.invoke({'topic': 'Generative AI'})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPSWayj_cP-i"
      },
      "outputs": [],
      "source": [
        "reviews = [\n",
        "    f\"\"\"\n",
        "    Purchased this adorable koala plush toy for my nephew's birthday,\n",
        "    and he's absolutely smitten with it, carrying it around everywhere he goes.\n",
        "    The plush is incredibly soft, and the koala's face has an endearing expression.\n",
        "    However, I did find it a tad on the smaller side given its price point.\n",
        "    I believe there may be larger alternatives available at a similar price.\n",
        "    To my delight, it arrived a day earlier than anticipated,\n",
        "    allowing me to enjoy it briefly before gifting it to him.\n",
        "    \"\"\",\n",
        "    f\"\"\"\n",
        "    Required a stylish lamp for my office space, and this particular one\n",
        "    came with added storage at a reasonable price.\n",
        "    The delivery was surprisingly quick, arriving within just two days.\n",
        "    However, the pull string for the lamp suffered damage during transit.\n",
        "    To my relief, the company promptly dispatched a replacement,\n",
        "    which arrived within a few days. Assembly was a breeze.\n",
        "    Then, I encountered an issue with a missing component,\n",
        "    but their support team responded swiftly and provided the missing part.\n",
        "    It appears to be a commendable company that genuinely values its\n",
        "    customers and the quality of its products.\n",
        "    \"\"\"\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90dSQ0yciLQa"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = \"\"\"\n",
        "            Act as a product review analyst.\n",
        "            Your task is to generate a short summary of a product\n",
        "            review from an ecommerce site.\n",
        "\n",
        "            Generate a summary of the review (max 2 lines)\n",
        "            Also show both the positives and negatives from the review (max 2 bullets)\n",
        "\n",
        "            ```{review}```\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
        "llm_chain = (\n",
        "    prompt_template\n",
        "      |\n",
        "    chatgpt\n",
        "      |\n",
        "    StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SjsgsUdiibW"
      },
      "outputs": [],
      "source": [
        "result = llm_chain.invoke({'review': reviews[0]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL0EKbgXivEj",
        "outputId": "c13b12d5-95a0-469e-816e-367a3f9a60b5"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WsezaGqi00W",
        "outputId": "88ddf297-1020-448e-a952-09939d0d780f"
      },
      "outputs": [],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNLieaWvi2XQ",
        "outputId": "ea8a0643-5412-4e49-c611-154e2d2285c2"
      },
      "outputs": [],
      "source": [
        "formatted_reviews = [{'review': review}\n",
        "                        for review in reviews]\n",
        "\n",
        "results = llm_chain.map().invoke(formatted_reviews)\n",
        "len(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtaDS_IXjhRw",
        "outputId": "cbe8ea04-154c-46a6-bb70-d409ab262e32"
      },
      "outputs": [],
      "source": [
        "for result in results:\n",
        "    print(result)\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}