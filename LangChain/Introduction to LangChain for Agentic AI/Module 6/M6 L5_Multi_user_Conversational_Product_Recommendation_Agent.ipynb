{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa91d8c5-decb-4923-b47a-abc16eb0521e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XTzBUFWQ-OWj"
   },
   "source": [
    "# Project: Build a Multi-user Conversational Product Recommendation Agent\n",
    "\n",
    "![](https://i.imgur.com/7ZHpO6U.png)\n",
    "\n",
    "\n",
    "___Created By: Dipanjan (DJ)___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef5027b3-1090-4d30-a256-d2b3fe7b0a1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L1KvMtf54l0d"
   },
   "source": [
    "## Install OpenAI and LangChain dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81ab77ad-62d6-477e-8a51-668b18049185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEzecGfICCw1",
    "outputId": "e1583440-5555-4f91-f34e-ca90bca72ce8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.11\n",
    "!pip install langchain-openai==0.2.12\n",
    "!pip install langchain-community==0.3.11\n",
    "!pip install gdown\n",
    "!pip install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "517e5215-8388-423e-8a68-38f3b04e1956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "939bf8bb-8bf3-457c-ace9-187b4e3b7661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "CiwGjVWK4q6F"
   },
   "source": [
    "## Load OpenAI API Credentials\n",
    "\n",
    "Here we load it from get password function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3672c0be-1ff9-49f3-a074-92082aa267cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PtBa7rlWJWH3"
   },
   "source": [
    "## Enter API Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "947b662d-3216-45f7-b0e2-f58ede35fee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ogxBkS6ZnnC",
    "outputId": "fde849a4-4e91-410b-96f4-a2c3dd72fd82"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "241e855b-c0c0-49ed-ae2f-705c4f69face",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "kDe44J0N0NcC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "496ee992-486e-4d79-881e-db1ed831aa29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "FXpLuazqAC1o"
   },
   "source": [
    "## Get Dataset of Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e049acd0-62a8-4ded-a7aa-dc48b57b499a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OcOjYvRxAFSI",
    "outputId": "01e5fe85-e192-4a4f-e70f-29bd561c6694"
   },
   "outputs": [],
   "source": [
    "# download it manually from https://drive.google.com/file/d/1tAwsv97fICL74uJH9fDlxNEZ_YFFJS3W/view?usp=sharing\n",
    "# or use gdown as follows to download it automatically\n",
    "!gdown 1tAwsv97fICL74uJH9fDlxNEZ_YFFJS3W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fda5b7b5-f33a-450e-b36a-94d21d576832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "BVhtbWb2C7S6",
    "outputId": "392446aa-9c2f-4f00-f862-498d7ad615a1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./Ecommerce_Product_List.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71be939f-58b5-4f5e-820e-917fc962cebf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKTqiNhtD0gx",
    "outputId": "4a969812-9b73-4330-828d-aea69a3240cf"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b33499c4-5191-45ec-80c4-bf7dfffc8d5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mh8VeyWoEyeC",
    "outputId": "0d87636e-c033-4291-e601-80e85541c120"
   },
   "outputs": [],
   "source": [
    "df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4e92da4-1cae-4c17-9b7f-a56048c85d34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfDCcH1cFDkr",
    "outputId": "f5321388-5ade-411c-f8b1-ba8b6d60892a"
   },
   "outputs": [],
   "source": [
    "df['Rating'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffee76ad-c07a-4e08-9b19-1f7264d2c20d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XH1TCb01Dm5a"
   },
   "source": [
    "## Product Recommender Agent Workflow\n",
    "\n",
    "We will:\n",
    "\n",
    "- Build a Pandas Code Tool Executor to filter products based on category, rating, price\n",
    "- Build a LLM Recommender Chain to filter products based on natural language descriptions using an LLM\n",
    "- Build a query rephraser LLM Chain to combine multiple queries in a conversation to generate better queries\n",
    "- Combine all of these into a single chain\n",
    "- Add conversational memory to this system\n",
    "\n",
    "![](https://i.imgur.com/qJIsErH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "622e0890-d9c8-4810-978e-579592432b29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "WID98LhFAV7r"
   },
   "source": [
    "## Text 2 Pandas Code Tool Executor Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b08748b4-452c-424b-b2e1-b851a18b7470",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1ru0VstDcnL",
    "outputId": "13212455-ef0f-45fc-d7f5-e4f34580ad1d"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import chain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n",
    "\n",
    "@chain\n",
    "def pandas_code_tool_executor(query):\n",
    "    result_df = eval(query)\n",
    "    if result_df.empty:\n",
    "        return df.to_markdown()\n",
    "    else:\n",
    "        return result_df.to_markdown()\n",
    "\n",
    "FILTER_PROMPT = \"\"\"Given the following schema of a dataframe table,\n",
    "            your task is to figure out the best pandas query to\n",
    "            filter the dataframe based on the user query which\n",
    "            will be in natural language.\n",
    "\n",
    "            The schema is as follows:\n",
    "\n",
    "            #   Column        Non-Null Count  Dtype\n",
    "            ---  ------        --------------  -----\n",
    "            0   Product_ID    30 non-null     object\n",
    "            1   Product_Name  30 non-null     object\n",
    "            2   Category      30 non-null     object\n",
    "            3   Price_USD     30 non-null     int64\n",
    "            4   Rating        30 non-null     float64\n",
    "            5   Description   30 non-null     object\n",
    "\n",
    "            Category has values: ['Laptop', 'Tablet', 'Smartphone',\n",
    "                                  'Smartwatch', 'Camera',\n",
    "                                  'Headphones', 'Mouse', 'Keyboard',\n",
    "                                  'Monitor', 'Charger']\n",
    "\n",
    "            Rating ranges from 1 - 5 in floats\n",
    "\n",
    "            You will try to figure out the pandas query focusing\n",
    "            only on Category, Price_USD and Rating if the user mentions\n",
    "            anything about these in their natural language query.\n",
    "            Do not make up column names, only use the above.\n",
    "            If not the pandas query should just return the full dataframe.\n",
    "            Remember the dataframe name is df.\n",
    "\n",
    "            Just return only the pandas query and nothing else.\n",
    "            Do not return the results as markdown, just return the query\n",
    "\n",
    "            User Query: {user_query}\n",
    "            Pandas Query:\n",
    "        \"\"\"\n",
    "\n",
    "filter_prompt_template = ChatPromptTemplate.from_template(FILTER_PROMPT)\n",
    "\n",
    "data_filter_chain = (\n",
    "         filter_prompt_template\n",
    "           |\n",
    "         chatgpt\n",
    "           |\n",
    "         StrOutputParser()\n",
    "           |\n",
    "         pandas_code_tool_executor\n",
    ")\n",
    "\n",
    "product_table = data_filter_chain.invoke({\"user_query\": \"\"\"looking for a tablet with > 10 inch display\n",
    "                                                           and at least 64GB storage\"\"\"})\n",
    "print(product_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10fe70b2-79c7-49dc-9005-01cb84f3f1ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1ntOX8xmA8Rj"
   },
   "source": [
    "## Product Description LLM Recommender Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "201465d9-f4e1-41de-b069-83be1334b75a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtAeKNhVpA1l",
    "outputId": "9c5f6e5b-e5c1-4035-f7aa-7006798fa21c"
   },
   "outputs": [],
   "source": [
    "RECOMMEND_PROMPT = \"\"\"Act as an expert retail product advisor\n",
    "                      Given the following table of products,\n",
    "                      focus on the product attributes and description in the table\n",
    "                      and based on the user query below do the following\n",
    "\n",
    "                      - Recommend the most appropriate products based on the query\n",
    "                      - Recommedation should have product name, price,  rating, description\n",
    "                      - Also add a brief on why you recommend the product\n",
    "                      - Do not make up products or recommend products not in the table\n",
    "                      - If some specifications do not match focus on the ones which match and recommend\n",
    "                      - If nothing matches recommend 5 random products from the table\n",
    "                      - Do not generate anything else except the fields mentioned above\n",
    "\n",
    "                    In case the user query is just a generic query or greeting\n",
    "                    respond to them appropriately without recommending any products\n",
    "\n",
    "                    Product Table:\n",
    "                    {product_table}\n",
    "\n",
    "                    User Query:\n",
    "                    {user_query}\n",
    "\n",
    "                    Recommendation:\n",
    "                    \"\"\"\n",
    "\n",
    "recommend_prompt_template = ChatPromptTemplate.from_template(RECOMMEND_PROMPT)\n",
    "\n",
    "recommend_chain = (\n",
    "         recommend_prompt_template\n",
    "           |\n",
    "         chatgpt\n",
    "           |\n",
    "         StrOutputParser()\n",
    ")\n",
    "\n",
    "response = recommend_chain.invoke({\"user_query\": \"\"\"looking for a tablet with greater than 10 inch display\n",
    "                                                           and at least 64GB storage\"\"\",\n",
    "                                   \"product_table\": product_table})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1c68e58-25c2-40ed-b892-ee3cee3c46c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "81hv-9UJoxeV"
   },
   "outputs": [],
   "source": [
    "combined_chain = (\n",
    "         {\n",
    "             'user_query' : itemgetter('user_query'),\n",
    "             'product_table' : data_filter_chain\n",
    "         }\n",
    "           |\n",
    "         recommend_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff8fa524-739a-43cc-860c-a68b8f66a734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfOQaZFYKiTN",
    "outputId": "1b3b7263-6a5b-4035-917a-4895bb9c55a1"
   },
   "outputs": [],
   "source": [
    "response = combined_chain.invoke({\"user_query\": \"\"\"looking for a cheap laptop\n",
    "                                                      in the range of 500 - 1000\n",
    "                                                \"\"\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae8a8e83-8b50-4492-807c-7da18ed93519",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "fm6pZinBV4Q1"
   },
   "source": [
    "## Multi-user Window-based Conversation Chains with persistence\n",
    "\n",
    "The beauty of `SQLChatMessageHistory` is that we can store separate conversation histories per user or session which is often the need for real-world chatbots which will be accessed by many users at the same time. Instead of in-memory we can store it in a SQL database which can be used to store a lot of conversations.\n",
    "\n",
    "We use a `get_session_history` function which is expected to take in a `session_id` and return a Message History object. Everything is stored in a SQL database. This `session_id` is used to distinguish between separate conversations, and should be passed in as part of the config when calling the new chain\n",
    "\n",
    "We also use a `memory_buffer_window` function to only use the top-K last historical conversations before sending it to the LLM, basically our own implementation of `ConversationBufferWindowMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72fc9332-8e11-4eab-9787-39fc6b52da23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tLdc_EEzWSKG"
   },
   "outputs": [],
   "source": [
    "# removes the memory database file - usually not needed\n",
    "# you can run this only when you want to remove all conversation histories\n",
    "!rm memory.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e522fdde-47ba-4122-864d-ef3c36b800a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-zsELwIgBind"
   },
   "source": [
    "## Historical Conversation Query Rephraser Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a75d66d3-eba7-4aaf-8bc3-e3e86a6e0a18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "J-Qam16QUgkj"
   },
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# used to retrieve conversation history from database\n",
    "# based on a specific user or session ID\n",
    "def get_session_history_db(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
    "\n",
    "\n",
    "SYS_PROMPT = \"\"\"You are a retail product expert.\n",
    "                Carefully analyze the following conversation history\n",
    "                and the current user query.\n",
    "                Refer to the history and rephrase the current user query\n",
    "                into a standalone query which can be used without the history\n",
    "                for making search queries.\n",
    "                Rephrase only if needed.\n",
    "                Just return the query and do not answer it.\n",
    "            \"\"\"\n",
    "\n",
    "# prompt to load in history and current input from the user\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"\"\"Current User Query:\n",
    "                     {human_input}\n",
    "                  \"\"\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create a memory buffer window function to return the last K conversations\n",
    "def memory_buffer_window(messages, k=10): # 10 here means retrieve only last 2*10 user-AI conversations\n",
    "    return messages[-(2*k):]\n",
    "\n",
    "# create a basic LLM Chain which only sends the last K conversations per user\n",
    "rephrase_query_chain = (\n",
    "    RunnablePassthrough.assign(history=lambda x: memory_buffer_window(x[\"history\"]))\n",
    "      |\n",
    "    prompt_template\n",
    "      |\n",
    "    chatgpt\n",
    "      |\n",
    "    StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "109b5de3-224e-4765-aa9a-adfe8cecfe80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XE5KFcjmBprc"
   },
   "source": [
    "## Combining All Chains Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b37148e4-3896-443e-b54e-66d6d3ca1d5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xqF_mibbBo_H"
   },
   "outputs": [],
   "source": [
    "combined_chain = (\n",
    "         {\n",
    "             'human_input' : itemgetter('human_input'),\n",
    "             'history' : itemgetter('history')\n",
    "         }\n",
    "           |\n",
    "        {\n",
    "            'user_query': rephrase_query_chain\n",
    "        }\n",
    "           |\n",
    "        RunnablePassthrough.assign(product_table=data_filter_chain)\n",
    "            |\n",
    "        recommend_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3c1b881-c1d7-425e-bab8-774c0bab094b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "TgV1zW5YBxBD"
   },
   "source": [
    "## Wrapping it into a Multi-user Conversation Chain with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5481c384-f317-4965-b5c3-093b2dabdbd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "GKepk9DBrRNS"
   },
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "# create a conversation chain which can load memory based on specific user or session id\n",
    "conv_chain = RunnableWithMessageHistory(\n",
    "    combined_chain,\n",
    "    get_session_history_db,\n",
    "    input_messages_key=\"human_input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# create a utility function to take in current user input prompt and their session ID\n",
    "# streams result live back to the user from the LLM\n",
    "def chat_with_llm(prompt: str, session_id: str):\n",
    "    response = conv_chain.invoke({\"human_input\": prompt},\n",
    "                                 {'configurable': { 'session_id': session_id}})\n",
    "    console = Console()\n",
    "    console.print(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70a66592-15fb-43bc-ad3a-4e53bf3670a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "kqfxpy4qB11L"
   },
   "source": [
    "## Test Product Recommender Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bbf9085-6724-4b7a-955b-5d1464f613e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gkPyZbTnxBSY"
   },
   "source": [
    "Test conversation chain for user 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b2b77ad-9c62-4191-9169-5d5e9db94438",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "ebkhHCjfWl0q",
    "outputId": "0bda24d0-14a1-4b7e-f01c-45c32df01737"
   },
   "outputs": [],
   "source": [
    "user_id = 'jim001'\n",
    "prompt = \"looking for a tablet\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75777e53-6724-478a-978e-f16d50aa3b7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "cW6On1LasjYb",
    "outputId": "00a800b2-86b3-49a7-eaf2-cf9f5efe44d8"
   },
   "outputs": [],
   "source": [
    "prompt = \"want one which has display larger than 10 inches\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99817de9-e755-4b38-b7e8-896e4a8207f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "gMY_wEU5soCL",
    "outputId": "097407d1-843a-43f2-b720-69854da47303"
   },
   "outputs": [],
   "source": [
    "prompt = \"need at least 128GB disk space\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9767c64b-09d7-42f5-957e-963708f1aad0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "qDLyOrajxD8i"
   },
   "source": [
    "Now test conversation chain for user 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0957178e-0527-4f91-b86c-30530c382f42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "YBe4sodJW9UL",
    "outputId": "03f52591-6774-49b3-c25b-57d195c0a31a"
   },
   "outputs": [],
   "source": [
    "user_id = 'bond007'\n",
    "prompt = \"I want a laptop with a high rating\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03d0c477-f850-4095-a00c-74453dfef13f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "ebV3Mt-vXG3U",
    "outputId": "49e15bee-2e72-41ae-f175-71ee69ee7065"
   },
   "outputs": [],
   "source": [
    "prompt = \"want atleast 16GB memory\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "M6 L5_Multi_user_Conversational_Product_Recommendation_Agent",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
