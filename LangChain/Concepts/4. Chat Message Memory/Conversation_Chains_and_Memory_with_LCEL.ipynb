{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3ef54a",
   "metadata": {},
   "source": [
    "# Exploring Conversation Chains and Memory with LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91950cda",
   "metadata": {},
   "source": [
    "## Install OpenAI, and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8d78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.50.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\n",
      "langchain-huggingface 0.3.0 requires huggingface-hub>=0.30.2, but you have huggingface-hub 0.27.1 which is incompatible.\n",
      "langchain-huggingface 0.3.0 requires langchain-core<1.0.0,>=0.3.65, but you have langchain-core 0.3.63 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qq langchain\n",
    "!pip install -qq langchain-openai\n",
    "!pip install -qq langchain-community\n",
    "!pip install -qq langchain-chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e16309",
   "metadata": {},
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9112fa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fbc8f2",
   "metadata": {},
   "source": [
    "## Load Connection to LLM\n",
    "\n",
    "Here we create a connection to ChatGPT to use later in our chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4c931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efeeecb",
   "metadata": {},
   "source": [
    "## Working with LangChain Chains\n",
    "\n",
    "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components. Also running on multiple data points can be done easily with chains.\n",
    "\n",
    "Chain's are the legacy interface for \"chained\" applications. We define a Chain very generically as a sequence of calls to components, which can include other chains.\n",
    "\n",
    "Here we will be using LCEL chains exclusively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b81c94",
   "metadata": {},
   "source": [
    "### The Problem with Simple LLM Chains\n",
    "\n",
    "Simple LLM Chains cannot keep a track of past conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e253fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate\n",
    "\n",
    "prompt_text = \"\"\"{query}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "llm_chain = prompt | chatgpt\n",
    "\n",
    "response = llm_chain.invoke({\"query\": \"What is the capital of France?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1c9b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you please provide more context or specify what aspect of India you are interested in? India is a vast country with a rich history, diverse culture, and significant developments in various fields such as politics, economy, technology, and social issues. Let me know what specific information you are looking for!\n"
     ]
    }
   ],
   "source": [
    "response = llm_chain.invoke({\"query\":\"And what about India?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f316d7c",
   "metadata": {},
   "source": [
    "## Working with ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24257419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/xkrl1q210t5_4t4hvbx286800000gp/T/ipykernel_5092/2476208786.py:14: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "SYS_PROMPT = \"\"\"Act as a helpful assistant and give brief answers\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        MessagesPlaceholder(variable_name=\"history\"), # This is where the conversation history will be stored\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8254735a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.memory.buffer.ConversationBufferMemory'>\n"
     ]
    }
   ],
   "source": [
    "print(type(memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ead6b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to get historical conversation messages from the memory\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8d65341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0acd0936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# lets create a function now which returns the list of messages from memory\n",
    "def get_memory_messages(query):\n",
    "    return memory.load_memory_variables(query)['history']\n",
    "\n",
    "print(get_memory_messages('What are the first four colors of a rainbow?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f5af102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableLambda"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(RunnableLambda(get_memory_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01afa779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# testing out the function with a runnable lambda which will go into our chain\n",
    "# this returns the history but we also need to send our current query to the prompt\n",
    "print(RunnableLambda(get_memory_messages).invoke({'query': 'What are the first four colors of a rainbow?'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaa66797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the first four colors of a rainbow1?',\n",
       " 'query2': 'sourav',\n",
       " 'history': []}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use RunnablePassthrough.assign() to combine the current input with memory history\n",
    "# This allows us to pass the query unchanged while adding the conversation history\n",
    "# The .assign() method adds a new key 'history' to the input dictionary\n",
    "# RunnableLambda(get_memory_messages) extracts the conversation history from memory\n",
    "RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    ).invoke({'query': 'What are the first four colors of a rainbow1?','query2':\"sourav\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e299f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'sourav', 'history': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1 = {\n",
    "    'query': RunnableLambda(lambda x: x['query2'])\n",
    "} |RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    )\n",
    "chain1.invoke({'query1': 'What are the first four colors of a rainbow1?','query2':\"sourav\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e3b1dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the first four colors of a rainbow1?', 'history': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = {\n",
    "    'query': RunnableLambda(lambda x: x['query1'])\n",
    "} |RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    )\n",
    "\n",
    "chain2.invoke({'query1': 'What are the first four colors of a rainbow1?','query2':\"sourav\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f8ec867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the first four colors of a rainbow1?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = RunnableLambda(lambda x: x['query1'])\n",
    "runnable.invoke({'query1': 'What are the first four colors of a rainbow1?', 'query2': \"sourav\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cfa6b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the first four colors of a rainbow1?',\n",
       " 'llm1': 'completion',\n",
       " 'llm2': 'completion',\n",
       " 'history': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fake_llm(prompt: str) -> str: # Fake LLM for the example\n",
    "    return \"completion\"\n",
    "\n",
    "chain = {\n",
    "    'query': RunnableLambda(lambda x: x['query']), \n",
    "    'llm1':  fake_llm,\n",
    "    'llm2':  fake_llm,\n",
    "} | RunnablePassthrough.assign(\n",
    "    history=RunnableLambda(get_memory_messages)\n",
    ")\n",
    "\n",
    "chain.invoke({'query': 'What are the first four colors of a rainbow1?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c85f56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our conversation chain now\n",
    "def get_memory_messages(query):\n",
    "    return memory.load_memory_variables(query)['history']\n",
    "\n",
    "conversation_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    ) # sends current query (input by user at runtime) and history messages to next step\n",
    "      |\n",
    "    prompt # creates prompt using the previous two variables\n",
    "      |\n",
    "    chatgpt # generates response using the prompt from previous step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94c50119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The first four colors of a rainbow are red, orange, yellow, and green.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 30, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None} id='run--b2510428-ef84-4254-a0ea-e768dae4d4ac-0' usage_metadata={'input_tokens': 30, 'output_tokens': 17, 'total_tokens': 47, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What are the first four colors of a rainbow?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "469eb5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/xkrl1q210t5_4t4hvbx286800000gp/T/ipykernel_5092/2263478525.py:1: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response.dict() #deprecated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': 'The first four colors of a rainbow are red, orange, yellow, and green.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 17,\n",
       "   'prompt_tokens': 30,\n",
       "   'total_tokens': 47,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_34a54ae93c',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run--b2510428-ef84-4254-a0ea-e768dae4d4ac-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 30,\n",
       "  'output_tokens': 17,\n",
       "  'total_tokens': 47,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.dict() #deprecated\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d800c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first four colors of a rainbow are red, orange, yellow, and green.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af24bf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02985654",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(query, {\"output\": response.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf6b62d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='What are the first four colors of a rainbow?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The first four colors of a rainbow are red, orange, yellow, and green.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a89ec967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The other three colors of a rainbow are blue, indigo, and violet.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'and the other 3?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25fdc930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='What are the first four colors of a rainbow?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The first four colors of a rainbow are red, orange, yellow, and green.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='and the other 3?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The other three colors of a rainbow are blue, indigo, and violet.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0246457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\n",
      "\n",
      "- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Explain AI in 2 bullet points'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d762622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='What are the first four colors of a rainbow?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The first four colors of a rainbow are red, orange, yellow, and green.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='and the other 3?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The other three colors of a rainbow are blue, indigo, and violet.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Explain AI in 2 bullet points', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\\n\\n- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a4268d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What are the first four colors of a rainbow?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The first four colors of a rainbow are red, orange, yellow, and green.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='and the other 3?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The other three colors of a rainbow are blue, indigo, and violet.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Explain AI in 2 bullet points', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\\n\\n- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d247b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\n",
      "\n",
      "- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields requiring advanced data analysis and pattern recognition.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Now do the same for Deep Learning'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9b61a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What are the first four colors of a rainbow?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The first four colors of a rainbow are red, orange, yellow, and green.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='and the other 3?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The other three colors of a rainbow are blue, indigo, and violet.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Explain AI in 2 bullet points', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\\n\\n- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Now do the same for Deep Learning', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\\n\\n- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields requiring advanced data analysis and pattern recognition.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7a826de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So far, we have discussed the following topics:\n",
      "\n",
      "1. The first four colors of a rainbow (red, orange, yellow, green) and the remaining three (blue, indigo, violet).\n",
      "2. A brief explanation of Artificial Intelligence (AI) in two bullet points.\n",
      "3. A brief explanation of Deep Learning in two bullet points.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What have we discussed so far?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "872d0e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What are the first four colors of a rainbow?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The first four colors of a rainbow are red, orange, yellow, and green.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='and the other 3?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The other three colors of a rainbow are blue, indigo, and violet.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Explain AI in 2 bullet points', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\\n\\n- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Now do the same for Deep Learning', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\\n\\n- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields requiring advanced data analysis and pattern recognition.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What have we discussed so far?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='So far, we have discussed the following topics:\\n\\n1. The first four colors of a rainbow (red, orange, yellow, green) and the remaining three (blue, indigo, violet).\\n2. A brief explanation of Artificial Intelligence (AI) in two bullet points.\\n3. A brief explanation of Deep Learning in two bullet points.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a382b",
   "metadata": {},
   "source": [
    "## Conversation Chains with ConversationBufferWindowMemory\n",
    "\n",
    "If you have a really long conversation, you might exceed the max token limit of the context window allowed for the LLM when using `ConversationBufferMemory` so `ConversationBufferWindowMemory` helps in just storing the last K conversations (one conversation piece is one user message and the corresponding AI message from the LLM) and thus helps you manage token limits and costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf5d475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/xkrl1q210t5_4t4hvbx286800000gp/T/ipykernel_5092/96416143.py:15: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(return_messages=True, k=2)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "SYS_PROMPT = \"\"\"Act as a helpful assistant and give brief answers\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# stores last 2 sets of human-AI conversations\n",
    "memory = ConversationBufferWindowMemory(return_messages=True, k=2)\n",
    "\n",
    "# creating our conversation chain now\n",
    "def get_memory_messages(query):\n",
    "    return memory.load_memory_variables(query)['history']\n",
    "\n",
    "conversation_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    ) # sends current query (input by user at runtime) and history messages to next step\n",
    "      |\n",
    "    prompt # creates prompt using the previous two variables\n",
    "      |\n",
    "    chatgpt # generates response using the prompt from previous step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a4f1f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first four colors of a rainbow are red, orange, yellow, and green.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What are the first four colors of a rainbow?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28df3749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The other three colors of a rainbow are blue, indigo, and violet.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'and the other 3?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8f941a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\n",
      "\n",
      "- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Explain AI in 2 bullet points'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53730694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\n",
      "\n",
      "- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields where large amounts of unstructured data are processed.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Now do the same for Deep Learning'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0495b43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Explain AI in 2 bullet points', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\\n\\n- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection and algorithmic trading), and everyday technology (virtual assistants and recommendation systems).', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Now do the same for Deep Learning', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\\n\\n- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields where large amounts of unstructured data are processed.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05e8ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So far, we have discussed the following topics:\n",
      "\n",
      "1. A brief explanation of Artificial Intelligence (AI) in two bullet points, covering its definition and applications.\n",
      "2. A brief explanation of Deep Learning in two bullet points, including its definition and applications.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What have we discussed so far?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92bce860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Now do the same for Deep Learning', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='- **Definition**: Deep Learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to model complex patterns in large datasets, enabling machines to learn from data in a way that mimics human brain function.\\n\\n- **Applications**: Deep Learning is widely used in image and speech recognition, natural language processing, autonomous vehicles, and various other fields where large amounts of unstructured data are processed.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What have we discussed so far?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='So far, we have discussed the following topics:\\n\\n1. A brief explanation of Artificial Intelligence (AI) in two bullet points, covering its definition and applications.\\n2. A brief explanation of Deep Learning in two bullet points, including its definition and applications.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1bd1a8",
   "metadata": {},
   "source": [
    "### Conversation Chains with ConversationSummaryMemory\n",
    "\n",
    "If you have a really long conversation or a lot of messages, you might exceed the max token limit of the context window allowed for the LLM when using `ConversationBufferMemory`\n",
    "\n",
    "`ConversationSummaryMemory` creates a summary of the conversation history over time. This can be useful for condensing information from the conversation messages over time.\n",
    "\n",
    "This memory is most useful for longer conversations, where keeping the past message history in the prompt verbatim would take up too many tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f9d831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "SYS_PROMPT = \"\"\"Act as a helpful assistant and give brief answers\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        # MessagesPlaceholder(variable_name=\"history\") - This placeholder inserts conversation history messages into the prompt\n",
    "        # The variable_name can be any string - \"history\", \"history_summary\", \"chat_history\", etc.\n",
    "        # It will be populated by the memory.load_memory_variables() function with the corresponding key\n",
    "        MessagesPlaceholder(variable_name=\"history_summary\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(return_messages=True, llm=chatgpt)\n",
    "# creating our conversation chain now\n",
    "def get_memory_messages(query):\n",
    "    return memory.load_memory_variables(query)['history']\n",
    "\n",
    "conversation_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history_summary=RunnableLambda(get_memory_messages)\n",
    "    ) # sends current query (input by user at runtime) and history messages as a summary to next step\n",
    "      |\n",
    "    prompt # creates prompt using the previous two variables\n",
    "      |\n",
    "    chatgpt # generates response using the prompt from previous step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0bfdb166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems, enabling them to perform tasks such as learning, reasoning, and problem-solving.\n",
      "\n",
      "- **Applications**: AI is used in various fields, including healthcare (diagnosis and treatment recommendations), finance (fraud detection), autonomous vehicles, customer service (chatbots), and more, enhancing efficiency and decision-making.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Explain AI in 2 bullet points'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1395e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Deep Learning is a subset of machine learning that uses neural networks with many layers to analyze and learn from large amounts of data, enabling complex pattern recognition and decision-making.\n",
      "- It is widely used in applications such as image and speech recognition, natural language processing, and autonomous systems, significantly improving performance in these areas.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Now do the same for Deep Learning'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c1980503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human asks the AI to explain artificial intelligence in two bullet points. The AI defines artificial intelligence as the simulation of human intelligence processes by machines, enabling tasks like learning and problem-solving, and lists its applications in fields such as healthcare, finance, autonomous vehicles, and customer service, highlighting its role in enhancing efficiency and decision-making. The human then requests a similar explanation for Deep Learning, and the AI describes it as a subset of machine learning that uses neural networks with many layers to analyze large amounts of data for complex pattern recognition and decision-making, with applications in image and speech recognition, natural language processing, and autonomous systems, significantly improving performance in these areas.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f36e9f",
   "metadata": {},
   "source": [
    "## Conversation Chains with VectorStoreRetrieverMemory\n",
    "\n",
    "`VectorStoreRetrieverMemory` stores historical conversation messages in a vector store and queries the top-K most \"relevant\" history messages every time it is called.\n",
    "\n",
    "This differs from most of the other Memory classes in that it doesn't explicitly track the order of interactions but retrieves history based on embedding similarity to the current question or prompt.\n",
    "\n",
    "In this case, the \"docs\" are previous conversation snippets. This can be useful to refer to relevant pieces of information that the AI was told earlier in the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6955fc9",
   "metadata": {},
   "source": [
    "### Connect to  Open AI Embedding Models\n",
    "\n",
    "LangChain enables us to access Open AI embedding models which include the newest models: a smaller and highly efficient `text-embedding-3-small` model, and a larger and more powerful `text-embedding-3-large` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dbe7b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06752ae7",
   "metadata": {},
   "source": [
    "#### Create a Vector Database to store conversation history\n",
    "\n",
    "Here we use the Chroma vector DB and initialize an empty database collection to store conversation messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5185c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# create empty vector DB\n",
    "chroma_db = Chroma(collection_name='history_db',\n",
    "                   embedding_function=openai_embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1927e279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/xkrl1q210t5_4t4hvbx286800000gp/T/ipykernel_5092/573889585.py:18: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = VectorStoreRetrieverMemory(retriever=retriever, return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "SYS_PROMPT = \"\"\"Act as a helpful assistant and give brief answers\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# load 2 most similar conversation messages from vector db history for each new message \\ prompt\n",
    "# this uses cosine embedding similarity to load the top 2 similar messgages to the input prompt \\ query\n",
    "retriever = chroma_db.as_retriever(search_type=\"similarity\",\n",
    "                                   search_kwargs={\"k\": 2})\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever, return_messages=True)\n",
    "\n",
    "# creating our conversation chain now\n",
    "def get_memory_messages(query):\n",
    "    return [memory.load_memory_variables(query)['history']]\n",
    "\n",
    "conversation_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(get_memory_messages)\n",
    "    ) # sends current query (input by user at runtime) and history messages to next step\n",
    "      |\n",
    "    prompt # creates prompt using the previous two variables\n",
    "      |\n",
    "    chatgpt # generates response using the prompt from previous step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7cbc358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn. It encompasses various technologies, including machine learning, natural language processing, and robotics. AI can perform tasks such as speech recognition, decision-making, and problem-solving, and is used in applications like virtual assistants, autonomous vehicles, and data analysis.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Tell me about AI'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "373278c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 2 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to analyze and learn from large amounts of data. It excels in tasks such as image and speech recognition, natural language processing, and game playing. Deep learning models automatically extract features from raw data, making them highly effective for complex problems.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What about deep learning'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5f7711d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fastest animal in the world is the peregrine falcon, which can reach speeds over 240 mph (386 km/h) during its hunting stoop (high-speed dive). On land, the cheetah holds the record, capable of sprinting up to 60-70 mph (97-113 km/h) in short bursts.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'Tell me about the fastest animal in the world in 2 lines'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e7e2066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cheetah is the fastest land animal, capable of reaching speeds of 60-70 mph (97-113 km/h) in short bursts covering distances up to 1,500 feet. Its unique adaptations, such as a lightweight body, long legs, and a flexible spine, enable it to accelerate rapidly and make sharp turns while chasing prey.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What about the cheetah?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d44c2",
   "metadata": {},
   "source": [
    "\n",
    "Now for a new query around machine learning even if the most recent conversation messages have been about animals, it uses the vector databases to load the last 2 historical conversations which are closest to the current question in terms of semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1daf45df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What about deep learning\n",
      "output: Deep learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to analyze and learn from large amounts of data. It excels in tasks such as image and speech recognition, natural language processing, and game playing. Deep learning models automatically extract features from raw data, making them highly effective for complex problems.\n",
      "query: Tell me about AI\n",
      "output: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn. It encompasses various technologies, including machine learning, natural language processing, and robotics. AI can perform tasks such as speech recognition, decision-making, and problem-solving, and is used in applications like virtual assistants, autonomous vehicles, and data analysis.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({'query': 'What about machine learning?'})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "085814d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a subset of artificial intelligence that focuses on the development of algorithms that allow computers to learn from and make predictions or decisions based on data. It involves training models on datasets to identify patterns and improve performance over time without being explicitly programmed. Machine learning is used in various applications, including recommendation systems, fraud detection, and predictive analytics.\n"
     ]
    }
   ],
   "source": [
    "query = {'query': 'What about machine learning?'}\n",
    "response = conversation_chain.invoke(query)\n",
    "memory.save_context(query, {\"output\": response.content}) # remember to save your current conversation in memory\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8094c5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What about the cheetah?\n",
      "output: The cheetah is the fastest land animal, capable of reaching speeds of 60-70 mph (97-113 km/h) in short bursts covering distances up to 1,500 feet. Its unique adaptations, such as a lightweight body, long legs, and a flexible spine, enable it to accelerate rapidly and make sharp turns while chasing prey.\n",
      "query: Tell me about AI\n",
      "output: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn. It encompasses various technologies, including machine learning, natural language processing, and robotics. AI can perform tasks such as speech recognition, decision-making, and problem-solving, and is used in applications like virtual assistants, autonomous vehicles, and data analysis.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({'query': 'What is the capital of India?'})['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7399ef",
   "metadata": {},
   "source": [
    "## Multi-user Conversation Chains with ChatMessageHistory\n",
    "\n",
    "The concept of `ChatHistory` refers to a class in LangChain which can be used to wrap an arbitrary chain. This `ChatHistory` will keep track of inputs and outputs of the underlying chain, and append them as messages to a message database. Future interactions will then load those messages and pass them into the chain as part of the input.\n",
    "\n",
    "The beauty of `ChatMessageHistory` is that we can store separate conversation histories per user or session which is often the need for real-world chatbots which will be accessed by many users at the same time.\n",
    "\n",
    "We use a `get_session_history` function which is expected to take in a `session_id` and return a Message History object. Everything is stored in memory. This `session_id` is used to distinguish between separate conversations, and should be passed in as part of the config when calling the new chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca425504",
   "metadata": {},
   "source": [
    "\n",
    "- `ChatMessageHistory`: This is a class in LangChain that stores a sequence of chat messages (such as HumanMessage, AIMessage, SystemMessage) for a conversation. It allows you to append new messages and retrieve the full message history, which is useful for maintaining conversational context.\n",
    "\n",
    "- `BaseChatMessageHistory`: This is an abstract base class that defines the interface for chat message history storage backends. It specifies methods like add_message, get_messages, and clear, which concrete implementations (like ChatMessageHistory, RedisChatMessageHistory, etc.) must provide.\n",
    "\n",
    "- `RunnableWithMessageHistory`: This is a wrapper for a Runnable (such as a chain or LLM) that automatically manages message history for each session or user. It uses a function (like get_session_history) to retrieve the appropriate message history object based on a session ID, and injects the history into the chain's input. This enables multi-user or multi-session conversational experiences.\n",
    "\n",
    "- `MessagesPlaceholder`: This is a special prompt template variable in LangChain that acts as a placeholder for a list of messages (e.g., the conversation history). When rendering a prompt, MessagesPlaceholder is replaced with the actual messages from history, allowing the LLM to see the full conversation context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b7ff82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# used to retrieve conversation history from memory\n",
    "# based on a specific user or session ID\n",
    "history_store = {}\n",
    "def get_session_history(session_id):\n",
    "    if session_id not in history_store:\n",
    "        history_store[session_id] = ChatMessageHistory()\n",
    "    return history_store[session_id]\n",
    "\n",
    "# prompt to load in history and current input from the user\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Act as a helpful AI Assistant\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{human_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create a basic LLM Chain\n",
    "llm_chain = (prompt_template\n",
    "                |\n",
    "             chatgpt)\n",
    "\n",
    "# create a conversation chain which can load memory based on specific user or session id\n",
    "conv_chain = RunnableWithMessageHistory(\n",
    "    llm_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"human_input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# create a utility function to take in current user input prompt and their session ID\n",
    "# streams result live back to the user from the LLM\n",
    "def chat_with_llm(prompt: str, session_id: str):\n",
    "    for chunk in conv_chain.stream({\"human_input\": prompt},\n",
    "                                   {'configurable': { 'session_id': session_id}}):\n",
    "        print(chunk.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5255f97",
   "metadata": {},
   "source": [
    "Test conversation chain for user 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fe06822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, Bob! Here are three key points about AI:\n",
      "\n",
      "1. **Definition and Purpose**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn. Its primary purpose is to perform tasks that typically require human intelligence, such as problem-solving, understanding natural language, and recognizing patterns.\n",
      "\n",
      "2. **Types of AI**: AI can be categorized into two main types: Narrow AI, which is designed for specific tasks (like virtual assistants or recommendation systems), and General AI, which aims to perform any intellectual task that a human can do. Currently, most AI applications are examples of Narrow AI.\n",
      "\n",
      "3. **Applications and Impact**: AI is used across various industries, including healthcare (for diagnostics), finance (for fraud detection), and transportation (in self-driving cars). Its impact is significant, as it enhances efficiency, drives innovation, and can lead to new solutions for complex problems, but it also raises ethical considerations regarding privacy and job displacement."
     ]
    }
   ],
   "source": [
    "user_id = 'bob123'\n",
    "prompt = \"Hi I am Bob, can you explain AI in 3 bullet points?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d73deaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here are three key points about deep learning:\n",
      "\n",
      "1. **Definition and Structure**: Deep learning is a subset of machine learning that uses neural networks with many layers (hence \"deep\") to model complex patterns in large datasets. These neural networks are inspired by the structure and function of the human brain, allowing them to learn from vast amounts of data.\n",
      "\n",
      "2. **Training Process**: Deep learning models are trained using large datasets and require significant computational power. They learn by adjusting the weights of connections in the network through a process called backpropagation, which minimizes the difference between the predicted output and the actual output.\n",
      "\n",
      "3. **Applications and Advancements**: Deep learning has led to breakthroughs in various fields, including image and speech recognition, natural language processing, and autonomous systems. Its ability to automatically extract features from raw data has made it a powerful tool for tasks like facial recognition, language translation, and medical image analysis."
     ]
    }
   ],
   "source": [
    "prompt = \"Now do the same for deep learning\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7277ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s a brief summary of what we’ve discussed so far in bullet points:\n",
      "\n",
      "- **Artificial Intelligence (AI)**:\n",
      "  - AI simulates human intelligence in machines to perform tasks like problem-solving and language understanding.\n",
      "  - It is categorized into Narrow AI (specific tasks) and General AI (human-like intelligence).\n",
      "  - AI is widely used in various industries, enhancing efficiency and innovation while raising ethical concerns.\n",
      "\n",
      "- **Deep Learning**:\n",
      "  - Deep learning is a subset of machine learning that uses multi-layered neural networks to model complex patterns.\n",
      "  - It involves training on large datasets using backpropagation to adjust network weights.\n",
      "  - Deep learning has enabled advancements in fields like image recognition, speech processing, and natural language understanding."
     ]
    }
   ],
   "source": [
    "prompt = \"Discuss briefly what have we discussed so far is bullet points?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5539ae0",
   "metadata": {},
   "source": [
    "Now test conversation chain for user 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "96520653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are two key points about LLMs (Large Language Models):\n",
      "\n",
      "- **Definition**: LLMs are advanced artificial intelligence models designed to understand and generate human-like text based on vast amounts of data. They utilize deep learning techniques, particularly transformer architectures, to process and predict language patterns.\n",
      "\n",
      "- **Applications**: LLMs are used in various applications, including chatbots, content generation, language translation, and summarization, enabling more natural interactions between humans and machines."
     ]
    }
   ],
   "source": [
    "user_id = 'james007'\n",
    "prompt = \"Hi can you explain what is an LLM in 2 bullet points?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cdd87b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got it! Here’s a refined explanation of LLMs in the context of AI:\n",
      "\n",
      "- **Definition**: In AI, LLMs (Large Language Models) are sophisticated neural network models trained on extensive datasets to understand, generate, and manipulate human language. They leverage deep learning techniques, particularly transformer architectures, to capture complex language patterns and semantics.\n",
      "\n",
      "- **Capabilities**: LLMs can perform a wide range of language-related tasks, such as answering questions, writing essays, translating languages, and engaging in conversations, making them valuable tools in natural language processing (NLP) applications."
     ]
    }
   ],
   "source": [
    "prompt = \"Actually I meant in the context of AI?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d91424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We discussed Large Language Models (LLMs) in the context of AI, highlighting two main points: \n",
      "\n",
      "1. **Definition**: LLMs are advanced neural network models trained on large datasets to understand and generate human language, utilizing deep learning techniques like transformers.\n",
      "  \n",
      "2. **Capabilities**: They can perform various language-related tasks, such as answering questions, writing content, translating languages, and engaging in conversations, making them essential in natural language processing applications."
     ]
    }
   ],
   "source": [
    "prompt = \"Summarize briefly what we have discussed so far?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd6407f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here’s a concise summary of our discussion in bullet points:\n",
      "\n",
      "- **Artificial Intelligence (AI)**:\n",
      "  - Simulates human intelligence in machines for tasks like problem-solving and language understanding.\n",
      "  - Divided into Narrow AI (specific tasks) and General AI (human-like intelligence).\n",
      "  - Used across industries, enhancing efficiency and innovation, while raising ethical concerns.\n",
      "\n",
      "- **Deep Learning**:\n",
      "  - A subset of machine learning using multi-layered neural networks to model complex patterns.\n",
      "  - Trained on large datasets through backpropagation to optimize performance.\n",
      "  - Drives advancements in image recognition, speech processing, and natural language understanding."
     ]
    }
   ],
   "source": [
    "user_id = 'bob123'\n",
    "prompt = \"Discuss briefly what have we discussed so far is bullet points?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9a5ffdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! However, I don't have access to previous conversations or discussions. If you could provide a brief summary or key points from our previous discussions, I can help you organize them into bullet points."
     ]
    }
   ],
   "source": [
    "user_id = 'Sourav'\n",
    "prompt = \"Discuss briefly what have we discussed so far is bullet points?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94077374",
   "metadata": {},
   "source": [
    "## Multi-user Window-based Conversation Chains with persistence - SQLChatMessageHistory\n",
    "\n",
    "The beauty of `SQLChatMessageHistory` is that we can store separate conversation histories per user or session which is often the need for real-world chatbots which will be accessed by many users at the same time. Instead of in-memory we can store it in a SQL database which can be used to store a lot of conversations.\n",
    "\n",
    "We use a `get_session_history` function which is expected to take in a `session_id` and return a Message History object. Everything is stored in a SQL database. This `session_id` is used to distinguish between separate conversations, and should be passed in as part of the config when calling the new chain\n",
    "\n",
    "We also use a `memory_buffer_window` function to only use the top-K last historical conversations before sending it to the LLM, basically our own implementation of `ConversationBufferWindowMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69845c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: memory.db: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# removes the memory database file - usually not needed\n",
    "# you can run this only when you want to remove all conversation histories\n",
    "!rm memory.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e45fa02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# used to retrieve conversation history from database\n",
    "# based on a specific user or session ID\n",
    "def get_session_history_db(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
    "\n",
    "# prompt to load in history and current input from the user\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Act as a helpful AI Assistant\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{human_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create a memory buffer window function to return the last K conversations\n",
    "def memory_buffer_window(messages, k=2):\n",
    "    return messages[-(k+1):]\n",
    "\n",
    "# create a basic LLM Chain which only sends the last K conversations per user\n",
    "llm_chain = (\n",
    "    RunnablePassthrough.assign(history=lambda x: memory_buffer_window(x[\"history\"]))\n",
    "      |\n",
    "    prompt_template\n",
    "      |\n",
    "    chatgpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dfd392ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a conversation chain which can load memory based on specific user or session id\n",
    "conv_chain = RunnableWithMessageHistory(\n",
    "    llm_chain,\n",
    "    get_session_history_db,\n",
    "    input_messages_key=\"human_input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# create a utility function to take in current user input prompt and their session ID\n",
    "# streams result live back to the user from the LLM\n",
    "def chat_with_llm(prompt: str, session_id: str):\n",
    "    for chunk in conv_chain.stream({\"human_input\": prompt},\n",
    "                                   {'configurable': { 'session_id': session_id}}):\n",
    "        print(chunk.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da662944",
   "metadata": {},
   "source": [
    "Test conversation chain for user 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1697e3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/.venv/lib/python3.11/site-packages/langchain_core/runnables/history.py:596: LangChainDeprecationWarning: `connection_string` was deprecated in LangChain 0.2.2 and will be removed in 1.0. Use connection instead.\n",
      "  message_history = self.get_session_history(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fastest animal in the world is the peregrine falcon. When in a dive, it can reach speeds of over 240 miles per hour (386 kilometers per hour). If you're considering speed in level flight, the Brazilian free-tailed bat holds the record, flying at speeds of around 99 miles per hour (160 kilometers per hour). For land animals, the cheetah is the fastest, capable of running speeds up to 60-70 miles per hour (97-113 kilometers per hour) in short bursts."
     ]
    }
   ],
   "source": [
    "user_id = 'jim001'\n",
    "prompt = \"Hi can you tell me which is the fastest animal?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "81bfc6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest animal is often considered to be the three-toed sloth. It moves at an average speed of about 0.24 kilometers per hour (0.15 miles per hour) when climbing trees. In water, they can swim slightly faster, but they are still quite slow compared to many other animals. Another contender for the title of slowest animal is the garden snail, which moves at a speed of about 0.03 miles per hour (0.048 kilometers per hour). Both of these animals have adapted to their slow pace as part of their survival strategies."
     ]
    }
   ],
   "source": [
    "prompt = \"what about the slowest animal?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39829056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest animal on Earth is the blue whale (*Balaenoptera musculus*). Blue whales can reach lengths of up to 100 feet (30 meters) or more and can weigh as much as 200 tons (approximately 181 metric tonnes). They are not only the largest animals alive today but also the largest animals known to have ever existed on our planet. Their immense size is supported by their aquatic environment, which allows them to float and move more easily than terrestrial animals of similar size."
     ]
    }
   ],
   "source": [
    "prompt = \"what about the largest animal?\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7f4efd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are the topics we've discussed so far:\n",
      "\n",
      "- The slowest animal (three-toed sloth and garden snail)\n",
      "- The largest animal (blue whale)"
     ]
    }
   ],
   "source": [
    "prompt = \"what topics have we discussed, show briefly as bullet points\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0451ee",
   "metadata": {},
   "source": [
    "Now test conversation chain for user 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "595e1c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are three simple points to explain AI to a child:\n",
      "\n",
      "1. **Smart Helpers**: AI is like a smart robot or computer that can help us with tasks, like answering questions or playing games, just like a friend would!\n",
      "\n",
      "2. **Learning from Experience**: AI learns from lots of information, kind of like how you learn from your school lessons and practice. The more it learns, the better it gets at helping us.\n",
      "\n",
      "3. **Talking and Understanding**: AI can understand what we say or write and can even talk back to us, making it feel like we’re having a conversation with a really clever buddy!"
     ]
    }
   ],
   "source": [
    "user_id = 'john005'\n",
    "prompt = \"Explain AI in 3 bullets to a child\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0a9202df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here are three simple points to explain Generative AI to a child:\n",
      "\n",
      "1. **Creative Robot**: Generative AI is like a creative robot that can make new things, like pictures, stories, or music, all by itself, just like an artist or a writer!\n",
      "\n",
      "2. **Using Ideas**: It learns from lots of examples, like reading many books or looking at many paintings, so it can come up with its own cool ideas based on what it has learned.\n",
      "\n",
      "3. **Imagination in Action**: When you ask Generative AI to create something, it uses its imagination to come up with fun and interesting stuff, almost like magic!"
     ]
    }
   ],
   "source": [
    "prompt = \"Now do the same for Generative AI\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "736a8363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are three simple points to explain machine learning to a child:\n",
      "\n",
      "1. **Learning Like You**: Machine learning is when computers learn from examples, just like you learn new things in school by practicing and seeing how things work.\n",
      "\n",
      "2. **Getting Better Over Time**: The more examples the computer sees, the better it gets at understanding and making decisions, like how you get better at a game the more you play it.\n",
      "\n",
      "3. **Solving Problems**: With machine learning, computers can help solve problems or make predictions, like guessing what movie you might like based on the ones you’ve watched before!"
     ]
    }
   ],
   "source": [
    "prompt = \"Now do the same for machine learning\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "004217f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are the topics we've discussed so far:\n",
      "\n",
      "- **Generative AI**\n",
      "  - Creative robot that makes new things (pictures, stories, music)\n",
      "  - Learns from examples to come up with new ideas\n",
      "  - Uses imagination to create fun and interesting content\n",
      "\n",
      "- **Machine Learning**\n",
      "  - Computers learn from examples like humans do\n",
      "  - Improves over time with more practice\n",
      "  - Helps solve problems and make predictions based on data\n",
      "\n",
      "If you have more questions or need further information on these topics, feel free to ask!"
     ]
    }
   ],
   "source": [
    "prompt = \"what topics have we discussed, show briefly as bullet points\"\n",
    "chat_with_llm(prompt, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b2e870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
