{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "142ae5ad-14b9-457d-a2d5-7013ebe7fe41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1kiH8lf1y4sD"
   },
   "source": [
    "# Build a Tool-Calling Agentic AI Research Assistant with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e1db11f-7aae-4d88-aa86-d6ba5bf1ee01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NYBpZTjLnEXb"
   },
   "source": [
    "This demo will cover building AI Agents with the legacy LangChain `AgentExecutor`. These are fine for getting started, but for working with more advanced agents and having more finer control, LangChain recommends to use LangGraph, which we cover in other courses.\n",
    "\n",
    "Agents are systems that use an LLM as a reasoning engine to determine which actions to take and what the inputs to those actions should be. The results of those actions can then be fed back into the agent and it determines whether more actions are needed, or whether it is okay to stop.\n",
    "\n",
    "![](https://i.imgur.com/1uVnBAm.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3af836f-e1ed-4207-9456-979ff4728f0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L1KvMtf54l0d"
   },
   "source": [
    "## Install OpenAI, and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faead4de-20d0-43ba-8276-c880057accca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2evPp14fy258",
    "outputId": "93aa791d-4f4c-4167-e6d1-7491fbeb93e5"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.14\n",
    "!pip install langchain-openai==0.3.0\n",
    "!pip install langchain-community==0.3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b43f2d7-f21c-46c0-9dd4-a9f40212ec9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AakmY6B_zYte",
    "outputId": "f206e910-8ac4-4423-c1af-c000a92f3429"
   },
   "outputs": [],
   "source": [
    "!pip install markitdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d547362a-fe2f-4d18-bc76-d9cb638e9431",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Any\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66f86022-7082-4b5b-8940-2fe27071ae79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H9c37cLnSrbg"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c9ccdfa-8841-44a4-83ca-a41912342878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv3JzCEx_PAd",
    "outputId": "3e7a5d36-2bd9-49d8-88bc-5753c36d235c"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f9428b4-9817-4f55-8e41-8912255d7923",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ucWRRI3QztL2"
   },
   "source": [
    "## Enter Tavily Search API Key\n",
    "\n",
    "Get a free API key from [here](https://tavily.com/#api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "914bdda5-c370-496d-b932-fe871b0ca43b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mK-1WLzOrJdb",
    "outputId": "143b9b1d-9ae9-4ab1-e830-27bab3836ee2"
   },
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3630acbb-1362-4ab9-a7be-27f2fa127fc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Ce5arICZEEov"
   },
   "source": [
    "## Enter WeatherAPI API Key\n",
    "\n",
    "Get a free API key from [here](https://www.weatherapi.com/signup.aspx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68fe28f8-d013-4215-9339-d1c085267c0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpAMz1XgEEov",
    "outputId": "da1143c0-4243-4799-d76e-79e41dd8ea5f"
   },
   "outputs": [],
   "source": [
    "WEATHER_API_KEY = getpass('Enter WeatherAPI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a07d12d-320d-417d-b072-657b57c85884",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1T0s0um5Svfa"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbcee778-7bbf-41e4-be23-6d396ef05764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x1YSuHNF_lbh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b52cb2f-e7dc-40b9-80f9-c6fd5c963f90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "howf-v0ARWbv"
   },
   "source": [
    "## Create Tools\n",
    "\n",
    "Here we create two custom tools which are wrappers on top of the [Tavily API](https://tavily.com/#api) and [WeatherAPI](https://www.weatherapi.com/)\n",
    "\n",
    "- Web Search tool with information extraction\n",
    "- Weather tool\n",
    "\n",
    "![](https://i.imgur.com/TyPAYXE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d4f5ad0-e142-4d43-8cc0-b3cd219e0bc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ue8xgu9WpuPi",
    "outputId": "5f312771-4696-4ee6-9d37-6a890b73086d"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from markitdown import MarkItDown\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "import requests\n",
    "import json\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5,\n",
    "                                  search_depth='advanced',\n",
    "                                  include_answer=False,\n",
    "                                  include_raw_content=True)\n",
    "# certain websites won't let you crawl them unless you specify a user-agent\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\"\n",
    "})\n",
    "md = MarkItDown(requests_session=session)\n",
    "\n",
    "@tool\n",
    "def search_web_extract_info(query: str) -> list:\n",
    "    \"\"\"Search the web for a query and extracts useful information from the search links.\"\"\"\n",
    "    print('Calling web search tool')\n",
    "    results = tavily_tool.invoke(query)\n",
    "    docs = []\n",
    "\n",
    "    def extract_content(url):\n",
    "        \"\"\"Helper function to extract content from a URL.\"\"\"\n",
    "        extracted_info = md.convert(url)\n",
    "        text_title = extracted_info.title.strip()\n",
    "        text_content = extracted_info.text_content.strip()\n",
    "        return text_title + '\\n' + text_content\n",
    "    # parallelize execution of different urls\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for result in tqdm(results):\n",
    "            try:\n",
    "                future = executor.submit(extract_content, result['url'])\n",
    "                # Wait for up to 15 seconds for the task to complete\n",
    "                content = future.result(timeout=15)\n",
    "                docs.append(content)\n",
    "            except TimeoutError:\n",
    "                print(f\"Extraction timed out for url: {result['url']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting from url: {result['url']} - {e}\")\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(query: str) -> list:\n",
    "    \"\"\"Search weatherapi to get the current weather of the queried location.\"\"\"\n",
    "    print('Calling weather tool')\n",
    "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
    "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
    "\n",
    "    response = requests.get(complete_url)\n",
    "    data = response.json()\n",
    "    if data.get(\"location\"):\n",
    "        return data\n",
    "    else:\n",
    "        return \"Weather Data Not Found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e015ff2-2f6e-44d0-99fa-30e7a56bb708",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "D2N5192vikJR"
   },
   "source": [
    "## Test Tool Calling with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f940a870-4a03-4a16-aa5a-5c6b4b8138e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_B2EFrwTpuXB"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "tools = [search_web_extract_info, get_weather]\n",
    "\n",
    "chatgpt_with_tools = chatgpt.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d97ea74-89df-4e0d-aca6-318329c95c35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0rVVBGDpuYw",
    "outputId": "95231440-d9de-4c58-a536-e05d67e0f279"
   },
   "outputs": [],
   "source": [
    "prompt = \"Get details of Microsoft's earnings call Q4 2024\"\n",
    "response = chatgpt_with_tools.invoke(prompt)\n",
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b38cca12-e017-400f-accf-eae84a88536b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qfchhGEpuaj",
    "outputId": "d4674863-91c3-44ea-8a7e-67121e208f3b"
   },
   "outputs": [],
   "source": [
    "prompt = \"how is the weather in Bangalore today\"\n",
    "response = chatgpt_with_tools.invoke(prompt)\n",
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4363a1e5-c5fe-44aa-960e-efeda0d802dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "c7kvwG3SmREW"
   },
   "source": [
    "## Build and Test AI Agent\n",
    "\n",
    "Now that we have defined the tools and the LLM, we can create the agent. We will be using a tool calling agent to bind the tools to the agent with a prompt. We will also add in the capability to store historical conversations as memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "518c8e14-094a-4710-bbf2-f76e62bbe16b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grNq1I6_5dxC",
    "outputId": "7353b0b3-cb8d-4324-efc1-601180a6bc7d"
   },
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# SYS_PROMPT = \"\"\"Act as a helpful assistant.\n",
    "#                 You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "#                 At the end of the loop, you output an Answer.\n",
    "#                 Use Thought to describe your thoughts about the question you have been asked.\n",
    "#                 Use Action to run one of the actions available to you - then return PAUSE.\n",
    "#                 Observation will be the result of running those actions.\n",
    "#                 Repeat till you get to the answer for the given user query.\n",
    "\n",
    "#                 Use the following workflow format:\n",
    "#                   Question: the input task you must solve\n",
    "#                   Thought: you should always think about what to do\n",
    "#                   Action: the action to take which can be any of the following:\n",
    "#                             - break it into smaller steps if needed\n",
    "#                             - see if you can answer the given task with your trained knowledge\n",
    "#                             - call the most relevant tools at your disposal mentioned below in case you need more information\n",
    "#                   Action Input: the input to the action\n",
    "#                   Observation: the result of the action\n",
    "#                   ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "#                   Thought: I now know the final answer\n",
    "#                   Final Answer: the final answer to the original input question\n",
    "\n",
    "#                 Tools at your disposal to perform tasks as needed:\n",
    "#                   - get_weather: whenever user asks get the weather of a place.\n",
    "#                   - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\n",
    "#              \"\"\"\n",
    "\n",
    "# prompt_template = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", SYS_PROMPT),\n",
    "#         MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
    "#         (\"human\", \"{query}\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# prompt_template.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "204f8ac8-fe05-423a-b37a-4fd1c610cc7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "u4NMA82HpueH"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "tools = [search_web_extract_info, get_weather]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0dab138-7f9e-4e75-819f-e66ed346e171",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Using Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1718d902-6f1e-402f-ad12-8e926ebc2189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create an LLM chain for deciding which tool to use\n",
    "tool_selection_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a tool selection assistant. \n",
    "    Based on the user's question, determine which tool would be most appropriate.\n",
    "    Respond with only the tool name: \"search_web_extract_info\", \"get_weather\" .\n",
    "    If none of these tools can help, respond with \"None\".\"\"\"),\n",
    "    (\"human\", \"{query}\")\n",
    "])\n",
    "\n",
    "tool_selection_chain = LLMChain(\n",
    "    llm=chatgpt,\n",
    "    prompt=tool_selection_prompt,\n",
    "    output_key=\"selected_tool\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bfa332e-2c41-4f05-9f3c-eee7c29c5cf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create an LLM chain for formatting tool inputs\n",
    "tool_input_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Extract the specific input needed for the tool from the user's query.\n",
    "    For WeatherService: Extract the location name.\n",
    "    for get_weather extract the keywords and search the info in web\n",
    "    Provide only the extracted information, nothing else.\"\"\"),\n",
    "    (\"human\", \"Tool to use: {selected_tool}\\nUser query: {query}\")\n",
    "])\n",
    "\n",
    "tool_input_chain = LLMChain(\n",
    "    llm=chatgpt,\n",
    "    prompt=tool_input_prompt,\n",
    "    output_key=\"tool_input\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8076128-3401-4386-a2ee-c0576645b41a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bd6319d-2757-4d44-b719-d573dff7b786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create an LLM chain for formatting the final response\n",
    "response_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Create a helpful response to the user's query using the tool's output.\"),\n",
    "    (\"human\", \"User query: {query}\\nTool used: {selected_tool}\\nTool output: {tool_output}\")\n",
    "])\n",
    "\n",
    "response_chain = LLMChain(\n",
    "    llm=chatgpt,\n",
    "    prompt=response_prompt,\n",
    "    output_key=\"response\",\n",
    "    output_parser=StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b91ddb9-7722-46a3-af52-46fd9c0efcc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to run the full chain\n",
    "def process_query(query: str) -> str:\n",
    "    # First, select which tool to use\n",
    "    tool_selection_result = tool_selection_chain.invoke({\"query\": query})\n",
    "    selected_tool = tool_selection_result[\"selected_tool\"].strip()\n",
    "    print(f\"Selected tool: {selected_tool}\")\n",
    "    \n",
    "    if selected_tool == \"None\":\n",
    "        return \"I don't have a tool that can help with this query.\"\n",
    "    \n",
    "    # Next, format the input for the selected tool\n",
    "    tool_input_result = tool_input_chain.invoke({\n",
    "        \"selected_tool\": selected_tool,\n",
    "        \"query\": query\n",
    "    })\n",
    "    tool_input = tool_input_result[\"tool_input\"].strip()\n",
    "    # print(f\"Tool input: {tool_input}\")\n",
    "    \n",
    "    # Find and run the appropriate tool\n",
    "    tool_output = \"Tool not found\"\n",
    "    for tool in tools:\n",
    "        if tool.name == selected_tool:\n",
    "            tool_output = tool.func(tool_input)\n",
    "            break\n",
    "    # print(f\"Tool output: {tool_output}\")\n",
    "    \n",
    "    # Format the final response\n",
    "    response_result = response_chain.invoke({\n",
    "        \"query\": query,\n",
    "        \"selected_tool\": selected_tool,\n",
    "        \"tool_output\": tool_output\n",
    "    })\n",
    "    return response_result[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa9ff2e5-ef5b-4c77-baac-da7353221943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "        \"What is 234 * 78.5?\",\n",
    "        \"What's the weather like in San Francisco?\",\n",
    "        \"Tell me about LangChain.\",\n",
    "    ]\n",
    "    \n",
    "for example in examples:\n",
    "    print(f\"\\n\\nQUERY: {example}\")\n",
    "    print(\"-\" * 50)\n",
    "    response = process_query(example)\n",
    "    print(\"FINAL RESPONSE:\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "863ecdd7-cb9a-4538-a7d7-5a1307d94a86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1. Tool_calling_LLM_chain",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
