{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22779d91-6043-4385-b108-00b2a3cf3948",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7yVV6txOmNMn"
   },
   "source": [
    "# Multimodal Prompt Engineering with Google Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc884ad2-0fb4-4a05-a1a8-ca7c3719eb51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "t1DnOs6rkbOy"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Gemini 1.5 Flash is a new language model from the Gemini family. This model introduces a breakthrough long context window of up to 1 million tokens that can help seamlessly analyze large amounts of information and long-context understanding. It can process text, images, audio, video, and code all together for deeper insights. Learn more about [Gemini 1.5](https://deepmind.google/technologies/gemini/flash/).\n",
    "\n",
    "Here we will:\n",
    "\n",
    "- analyze images for insights.\n",
    "- analyze audio for insights.\n",
    "- understand videos (including their audio components).\n",
    "- extract information from PDF documents.\n",
    "- process images, video, audio, and text simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c9be1c1-8a78-4afa-adcd-56032f2d4170",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6353315e-71e6-44a0-bf76-d60467dd2af7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install Google Gen AI library for Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97f462dd-7e0b-4543-905f-e2b1be7bc9a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3791,
     "status": "ok",
     "timestamp": 1734092043476,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "tFy3H3aPgx12",
    "outputId": "f5230878-428c-419b-926e-078d40a696b0"
   },
   "outputs": [],
   "source": [
    "!pip install google-generativeai==0.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae02e049-b1cf-4eef-bcfc-5e4956029599",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PtBa7rlWJWH3"
   },
   "source": [
    "## Enter API Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "872fd2c5-cf8d-4d07-9332-b1724f142442",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9300,
     "status": "ok",
     "timestamp": 1734092052772,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "Av1UpSgXZUsI",
    "outputId": "621c571a-b9de-4964-b40e-39c976f5da17"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "GOOGLE_API_KEY = getpass('Enter Gemini API Key:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7704b0d-9c21-44f8-a237-4850a40614f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jXHfaVS66_01"
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d00ec08-a3c6-466e-852a-62515dca0cf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "executionInfo": {
     "elapsed": 5908,
     "status": "ok",
     "timestamp": 1734092060557,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "lslYAvw37JGQ",
    "outputId": "a83fc6cc-e97f-4b21-d969-ebee74c93eab"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d972d5a-d0b3-44ed-b3cf-cd013e523553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "BY1nfXrqRxVX"
   },
   "source": [
    "### Load the Gemini 1.5 Flash model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0727c98-4261-44fc-966b-d0ebbba05b74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1734092063620,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "U7ExWmuLBdIA"
   },
   "outputs": [],
   "source": [
    "generation_config = genai.types.GenerationConfig(\n",
    "    temperature=0\n",
    ")\n",
    "gemini = genai.GenerativeModel(model_name='gemini-1.5-flash-latest',\n",
    "                               generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "177ff2e0-b63f-4b7b-91cc-a0f7fd47f469",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "l9OKM0-4SQf8"
   },
   "source": [
    "### LLM basic usage\n",
    "\n",
    "Below is a simple example that demonstrates how to prompt the Gemini 1.5 Flash model using the API. Learn more about the [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini#gemini-pro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac368214-7610-4a10-9f62-777dbd165ce6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "executionInfo": {
     "elapsed": 2678,
     "status": "ok",
     "timestamp": 1734092068068,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "FhFxrtfdSwOP",
    "outputId": "7f76dc4a-c9ec-4451-9076-9f8a2f1ccd8c"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "prompt = \"\"\"\n",
    "  Explain what is Generative AI in 3 bullet points\n",
    "\"\"\"\n",
    "\n",
    "response = gemini.generate_content(contents=prompt)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69995257-7758-4970-8a7c-e5dd20eaba09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "CqbsC7LHA_qB"
   },
   "source": [
    "## Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3901637-e3e9-4a69-bc18-e8896e1a9a4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iESsxr9bBBhg",
    "outputId": "9ced29b7-8390-4d34-c82c-dd69fba27436"
   },
   "outputs": [],
   "source": [
    "# download images using curl\n",
    "!curl https://i.imgur.com/6b9jwkk.png -o image1.png\n",
    "!curl https://i.imgur.com/9CWuU2q.png -o image2.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6ea9d1a-e448-41b4-bf5b-bdf20214a22c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "g7LHLGWEBOgt",
    "outputId": "bd216bd8-3d82-46bd-f18d-e266de7295e8"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as ImageDisp, display\n",
    "\n",
    "display(ImageDisp('image1.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c28b9f3-3256-4cb8-b9eb-5d79e7b65ca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YTO4T2eMBYRL",
    "outputId": "0f4cc0c9-a533-4a02-ac37-af34a0e63ccb"
   },
   "outputs": [],
   "source": [
    "display(ImageDisp('image2.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f451072-ba93-4ffe-9207-067ba0905412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "b98gVHBoCY6o"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image1 = Image.open('image1.png')\n",
    "image2 = Image.open('image2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce2fda5b-59e7-4ecd-aa18-cb9359440b2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "WJOhxB0RBa4A",
    "outputId": "c30bb316-4681-4fcd-e07e-6a8f427c4dc5"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Given the following images which can contain graphs, tables and text,\n",
    "  analyze all of them to answer the following question:\n",
    "\n",
    "  Tell me about the top 5 years with largest Wildfires\n",
    "\"\"\"\n",
    "\n",
    "contents = [image1, image2,  prompt]\n",
    "response = gemini.generate_content(contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6d43b3b-1625-4684-82d9-10fc949ed48d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "p1im43NQCkx1",
    "outputId": "e6253a55-d585-402f-cbfd-65323ddb97ea"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Given the following images which can contain graphs, tables and text,\n",
    "  analyze all of them to answer the following question:\n",
    "\n",
    "  Tell me about trend of wildfires in terms of acreage burned by region and ownership\n",
    "\"\"\"\n",
    "\n",
    "contents = [image1, image2,  prompt]\n",
    "response = gemini.generate_content(contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f38a4056-91ec-4a7d-a31d-c1a0ca1a096b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9HTEdrOm_Ie0"
   },
   "source": [
    "## PDF Doc Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65e5cca4-2c3d-4cd5-98c3-a06cf3d716bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_wpUGR8_NCO",
    "outputId": "7949609c-d7dc-4630-aa5e-9194afd5052c"
   },
   "outputs": [],
   "source": [
    "!wget https://sgp.fas.org/crs/misc/IF10244.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f053de6-4f05-4239-9b1d-c91eb5620146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "id": "KOXNdYMX_Opk",
    "outputId": "2c87b8f7-9918-4f6a-d7ed-51300c9cf491"
   },
   "outputs": [],
   "source": [
    "pdf_ref = genai.upload_file(path='./IF10244.pdf')\n",
    "pdf_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08c61b50-b6f8-46ba-bf7a-ac48709c0ff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "i7tED33A_WpZ",
    "outputId": "de0333c1-58c9-4cc6-de40-3efbe739c466"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Given the PDF file, use it to answer the following question:\n",
    "\n",
    "  Tell me about the top 5 years with largest Wildfires\n",
    "\"\"\"\n",
    "\n",
    "contents = [pdf_ref, prompt]\n",
    "\n",
    "response = gemini.generate_content(contents)\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb705ede-0570-4f33-986e-9fbfeb849a44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "acRxKRA-sr0j"
   },
   "source": [
    "## Audio understanding\n",
    "\n",
    "Gemini 1.5 Flash can directly process audio for long-context understanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d39f5576-a379-4257-a9d1-eeff8f3df9ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVQjZP5TJB1A",
    "outputId": "5d7dee6c-1da0-4fe7-ca35-5f1ad9360420"
   },
   "outputs": [],
   "source": [
    "!wget \"https://storage.googleapis.com/cloud-samples-data/generative-ai/audio/pixel.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "841490bc-2cd5-49e1-af69-969c1486451a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "bLo6yj_pJMHl",
    "outputId": "3e91ed67-752c-40ac-90af-41586036b78e"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.Audio('./pixel.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72c9f152-b35d-4776-b4c1-54ba54243e7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ndrrPztwImLO"
   },
   "outputs": [],
   "source": [
    "audio_file = genai.upload_file(path='./pixel.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb153c3d-c7d0-4c81-9c35-bf6fd504c7c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wC6bkr8uJani",
    "outputId": "7f2f54b6-180b-4e9e-8654-c56669df676e"
   },
   "outputs": [],
   "source": [
    "audio_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19b9a507-0b23-4979-944c-220b82163f9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9sXM19QQ4vj1"
   },
   "source": [
    "#### Example 1: Title Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "442acbc4-1a83-4075-bf08-34bf461eaa09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "OPQ1fBk44E6L",
    "outputId": "0e9931c3-e596-49cc-8a8c-61e886d33749"
   },
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"\"\"\n",
    "  Please provide a summary for the audio.\n",
    "  Provide chapter titles with timestamps, be concise and short, no need to provide chapter summaries.\n",
    "  Do not make up any information that is not part of the audio and do not be verbose.\n",
    "\"\"\"\n",
    "\n",
    "contents = [audio_file, prompt]\n",
    "response = gemini.generate_content(contents=contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "110547d3-6558-41b0-962a-4cfb16b66677",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dzA8vKgQATGL"
   },
   "source": [
    "#### Example 2: Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90c19839-cf3b-415e-ad9c-1117158061ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "qT2T602zr7bB",
    "outputId": "bd24ec0f-fc11-41ec-f9e7-c830913f3eaa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Can you transcribe this interview, in the format of [timecode] - [speaker] : caption.\n",
    "    Use speaker A, speaker B, etc. to identify the speakers. Map each speaker to their real name at the start of the output\n",
    "    Each speaker should have a single caption based on their starting timestamp\n",
    "    Do not break up the transcript into multiple timestamps for the same speaker\n",
    "    Show the output only for the part of the conversation about the pixel watch and follow the format mentioned above for the output\n",
    "\"\"\"\n",
    "\n",
    "contents = [audio_file, prompt]\n",
    "response = gemini.generate_content(contents=contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f741dea2-36b6-40d6-9bd3-8dd9542a15d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RX3HgFTf6CLq"
   },
   "source": [
    "#### Example 3: Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f877d3b-7f06-4ecc-bbc3-1af647329f23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "id": "wg0Mj8pj5i24",
    "outputId": "a0d4ed88-8e2d-43ca-fae4-d69933fe8332"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Given the audio file, generate a comprehensive summary of:\n",
    "     - Key Speakers\n",
    "     - Key products and features discussed\n",
    "     - Any other noteworthy discussions\n",
    "\"\"\"\n",
    "\n",
    "contents = [audio_file, prompt]\n",
    "response = gemini.generate_content(contents=contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b964dd4b-0896-4791-8a2c-ce1e7ad82a3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_U36v4TmswAG"
   },
   "source": [
    "## Video with audio understanding\n",
    "\n",
    "Try out Gemini 1.5 Flash’s native multimodal and long context capabilities on video interleaving with audio inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4f09a4e-72ef-47f1-9bd2-3007b3aa4631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dhz1guhL-Io",
    "outputId": "81eda92b-d5b7-40d9-bed8-a4f70127fc34"
   },
   "outputs": [],
   "source": [
    "!wget \"https://storage.googleapis.com/cloud-samples-data/generative-ai/video/pixel8.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88c28436-2ff4-44c8-8930-ac695a0bc3ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "EDswcPI0tSRk",
    "outputId": "c0aed7eb-7acb-4e15-f2ac-df174756abe1"
   },
   "outputs": [],
   "source": [
    "IPython.display.Video('pixel8.mp4', embed=True, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30171be7-704e-4e69-89f8-f38e9cd22dcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IpBBFMWpMfT9"
   },
   "outputs": [],
   "source": [
    "video_file = genai.upload_file(path='./pixel8.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7db1bd04-505a-4048-9e09-61a8b7374ee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "R9isZfjzCYxw",
    "outputId": "ab4b5277-8bb0-4731-9e11-92b7069b1f52"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Provide a comprehensive summary of the video.\n",
    "  The summary should also contain anything important which people discuss in the video.\n",
    "\"\"\"\n",
    "\n",
    "contents = [video_file, prompt]\n",
    "\n",
    "response = gemini.generate_content(contents=contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f60ec6a2-25ee-4183-88c3-5db5565857fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pC1vS-5Jinbi",
    "outputId": "9636b086-e0d8-4df8-c63b-9d82d37ac206"
   },
   "outputs": [],
   "source": [
    "!gdown -O 'awsq_video.mp4' '1shnBXeuXYcbRr9IhxofHkT3rlSaqPG1e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd79e67f-2867-48ea-a74b-bdb094b25971",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "lkF3JCnur7bC",
    "outputId": "3c3bff17-19e9-48ca-f51f-1f3a949ae2a8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "IPython.display.Video('awsq_video.mp4', embed=True, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0914b540-7644-4be8-a467-301fd77e7c9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "mZVzpiAqr7bC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid = genai.upload_file(path='./awsq_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46a7c730-e3cb-4ac8-a049-1981f28f8213",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "hHifGyler7bC",
    "outputId": "521b495d-d501-433f-9ecb-9418eed9a0fa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Provide a description of the video.\n",
    "  The description should cover the key steps covered in the video in bullet points\n",
    "\"\"\"\n",
    "\n",
    "contents = [vid, prompt]\n",
    "response = gemini.generate_content(contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f62b4978-c324-4fd9-add5-007b6164b85a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "JcBZZ-bJe2yS"
   },
   "source": [
    "Gemini 1.5 Pro model is able to process the video with audio, retrieve and extract textual and audio information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9625d48c-d3e9-49db-9c25-689de38bb193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "s3vu8ogWs7iZ"
   },
   "source": [
    "## All modalities (images, video, audio, text) at once\n",
    "\n",
    "Gemini 1.5 Pro is natively multimodal and supports interleaving of data from different modalities, it can support a mix of audio, visual, text, and\n",
    "code inputs in the same input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ade30128-fea7-4ccd-841d-9a37db3643d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0htbobb4SDuD",
    "outputId": "34592a12-f751-4a1a-8183-7c7a49b5ffc0"
   },
   "outputs": [],
   "source": [
    "!wget 'https://storage.googleapis.com/cloud-samples-data/generative-ai/video/behind_the_scenes_pixel.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "805055bc-c5e8-451a-83e9-083e6429e502",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjXmyyJ8UaDi",
    "outputId": "48ee3c33-019b-4972-b08c-c18c0cb83615"
   },
   "outputs": [],
   "source": [
    "!wget 'https://storage.googleapis.com/cloud-samples-data/generative-ai/image/a-man-and-a-dog.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "daaa5007-a50a-4e5b-9978-41445422882f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "qS7KSwvbjhFh",
    "outputId": "80a9a50c-c371-4583-d4d1-3884545396ce"
   },
   "outputs": [],
   "source": [
    "IPython.display.Image('a-man-and-a-dog.png', width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f02012a-8b2a-4cc0-af93-4ec912227a1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cASz2BFlUj96"
   },
   "outputs": [],
   "source": [
    "video_file = genai.upload_file(path='./behind_the_scenes_pixel.mp4')\n",
    "image_file = genai.upload_file(path='./a-man-and-a-dog.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0510d69c-de54-4689-8e99-f8a4c406b234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "pRdzwDi9iLGn",
    "outputId": "51e6d9e4-9823-4a57-8a5c-50f3b5c568a8"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Look through each frame in the video carefully and answer the questions.\n",
    "  Only base your answers strictly on what information is available in the video attached.\n",
    "  Do not make up any information that is not part of the video and summarize your answer\n",
    "  in three bullet points max\n",
    "\n",
    "  Questions:\n",
    "  - When is the moment in the image happening in the video? Provide a timestamp.\n",
    "  - What is the context of the moment and what does the narrator say about it?\n",
    "\"\"\"\n",
    "\n",
    "contents = [video_file, image_file, prompt]\n",
    "response = gemini.generate_content(contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e824522e-133e-4a21-b620-0a8cf286cdc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "b3iovYxOwOT7"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, you've learned how to use the Gemini 1.5 Flash to:\n",
    "\n",
    "- analyze images for insights.\n",
    "- analyze PDF docs for insights.\n",
    "- analyze audio for insights.\n",
    "- understand videos (including their audio components).\n",
    "- process images, video, audio, and text simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddbdbfb5-a7c4-463d-bf25-bd24c14a5d22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "JcduiYrmVaHb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "M7_Multimodal_Prompt_Engineering_with_Google_Gemini",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
