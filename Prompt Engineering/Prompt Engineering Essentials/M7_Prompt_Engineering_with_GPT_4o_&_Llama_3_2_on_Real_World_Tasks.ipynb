{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6a47a2e-a057-41cc-92dd-60db4fe43d3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "fb6rdwlCsCGt"
   },
   "source": [
    "# Prompt Engineering with GPT-4o & Llama 3.2 90B on Real-World Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f285c97a-c262-4069-8766-d277de1f3976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XTzBUFWQ-OWj"
   },
   "source": [
    "In this notebook you will use the OpenAI's GPT-4o and Meta's Llama 3.2 90B for the following real-world tasks\n",
    "\n",
    "- Task - 1: Review Analysis and Response\n",
    "- Task - 2: Paper Analysis and Summarization\n",
    "- Task - 3: Marketing Adverts for Smartphone\n",
    "- Task - 4: IT Support Resolution\n",
    "- Task - 5: Synthetic Data Generation\n",
    "\n",
    "\n",
    "___Created By: Dipanjan (DJ)___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dea3869-2813-4a90-a074-3d97588c4ef6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L1KvMtf54l0d"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db388af9-7385-4ce2-aba6-8cae20131710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24274,
     "status": "ok",
     "timestamp": 1734092311973,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "2evPp14fy258",
    "outputId": "4e4785e7-fc68-4c87-9f95-aa6486237bb8"
   },
   "outputs": [],
   "source": [
    "!pip install openai==1.55.3\n",
    "!pip install groq==0.13.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14ff695a-667e-497d-88d2-6eac9d3cc16b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "CiwGjVWK4q6F"
   },
   "source": [
    "## Load OpenAI API Credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca1b380c-0b41-45fd-97bb-f5e9b724e1c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4116,
     "status": "ok",
     "timestamp": 1734092323458,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "ryheOZuXxa41",
    "outputId": "178c38a7-b1d5-4189-ebca-fcab26b073d9"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "openai_key = getpass(\"Enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49052ca2-1fc7-4f58-a9e7-589a85d0f3ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 1389,
     "status": "ok",
     "timestamp": 1734092326089,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "kDe44J0N0NcC"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from IPython.display import HTML\n",
    "\n",
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbfc379d-c9b1-4048-af6b-d714836b8877",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "qvzfEaGRr6iJ"
   },
   "source": [
    "## Load Groq API Credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3a1ee27-45f5-4a02-b2ac-84e475e49a90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6533,
     "status": "ok",
     "timestamp": 1734092334220,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "-Tb0TO3Nr6iK",
    "outputId": "d914f8a6-bbc1-4a4a-dc13-80cff98b9970"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "groq_key = getpass(\"Enter your Groq API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b45730f-f50a-4422-8b9a-3b4db227b205",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1734092336202,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "nhJdZLOLvBzs"
   },
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "groq_client = Groq(api_key=groq_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c6d0dad-0eba-4064-991e-7387d61dab5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "VDWhgxCy5bA6"
   },
   "source": [
    "## Create OpenAI and Groq Chat Completion Access Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d248dd6d-d493-47bb-9707-f032b6fc2077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1734092349111,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "kA9gVCwK0WKd"
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    if model == \"gpt-4o\":\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0, # degree of randomness of the model's output\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    elif model == \"llama-3.2-90b-vision-preview\":\n",
    "        response = groq_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0, # degree of randomness of the model's output\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    else:\n",
    "        return \"LLM not configured! Please configure logic for specific model in get_completion()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e3c248b-8648-4f63-a298-9097ec8ff9f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1TFZjzuGjCOw"
   },
   "source": [
    "## Let's try out the APIs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fde40624-0159-43ce-a18d-052539a947c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1734092359180,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "0Nbv6wrc5wN3"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0aa6cf5-cff1-41fb-bce0-caedeb331179",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "executionInfo": {
     "elapsed": 1804,
     "status": "ok",
     "timestamp": 1734092361340,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "KK-kjmMoi5rO",
    "outputId": "62c357d0-4d4f-48c8-b677-b6c3a77fd395"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt='Explain Generative AI in 2 bullet points',\n",
    "                          model='gpt-4o')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "116c8441-84e1-49ad-96cf-2e1c8b8b8406",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "executionInfo": {
     "elapsed": 1087,
     "status": "ok",
     "timestamp": 1734092367068,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "VmnwGrskn_oz",
    "outputId": "1124fece-4f8c-46e1-9846-9793f23c0dd0"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt='Explain Generative AI in 2 bullet points',\n",
    "                          model='llama-3.2-90b-vision-preview')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c376997d-0d5c-485d-b9c1-b71da1af22b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "AeDkpvGDhMGV"
   },
   "source": [
    "## Task - 1: Review Analysis and Response\n",
    "\n",
    "For each review get ChatGPT to do the following:\n",
    "\n",
    "            - Summarize the following reviews below, delimited by triple\n",
    "            backticks. For each review, the summary should be at most 3 lines.\n",
    "            - Highlight both the positives and negatives for each review\n",
    "            - Display the overall sentiment for each review (positive, negative, neutral)\n",
    "            - Display a list of 3 - 5 emotions expressed by the customer\n",
    "            - If the sentiment is positive or neutral write an email and thank them for the review\n",
    "            - If the sentiment is negative apologize and write an email with an appropriate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bfc37de-8651-472c-aa6f-51e7190788bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "hRbBZB57hT0G"
   },
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    f\"\"\"\n",
    "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
    "    The sound quality is impressively clear with just the right amount of bass.\n",
    "    It's also waterproof, which tested true during a recent splashing incident.\n",
    "    Though it's compact, the volume can really fill the space.\n",
    "    The price was a bargain for such high-quality sound.\n",
    "    Shipping was also on point, arriving two days early in secure packaging.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Purchased a new gaming keyboard because of its rave reviews about responsiveness and backlighting.\n",
    "    It hasn't disappointed. The keys have a satisfying click and the LED colors are vibrant,\n",
    "    enhancing my gaming experience significantly. Price-wise, it's quite competitive,\n",
    "    and I feel like I got a good deal. The delivery was swift, and it came well-protected,\n",
    "    ensuring no damage during transport.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Ordered a set of wireless earbuds for running, and they've been a letdown.\n",
    "    The sound constantly cuts out, and the fit is uncomfortable after only a few minutes of use.\n",
    "    They advertised a 12-hour battery life, but I'm barely getting four hours.\n",
    "    Considering the cost, I expected better quality and performance.\n",
    "    They did arrive on time, but the positives end there. I'm already looking into a return.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    The tablet stand I bought was touted as being sturdy and adjustable,\n",
    "    but it's anything but. It wobbles with the slightest touch,\n",
    "    and the angles are not holding up as promised. It feels like a breeze could knock it over.\n",
    "    It was also pricier than others I've seen, which adds to the disappointment.\n",
    "    It did arrive promptly, but what's the use if the product doesn't meet basic expectations?\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Needed a new kitchen blender, but this model has been a nightmare.\n",
    "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
    "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
    "    I thought the brand meant quality, but this product has proven me wrong.\n",
    "    Plus, it arrived three days late. Definitely not worth the expense.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a3d019e-960c-4e29-8d09-e895ebb6c232",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jZwPaViatl7f"
   },
   "outputs": [],
   "source": [
    "gpt_responses = []\n",
    "llama_responses = []\n",
    "\n",
    "for review in reviews:\n",
    "    prompt = f\"\"\"\n",
    "                Act as a product review analyst.\n",
    "                Your task is to perform the following tasks:\n",
    "\n",
    "                - Summarize the following review below, delimited by triple\n",
    "                backticks in at most 3 lines.\n",
    "                - Highlight both the positives and negatives for the review separately if any\n",
    "                - Display the overall sentiment for the review (positive, negative OR neutral)\n",
    "                - Display a list of 3 - 5 emotions expressed by the customer\n",
    "                - If the sentiment is positive or neutral write an email and thank them for the review\n",
    "                - If the sentiment is negative apologize and write an email with an appropriate response\n",
    "\n",
    "                ```{review}```\n",
    "                \"\"\"\n",
    "    response = get_completion(prompt,\n",
    "                              model='gpt-4o')\n",
    "    gpt_responses.append(response)\n",
    "    response = get_completion(prompt,\n",
    "                              model='llama-3.2-90b-vision-preview')\n",
    "    llama_responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a8a6b67-5f9c-47dd-8694-84fc6d040c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EdUFkKAmtmBj",
    "outputId": "cae9c547-3de0-4e94-accb-923c84333083"
   },
   "outputs": [],
   "source": [
    "for review, gpt_response, in zip(reviews, gpt_responses):\n",
    "    print('Review:')\n",
    "    display(Markdown(review))\n",
    "    print()\n",
    "    print('LLM Response:')\n",
    "    display(Markdown(gpt_response))\n",
    "    print('------')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4afa99cd-26bd-42a0-bbf3-f9dbfbf23ae1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sOOusUF_takD",
    "outputId": "8021131b-eb0f-4a2d-f0a0-385dc7e503eb"
   },
   "outputs": [],
   "source": [
    "for review, llama_response, in zip(reviews, llama_responses):\n",
    "    print('Review:')\n",
    "    display(Markdown(review))\n",
    "    print()\n",
    "    print('LLM Response:')\n",
    "    display(Markdown(llama_response))\n",
    "    print('------')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67591b6f-5d7e-4539-a15f-ea9fa7303acb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "eEtB1IOimA0i"
   },
   "source": [
    "## Task - 2: Paper Analysis and Summarization\n",
    "\n",
    "- Act as a Artificial Intelligence Expert.\n",
    "Transform this research paper abstract in triple backticks\n",
    "into a short concise summary of maximum 10 lines\n",
    "\n",
    "- Act as a Artificial Intelligence Expert.\n",
    "Transform this research paper abstract in triple backticks\n",
    "into an executive summary for a healthcare company.\n",
    "Have bullet points for pros and cons of ethics in Generative AI as mentioned in the paper.\n",
    "\n",
    "- Act as a Artificial Intelligence Expert.\n",
    "Transform this research paper abstract in triple backticks\n",
    "into an executive summary for a generative AI company solving healthcare problems.\n",
    "Have bullet points for key points mentioned for\n",
    "Generative AI for text, images and structured data based healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfd587e0-a38f-4c86-9e4f-869dba6c6e98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4FnITE6zhV-9"
   },
   "outputs": [],
   "source": [
    "paper_abstract = f\"\"\"\n",
    "The widespread use of ChatGPT and other emerging technology powered by generative\n",
    "artificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\n",
    "high-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\n",
    "issues beyond following guidelines and regulations that are still under discussion and\n",
    "development. On the other hand, other types of generative AI have been used to synthesize\n",
    "images and other types of data for research and practical purposes, which have resolved some\n",
    "ethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\n",
    "of ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\n",
    "generative AI via a systematic scoping review of relevant existing research in healthcare, and\n",
    "reduce the gaps by proposing an ethics checklist for comprehensive assessment and\n",
    "transparent documentation of ethical discussions in generative AI development. While the\n",
    "checklist can be readily integrated into the current peer review and publication system to\n",
    "enhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\n",
    "products) to help users establish reasonable trust in their capabilities.\n",
    "\n",
    "Current ethical discussions on generative AI in healthcare\n",
    "We conducted a systematic scoping review to analyse current ethical discussions on\n",
    "generative AI in healthcare. Our search in four major academic research databases for\n",
    "relevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\n",
    "detailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\n",
    "which 193 articles were included for analysis based on application data modality (text, image,\n",
    "or structured data), ethical issues discussed, generative AI involved, and whether generative\n",
    "AI causes or offers technical solutions for issues raised.\n",
    "\n",
    "Generative AI for text data-based healthcare\n",
    "Forty-one of the 193 articles discussed ethical considerations pertaining to generative AI\n",
    "applications for text data, with 20 articles describing methodological developments or\n",
    "applications of generative AI and the other 21 articles describing review-type works on this\n",
    "topic. Although some of these review-type articles used the general term “generative AI”, the\n",
    "main body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\n",
    "discussions on ethical issues, whereas the other 12 articles only briefly touched on some\n",
    "ethical aspects.\n",
    "Among the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\n",
    "specifically by GPT in 16 of the articles), covering a wide range of application scenarios and\n",
    "considered the application of all 10 ethical principles identified in the review (see Figure 1),\n",
    "as well as other less discussed concerns such as human-AI interaction, and the rights of\n",
    "LLMs to be considered as co-authors in scientific papers. One paper only commented briefly\n",
    "on the need for ethical considerations in LLMs and is summarised in the “Others” category.\n",
    "Although all ethical principles are equally important, some are discussed more often than\n",
    "others, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\n",
    "privacy.\n",
    "Fifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\n",
    "confidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\n",
    "autoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\n",
    "medical text, to reduce disparity by providing accessible services and assistance, to detect\n",
    "health-related misinformation, to generate trusted content, and to improve accountability or\n",
    "transparency over existing approaches. While most articles focused on either identifying\n",
    "ethical issues caused by generative AI or proposing generative AI-based solutions, three\n",
    "articles discussed both to provide a more balanced perspective.\n",
    "\n",
    "Generative AI for image and structured data-based healthcare\n",
    "Unlike the diverse application scenarios of generative AI based on text data, for image and\n",
    "structured data, this use of generative AI focuses on data synthesis and encryption. Hence the\n",
    "majority of articles discussed the methodological developments of generative AI as giving\n",
    "rise to a more distinctive and focused set of ethical issues.\n",
    "5\n",
    "Notably, of the 98 articles on image data and 58 articles on structured data, more than half\n",
    "(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\n",
    "brief motivation for methodological developments or as a general discussion point. The rest\n",
    "included more in-depth discussions or evaluations of ethical issues. Among these 155 articles\n",
    "(as one article covered multiple modalities), 11 articles were review-type work, where 10\n",
    "articles reviewed methods that mentioned one or two ethical perspectives, and only one\n",
    "article24 discussed detailed ethical concerns on generative AI applications.\n",
    "Resolving privacy issues was the main aim of articles for these two data modalities (n=74 for\n",
    "image data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\n",
    "data using GAN. Eight articles on image data and 9 articles on structured data used\n",
    "generative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\n",
    "existing databases. For both data modalities, we did not see explicit discussions on resolving\n",
    "autonomy, integrity, or morality issues using generative AI, and for structured data the articles\n",
    "additionally lacked discussions on trust or transparency.\n",
    "Only 11 articles for image data selectively discussed some ethical issues that generative AI\n",
    "can give rise to, without specific discussions regarding autonomy, integrity, or morality. For\n",
    "structured data, only 4 articles discussed equity, privacy, or data security issues caused by\n",
    "generative AI. Only two articles on structured data included both the cause and resolving\n",
    "perspectives by discussing ethical issues that may arise from limitations of methods\n",
    "proposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4dbef04-be20-428a-90aa-4997f721deb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "6V8bj9PytnwH"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as a Artificial Intelligence Expert.\n",
    "Transform this research paper abstract in triple backticks\n",
    "into a short concise summary of maximum 10 lines\n",
    "\n",
    "Abstract:\n",
    "```{paper_abstract}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce5edab4-3424-485c-b9f0-d64a7e4f145a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "id": "3QJtuCp8uLEx",
    "outputId": "ed075d36-e3c5-4870-9949-087ee419b57f"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='gpt-4o')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5aa60b6f-781f-4791-9678-0a34841902f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "3IqtGWZNuPcW",
    "outputId": "cfb7fe5e-f6b1-4fe1-e0e0-10f790ca526a"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='llama-3.2-90b-vision-preview')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cb0e9a0-43d2-414b-b1d8-bdf1277f6fd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "VoOtVYKttn1d"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as a Artificial Intelligence Expert.\n",
    "Transform this research paper abstract in triple backticks\n",
    "into an executive summary for a healthcare company.\n",
    "Have bullet points for pros and cons of ethics in Generative AI as mentioned in the paper.\n",
    "\n",
    "Abstract:\n",
    "```{paper_abstract}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8023011-ad0f-4b36-a724-50456a2a28a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "dr9N8MxuuXXt",
    "outputId": "b3ca18f7-6d4d-4cbe-b9a9-ef5be427ff77"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='gpt-4o')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c3ec083-3915-41ee-9243-50a9589f6db5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "id": "ZBAoEVwIuhAX",
    "outputId": "e846ebed-2202-49c1-f11a-433771ba5d02"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='llama-3.2-90b-vision-preview')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bcf2453-0486-4ef3-b674-9473e7768c01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "uLB_1U-mm345"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as a Artificial Intelligence Expert.\n",
    "Transform this research paper abstract in triple backticks\n",
    "into an executive summary for a generative AI company solving healthcare problems.\n",
    "Have bullet points for key points mentioned for\n",
    "Generative AI for text, images and structured data based healthcare\n",
    "\n",
    "Abstract:\n",
    "```{paper_abstract}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08af1df6-a76b-4b44-8cd3-61926f77fb35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "7gf_W5idumYF",
    "outputId": "7c90332f-aefe-4c29-bc1b-6e93047e4561"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='gpt-4o')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93c91c58-4b26-445e-b294-01c0097b9e1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "uAyyArSquwVd",
    "outputId": "c2166632-f6f3-4dca-b1b0-5a94538343e8"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='llama-3.2-90b-vision-preview')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddd2062c-f16e-4bd6-b85a-4e0f00149604",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NIo7i6vNmRJO"
   },
   "source": [
    "## Task 3 - Marketing Adverts for Smartphone\n",
    "\n",
    "You have the technical fact sheets of one smartphone. Try some iterative prompt engineering and do the following:\n",
    "\n",
    "1. Generate marketing product description for the smartphone\n",
    "\n",
    "2. Custom product description which has the following:\n",
    "\n",
    "```\n",
    "The description should follow this format:\n",
    "\n",
    "Product Name: <Name of the smartphone>\n",
    "​\n",
    "Description: <Brief Overview of the features>\n",
    "​\n",
    "Product Specifications:\n",
    "<Table with key product feature specifications>\n",
    "​\n",
    "The description should focus on the most important features\n",
    "a customer might look for in a phone including the foldable display screen,\n",
    "processing power, RAM, camera and battery life.\n",
    "​\n",
    "After the description, the table should have the\n",
    "key specifications of the product. It should have two columns.\n",
    "The first column should have 'Feature'\n",
    "and the second column should have 'Specification'\n",
    "and try to put exact numeric values for features if they exist.\n",
    "Only put the most important features in the table which matter to users.\n",
    "```\n",
    "\n",
    "3. Custom product description focusing on specific aspects like display, camera and in less than 60 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e88fffb-c043-4dc4-9c75-5531839ffbef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1F5spdPWmWrr"
   },
   "outputs": [],
   "source": [
    "fact_sheet_mobile = \"\"\"\n",
    "PRODUCT NAME:\n",
    "Samsung Galaxy Z Fold6\n",
    "​\n",
    "PRODUCT OVERVIEW:\n",
    "Galaxy AI is Here - Put PC-like power in your pocket, Galaxy Z Fold6. More powerful than ever with its super-slim, productive screen. Now super-charged with Galaxy AI on foldables.\n",
    "Fold open a mobile gaming beast with a massive screen made better with the Vision Booster's powerful brightness and clarity even in broad daylight.\n",
    "Enjoy silky-smooth gaming with Vulkan, even in AAA games. Then, Snapdragon 8 Gen 3 for Galaxy renders graphics that are absolutely fire.\n",
    "Meet Fold's most powerful camera system yet. Topped with an upgraded NPU, mind-blowing specs and ProVisual Engine, it'll transform your multimedia experience. Zoom way, way, way in while keeping noise down and resolution clear with ProVisual Engine. Its sharp analysis of the zoomed-in region enhances your shot dramatically.\n",
    "With our high-resolution, 50MP camera, witness every detail come to life with stunning clarity and vibrancy.​\n",
    "\n",
    "PRODUCT SPECS:\n",
    "Network\tTechnology\n",
    "GSM / CDMA / HSPA / EVDO / LTE / 5G\n",
    "Launch\tAnnounced\t2024, July 10\n",
    "Status\tAvailable. Released 2024, July 24\n",
    "Body\tDimensions\tUnfolded: 153.5 x 132.6 x 5.6 mm\n",
    "Folded: 153.5 x 68.1 x 12.1 mm\n",
    "Weight\t239 g (8.43 oz)\n",
    "Build\tGlass front (Gorilla Glass Victus 2) (folded), plastic front (unfolded), glass back (Gorilla Glass Victus 2), aluminum frame\n",
    "SIM\tUp to two Nano-SIM and multi eSIM\n",
    " \tIP48 water resistant (up to 1.5m for 30 min)\n",
    "Enhanced armor aluminum frame with tougher drop and scratch resistance (advertised)\n",
    "Stylus support\n",
    "Display\tType\tFoldable Dynamic LTPO AMOLED 2X, 120Hz, HDR10+, 2600 nits (peak)\n",
    "Size\t7.6 inches, 185.2 cm2 (~91.0% screen-to-body ratio)\n",
    "Resolution\t1856 x 2160 pixels (~374 ppi density)\n",
    " \tCover display:\n",
    "Dynamic LTPO AMOLED 2X, 120Hz, 2600 nits (peak), Corning Gorilla Glass Victus 2\n",
    "6.3 inches, 968 x 2376 pixels, 410 ppi\n",
    "Platform\tOS\tAndroid 14, up to 4 major Android upgrades, One UI 6.1.1\n",
    "Chipset\tQualcomm SM8650-AC Snapdragon 8 Gen 3 (4 nm)\n",
    "CPU\t8-core (1x3.39GHz Cortex-X4 & 3x3.1GHz Cortex-A720 & 2x2.9GHz Cortex-A720 & 2x2.2GHz Cortex-A520)\n",
    "GPU\tAdreno 750 (1 GHz)\n",
    "Memory\tCard slot\tNo\n",
    "Internal\t256GB 12GB RAM, 512GB 12GB RAM, 1TB 12GB RAM\n",
    " \tUFS 4.0\n",
    "Main Camera\tTriple\t50 MP, f/1.8, 23mm (wide), 1.0µm, dual pixel PDAF, OIS\n",
    "10 MP, f/2.4, 66mm (telephoto), 1.0µm, PDAF, OIS, 3x optical zoom\n",
    "12 MP, f/2.2, 123˚, 12mm (ultrawide), 1.12µm\n",
    "Features\tLED flash, HDR, panorama\n",
    "Video\t8K@30fps, 4K@60fps, 1080p@60/120/240fps (gyro-EIS), 720p@960fps (gyro-EIS), HDR10+\n",
    "Selfie camera\tSingle\t4 MP, f/1.8, 26mm (wide), 2.0µm, under display\n",
    "Cover camera:\n",
    "10 MP, f/2.2, 24mm (wide), 1/3\", 1.22µm\n",
    "Features\tHDR\n",
    "Video\t4K@30/60fps, 1080p@30/60fps, gyro-EIS\n",
    "Sound\tLoudspeaker\tYes, with stereo speakers\n",
    "3.5mm jack\tNo\n",
    " \t32-bit/384kHz audio\n",
    "Tuned by AKG\n",
    "Comms\tWLAN\tWi-Fi 802.11 a/b/g/n/ac/6e, tri-band, Wi-Fi Direct\n",
    "Bluetooth\t5.3, A2DP, LE, aptX HD\n",
    "Positioning\tGPS, GALILEO, GLONASS, BDS, QZSS\n",
    "NFC\tYes\n",
    "Radio\tNo\n",
    "USB\tUSB Type-C 3.2, OTG\n",
    "Features\tSensors\tFingerprint (side-mounted), accelerometer, gyro, proximity, compass, barometer\n",
    " \tSamsung DeX (desktop experience support)\n",
    "Ultra Wideband (UWB) support\n",
    "Circle to Search\n",
    "Battery\tType\tLi-Po 4400 mAh, non-removable\n",
    "Charging\t25W wired, QC2.0, 50% in 30 min (advertised)\n",
    "15W wireless\n",
    "4.5W reverse wireless\n",
    "Misc\tColors\tNavy, Silver Shadow, Pink, Black, White\n",
    "Models\tSM-F956B, SM-F956B/DS, SM-F956U, SM-F956U1, SM-F956N, SM-F956W, SM-F9560\n",
    "SAR EU\t1.24 W/kg (head)     1.39 W/kg (body)\n",
    "Price\t₹ 132,890 / $ 1,147.35 / £ 1,199.99 / € 1,245.00\n",
    "Tests\tPerformance\tAnTuTu: 1608744 (v10)\n",
    "GeekBench: 6757 (v6)\n",
    "3DMark: 4644 (Wild Life Extreme)\n",
    "Display\t1630 nits max brightness (measured)\n",
    "Loudspeaker\t-26.5 LUFS (Good)\n",
    "Battery (new)\n",
    "Active use score 11:31h\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6596d48-bb61-46c6-8dbd-550f27211eca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "QXsNT5cptrE0"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "in triple backticks.\n",
    "​\n",
    "Write a brief marketing product description\n",
    "\n",
    "Technical specifications:\n",
    "```{fact_sheet_mobile}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8e3c766-fad5-477e-ab13-af86409b73d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "gJA88tF6wID-",
    "outputId": "bc1d9691-1b18-406e-8aa3-3715959206d7"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='gpt-4o')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59f7cfa2-82b6-4eea-b024-1487dc65739d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "7RzkRuBQwRTr",
    "outputId": "18928a40-1cc5-41c8-ca0b-faf74568c1ee"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='llama-3.2-90b-vision-preview')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fab0ffd5-7fba-47a8-bcca-72eee1f093a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "A0kIyc4ZtrIU"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "in triple backticks.\n",
    "​\n",
    "Write a brief product description.\n",
    "\n",
    "The description should follow this format:\n",
    "\n",
    "<h3>Product Name<h3>\n",
    "\n",
    "<Name of the smartphone>\n",
    "​\n",
    "<h3>Description<h3>\n",
    "\n",
    "<Brief Overview of the features>\n",
    "​\n",
    "<h3>Product Specifications<h3>\n",
    "\n",
    "<Table with key product feature specifications>\n",
    "​\n",
    "The description should only focus on the most important features\n",
    "a customer might look for in a phone including the foldable display screen,\n",
    "processing power, RAM, camera and battery life.\n",
    "​\n",
    "After the description, the table should have the\n",
    "key specifications of the product. It should have two columns.\n",
    "The first column should have 'Feature'\n",
    "and the second column should have 'Specification'\n",
    "and try to put exact numeric values for features if they exist.\n",
    "Only put the most important features in the table which matter to users.\n",
    "\n",
    "Technical specifications:\n",
    "```{fact_sheet_mobile}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ba22701-d54d-4c38-83c5-ec3580397f66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "I9pufHTxwZil",
    "outputId": "0170a753-40d3-4f44-d20e-b9d2016300c5"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='gpt-4o')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96876bc0-f5bb-4a05-a5bd-3e6fad506398",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "n0hFSmJjweFS",
    "outputId": "557bd947-3c8a-4f25-bf2b-09780093fcba"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='llama-3.2-90b-vision-preview')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b9e1a08-179f-43c1-ac4a-2c7b24a55d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ed-Y_8IvoPUt"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "in triple backticks.\n",
    "\n",
    "Write a catchy product description which uses at most 60 words\n",
    "and focuses on the most important things about the smartphone\n",
    "which might matter to users like display and camera.\n",
    "Use relevant emojis as needed.\n",
    "\n",
    "Technical specifications:\n",
    "```{fact_sheet_mobile}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f92c5c98-63a0-4082-8a8e-6eca49e2a38a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "0JI7l0yjq_V3",
    "outputId": "d247a67b-4901-4d25-cd78-820b11c5bfc8"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='gpt-4o')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4428bb56-65d8-4a98-a9ca-8fb5f076fc2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "0zV_-UOqwpUE",
    "outputId": "e91ed906-4cfa-432d-d1f7-467dd82bfc46"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='llama-3.2-90b-vision-preview')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0eb23884-e7f4-4fd8-9769-73775717c85a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_VBDwjHlowmk"
   },
   "source": [
    "## Exercise 4 - IT Support Resolution\n",
    "\n",
    "Ask the LLM to act as a customer support agent, process each customer ticket message and output the response in JSON with the following fields\n",
    "```\n",
    "orig_msg: The original customer message\n",
    "orig_lang: Detected language of the customer message e.g. Spanish\n",
    "category: 1-2 word describing the category of the problem\n",
    "trans_msg: Translated customer message in English\n",
    "response: Response to the customer in orig_lang\n",
    "trans_response: Response to the customer in English\n",
    "```\n",
    "\n",
    "Hint: Use the following prompt in a for loop\n",
    "\n",
    "```\n",
    "prompt = f\"\"\"\n",
    "            Act as a customer support agent. For the IT support message mentioned below\n",
    "            in triple backticks, create a response is JSON in the following format:\n",
    "\n",
    "            {{\n",
    "                orig_msg: The original customer message\n",
    "                orig_lang: Detected language of the customer message e.g. Spanish\n",
    "                category: 1-2 word describing the category of the problem\n",
    "                trans_msg: Translated customer message in English\n",
    "                response: Response to the customer in orig_lang\n",
    "                trans_response: Response to the customer in English\n",
    "            }}\n",
    "\n",
    "            Message:\n",
    "            '''{msg}'''\n",
    "            \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fcae3ea-9971-44c7-b176-342b802464f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ZrRFJVSMoDqa"
   },
   "outputs": [],
   "source": [
    "it_support_queue = [\n",
    "    \"Não consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.\",\n",
    "    \"Ho problemi a stampare i documenti da remoto. Il lavoro non viene inviato alla stampante di rete.\",\n",
    "    \"プリンターのトナーを交換しましたが、印刷品質が低下しています。サポートが必要です。\",\n",
    "    \"Я не могу войти в систему учета времени, появляется сообщение об ошибке. Мне нужна помощь.\",\n",
    "    \"Internet bağlantım çok yavaş ve bazen tamamen kesiliyor. Yardım eder misiniz?\",\n",
    "    \"Не могу установить обновление безопасности. Появляется код ошибки. Помогите, пожалуйста.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b2d952d-c180-4b3b-839a-e3e6b8352ef9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "LUluiGOsts0z"
   },
   "outputs": [],
   "source": [
    "gpt_responses = []\n",
    "llama_responses = []\n",
    "\n",
    "for msg in it_support_queue:\n",
    "    prompt = f\"\"\"\n",
    "                Act as a customer support agent. For the IT support message mentioned below\n",
    "                in triple backticks, create a response in JSON in the following format:\n",
    "\n",
    "                {{\n",
    "                    orig_msg: The original customer message\n",
    "                    orig_lang: Detected language of the customer message e.g. Spanish\n",
    "                    category: 1-2 word describing the category of the problem\n",
    "                    trans_msg: Translated customer message in English\n",
    "                    response: Response to the customer in orig_lang\n",
    "                    trans_response: Response to the customer in English\n",
    "                }}\n",
    "\n",
    "                Message:\n",
    "                '''{msg}'''\n",
    "                \"\"\"\n",
    "    response = get_completion(prompt,\n",
    "                              model='gpt-4o')\n",
    "    gpt_responses.append(response)\n",
    "    response = get_completion(prompt,\n",
    "                              model='llama-3.2-90b-vision-preview')\n",
    "    llama_responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65358691-e57d-4ae5-9190-b8c3e4c791ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kjtsm77ets3h",
    "outputId": "fa161187-e838-495a-d8df-25a729b4ebae"
   },
   "outputs": [],
   "source": [
    "for response in gpt_responses:\n",
    "  display(Markdown(response))\n",
    "  print('-----')\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0339b2e8-0d36-4ad0-a26d-0d17a25c0040",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oGo-3TsWzNb5",
    "outputId": "03b8bc81-d926-4bd1-bb29-5d26178bcfcd"
   },
   "outputs": [],
   "source": [
    "for response in llama_responses:\n",
    "  display(Markdown(response))\n",
    "  print('-----')\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18a17a42-114f-495d-87a5-c4e3cd821050",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "vDkUijhs9vN5"
   },
   "source": [
    "## Exercise 5 - Synthetic Data Generation\n",
    "\n",
    "Ask the LLM to generate synthetic data for you which can be used for few-shot prompting or training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b42e364-71db-4775-8e6a-bf53e1b61575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "vIuU_8938-8O"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an expert English linguist with a solid experience of how social media platforms\n",
    "like Twitter function.\n",
    "\n",
    "Generate five positive and five negative movie-review tweets.\n",
    "\n",
    "Constraints: Make sure that the length of tweet is within 250 characters.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d802c61-1041-4281-8d31-09ded62e5276",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "VKGJe-TLzaeZ",
    "outputId": "89d7f0c7-3775-400e-977b-0ca56942feb5"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='gpt-4o')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ee60cae-1511-4344-84a4-5034e64c2aa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "r2cFOeUrGvBM",
    "outputId": "76d93985-46fe-4b62-b3fe-8e2ab8ef2c0a"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='llama-3.2-90b-vision-preview')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dc84783-a92b-4c9c-af28-6ecdb3a74490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_W27k0z09OHt"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an expert English linguist with a solid experience of\n",
    "how retail websites like Amazon work.\n",
    "\n",
    "Generate three positive and three negative laptop reviews. They should be detailed.\n",
    "Output in the following format:\n",
    "Review: <review>\n",
    "Sentiment: <sentiment>\n",
    "Key Topics: <key topics> (max 3)\n",
    "\n",
    "Constraints: Make sure that the laptop product reviews contain a maximum of 200 words.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54a785fa-1adc-4559-bb0f-eb56a337a625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "id": "DuCpKVjz0Tah",
    "outputId": "cecc29d8-610b-43ce-e4c1-0bb7c481dcb9"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='gpt-4o')\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdad7c8f-4baa-4fc6-b0b3-f99af4811f82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "n6pefVgp0U3m",
    "outputId": "bb3cbf7c-7a0b-4760-c537-efe5579065cb"
   },
   "outputs": [],
   "source": [
    "response = get_completion(prompt,\n",
    "                          model='llama-3.2-90b-vision-preview')\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "M7_Prompt_Engineering_with_GPT_4o_&_Llama_3_2_on_Real_World_Tasks",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
